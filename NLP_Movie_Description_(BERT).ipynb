{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Movie Description (BERT).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBQ6/EJw05GADTrWdgFdD5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "681af7c040a24a8388b1243e44d7503c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8363e67accaa4c328f7a1c658bd81996",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e48e1146e0a7416a8cf63ce2dc2a500b",
              "IPY_MODEL_f72f62c7a55c4a49ad790430995d741e"
            ]
          }
        },
        "8363e67accaa4c328f7a1c658bd81996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e48e1146e0a7416a8cf63ce2dc2a500b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97aa0ad91a734b49852f0e9bf2befd0a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_271c7621d3484d27a4a72cf0baed171a"
          }
        },
        "f72f62c7a55c4a49ad790430995d741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_447b684f51b3416bbc7dc395119c3329",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 800kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_274dc6e5a9544e46bba1f5887ab108ec"
          }
        },
        "97aa0ad91a734b49852f0e9bf2befd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "271c7621d3484d27a4a72cf0baed171a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "447b684f51b3416bbc7dc395119c3329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "274dc6e5a9544e46bba1f5887ab108ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AudreyCTang/Movie-Review-Topic-Modelling-Sentiment-Analysis/blob/master/NLP_Movie_Description_(BERT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYu3MakxN4W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF8XGs8UiH2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbmSekjwMYMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "423341a7-e499-46fc-8298-09ea0d0278a3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o-cgdSPN9gm",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "23673904-5f14-4536-ecba-6293bc7deea4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3a3c985-eb58-4078-9cbc-d09f20054ec4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3a3c985-eb58-4078-9cbc-d09f20054ec4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving IMDB_Reviews.csv to IMDB_Reviews.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4oMLKxVMlbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['IMDB_Reviews.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blWlL2_lexBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "da6d9740-f2a3-492f-d443-760bab0e143c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Based on an actual story, John Boorman shows t...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a gem. As a Film Four production - the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I really like this show. It has drama, romance...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>This is the best 3-D experience Disney has at ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Of the Korean movies I've seen, only three had...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             Review  Sentiment\n",
              "0           0  Based on an actual story, John Boorman shows t...        1.0\n",
              "1           1  This is a gem. As a Film Four production - the...        1.0\n",
              "2           2  I really like this show. It has drama, romance...        1.0\n",
              "3           3  This is the best 3-D experience Disney has at ...        1.0\n",
              "4           4  Of the Korean movies I've seen, only three had...        1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxoXWX3ae0sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.drop(columns='Unnamed: 0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyx4Jo3oe67j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "e2d1e2d9-6f4d-4189-9834-901d2d62864d"
      },
      "source": [
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 25,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18793</th>\n",
              "      <td>Jack Frost 2. THE worst \"horror film\" I have e...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14801</th>\n",
              "      <td>Mansfield Park, in its second half, is my favo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19194</th>\n",
              "      <td>There was a time when the Alien series was a s...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15050</th>\n",
              "      <td>Oddball black-comedy romance featuring a great...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5316</th>\n",
              "      <td>One of the best films I've seen in a long time...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17888</th>\n",
              "      <td>And also a wonderful beginning, a real quick s...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1771</th>\n",
              "      <td>Fuckland is an interesting film. I personally ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11215</th>\n",
              "      <td>I'm not a fan of scratching, but I really dug ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15662</th>\n",
              "      <td>I loved so much last Bellocchio's movie, the m...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11185</th>\n",
              "      <td>Recently released on British DVD, this is a go...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Review  Sentiment\n",
              "18793  Jack Frost 2. THE worst \"horror film\" I have e...        0.0\n",
              "14801  Mansfield Park, in its second half, is my favo...        0.0\n",
              "19194  There was a time when the Alien series was a s...        0.0\n",
              "15050  Oddball black-comedy romance featuring a great...        0.0\n",
              "5316   One of the best films I've seen in a long time...        1.0\n",
              "17888  And also a wonderful beginning, a real quick s...        0.0\n",
              "1771   Fuckland is an interesting film. I personally ...        1.0\n",
              "11215  I'm not a fan of scratching, but I really dug ...        1.0\n",
              "15662  I loved so much last Bellocchio's movie, the m...        0.0\n",
              "11185  Recently released on British DVD, this is a go...        1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK3IzK2CfytH",
        "colab_type": "text"
      },
      "source": [
        "# Topic Modelling\n",
        "For the first part, we will use topic modelling techniques to group different reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEJr8Uo1gTot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "ca603303-ae6f-4a02-934d-b30376ce6a8f"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (49.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=98fd7c9a4e2d491f36d4554010715e862acd0dd13cc87750290ad8836745eebf\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=31006a3565880ebae2f95c94931921298ec9f1828ff3183a7a5191913fc17ba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4e-4FLRrJ4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ad621922-52d1-4d3c-c939-d69cbe2c58a0"
      },
      "source": [
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import LsiModel, TfidfModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "from gensim.parsing.preprocessing import preprocess_string, remove_stopwords\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize, corpus\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "from nltk.stem import RegexpStemmer, WordNetLemmatizer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Run in python console\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.style as style\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "# Get topic weights and dominant topics ------------\n",
        "from sklearn.manifold import TSNE\n",
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.models import Label\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxrTNXcrgabI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df.Review.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKM6rD_ANSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df.Sentiment.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF6ka4O_B8LQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0802c57b-45e8-4ab4-e7bc-d6b2cd4e2182"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVjKt0cFgmb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def clean_text(x):\n",
        "    \n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', x)\n",
        "\n",
        "\n",
        "    \n",
        "    return x\n",
        "    \n",
        "\n",
        "    \n",
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def clean(x):\n",
        "    x = clean_text(x)\n",
        "    x = clean_numbers(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def remove_stopwords(x):\n",
        "    stopwords = ['movi', 'film', 'like', 'scene', 'watch']\n",
        "    x  = [word for word in x if word.lower() not in stopwords]\n",
        "\n",
        "    return x\n",
        "\n",
        "def prepare_documents(documents):\n",
        "    print('Preparing documents')\n",
        "    documents = [clean(document) for document in documents]\n",
        "    documents = [preprocess_string(doc) for doc in documents]\n",
        "    documents = [remove_stopwords(doc) for doc in documents]\n",
        "\n",
        "    return documents\n",
        "\n",
        "def create_lda_model(documents, dictionary, number_of_topics):\n",
        "\n",
        "    print(f'Creating LDA Model with {number_of_topics} topics')\n",
        "\n",
        "    # using bow to construct relevance table out of documents\n",
        "    document_terms = [dictionary.doc2bow(doc) for doc in documents]\n",
        "\n",
        "    return LdaModel(document_terms,\n",
        "                    num_topics=number_of_topics,\n",
        "                    id2word = dictionary, passes=15), document_terms\n",
        "\n",
        "def run_lda_process(documents, number_of_topics):\n",
        "\n",
        "    documents = prepare_documents(documents)\n",
        "    \n",
        "    # mapping between words and their integer ids\n",
        "    dictionary = corpora.Dictionary(documents)\n",
        "\n",
        "    lda_model, document_terms = create_lda_model(documents, dictionary,\n",
        "                                 number_of_topics)\n",
        "\n",
        "    return documents, dictionary, lda_model, document_terms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnuh3O10nILn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_coherence_score(documents, dictionary, model):\n",
        "\n",
        "    coherence_model = CoherenceModel(model=model,\n",
        "                                     texts=documents,\n",
        "                                     dictionary=dictionary,\n",
        "                                     coherence='c_v')\n",
        "    return coherence_model.get_coherence()\n",
        "\n",
        "def get_coherence_values(start, stop, document):\n",
        "\n",
        "    for num_topics in range(start, stop):\n",
        "        print(f'\\nCalculating coherence for {num_topics} topics')\n",
        "        documents, dictionary, model, document_terms = run_lda_process(document,\n",
        "                                                       number_of_topics=num_topics)\n",
        "        coherence = calculate_coherence_score(documents,\n",
        "                                              dictionary,\n",
        "                                              model)\n",
        "\n",
        "        yield coherence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsJ0DShrnRqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "7e5a7bc7-c0b8-4ff0-aae9-b24e34287899"
      },
      "source": [
        "min_topics, max_topics = 6,20\n",
        "\n",
        "coherence_scores = list(get_coherence_values(min_topics, max_topics, data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating coherence for 6 topics\n",
            "Preparing documents\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7fe7eb0e1266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmin_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcoherence_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-74cb69429e20>\u001b[0m in \u001b[0;36mget_coherence_values\u001b[0;34m(start, stop, document)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nCalculating coherence for {num_topics} topics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         documents, dictionary, model, document_terms = run_lda_process(document,\n\u001b[0;32m---> 14\u001b[0;31m                                                        number_of_topics=num_topics)\n\u001b[0m\u001b[1;32m     15\u001b[0m         coherence = calculate_coherence_score(documents,\n\u001b[1;32m     16\u001b[0m                                               \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-557025c64f45>\u001b[0m in \u001b[0;36mrun_lda_process\u001b[0;34m(documents, number_of_topics)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_lda_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# mapping between words and their integer ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-557025c64f45>\u001b[0m in \u001b[0;36mprepare_documents\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preparing documents'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-557025c64f45>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preparing documents'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_string\u001b[0;34m(s, filters)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36mstem_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/parsing/porter.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1ab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/parsing/porter.py\u001b[0m in \u001b[0;36m_step2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ational\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdkUjA7nSIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style.use('fivethirtyeight')\n",
        "\n",
        "x = [int(i) for i in range(min_topics, max_topics)]\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "plt.plot(x, coherence_scores)\n",
        "\n",
        "plt.xlabel('Number of topics')\n",
        "\n",
        "plt.ylabel('Coherence Value')\n",
        "\n",
        "plt.title('Coherence Scores by number of Topics')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXxuNe7-gwwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f123a87-4a9f-4023-b6c4-bd0cf528f8f9"
      },
      "source": [
        "NUM_TOPICS = 15\n",
        "\n",
        "documents, dictionary, model, document_terms = run_lda_process(data, number_of_topics=NUM_TOPICS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing documents\n",
            "Creating LDA Model with 15 topics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi-YDlYTgyCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find dominant topics in each document\n",
        "\n",
        "def format_topics_sentences(ldamodel=None, corpus=document_terms, texts=data):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row_list in enumerate(ldamodel[corpus]):\n",
        "#         print(row_list)\n",
        "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "#         print(row)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "#             print(j, (topic_num, prop_topic))\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ElraQhhg_k2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "a2a2bdd9-aa3e-455f-8059-0f1bc6324a19"
      },
      "source": [
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=model, corpus=document_terms, texts=documents)\n",
        "\n",
        "# apply the above function to find dominant topics in data\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "# get 10 random samples\n",
        "df_dominant_topic.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3442</th>\n",
              "      <td>3442</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.5111</td>\n",
              "      <td>love, plai, girl, role, great, good, year, com...</td>\n",
              "      <td>[cherri, tell, naiv, unmarri, virgin, decid, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20717</th>\n",
              "      <td>20717</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.5832</td>\n",
              "      <td>bad, good, time, think, act, peopl, thing, loo...</td>\n",
              "      <td>[nightmar, sensat, feel, wake, nightmar, got, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>694</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.4335</td>\n",
              "      <td>mummi, ranger, gai, gold, heist, mexican, east...</td>\n",
              "      <td>[year, prison, toni, stéphanoi, jean, servai, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12163</th>\n",
              "      <td>12163</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.4267</td>\n",
              "      <td>love, plai, girl, role, great, good, year, com...</td>\n",
              "      <td>[extrem, delight, bias, suppos, happen, ador, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3506</th>\n",
              "      <td>3506</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.3495</td>\n",
              "      <td>bad, good, time, think, act, peopl, thing, loo...</td>\n",
              "      <td>[year, old, releas, year, later, qualm, hire, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6488</th>\n",
              "      <td>6488</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.9067</td>\n",
              "      <td>bad, good, time, think, act, peopl, thing, loo...</td>\n",
              "      <td>[turn, better, expect, part, pretti, funni, ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2088</th>\n",
              "      <td>2088</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.4694</td>\n",
              "      <td>life, charact, peopl, stori, live, man, world,...</td>\n",
              "      <td>[lot, dialogu, flat, goofi, add, machin, daili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10109</th>\n",
              "      <td>10109</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>love, plai, girl, role, great, good, year, com...</td>\n",
              "      <td>[great, new, avail, dvd, http, treasureflix, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1113</th>\n",
              "      <td>1113</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.3132</td>\n",
              "      <td>charact, stori, good, time, great, actor, act,...</td>\n",
              "      <td>[battleship, potemkin, said, favourit, charli,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2326</th>\n",
              "      <td>2326</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.3829</td>\n",
              "      <td>charact, stori, good, time, great, actor, act,...</td>\n",
              "      <td>[despit, titl, unlik, stori, love, war, isn, s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Document_No  ...                                               Text\n",
              "3442          3442  ...  [cherri, tell, naiv, unmarri, virgin, decid, b...\n",
              "20717        20717  ...  [nightmar, sensat, feel, wake, nightmar, got, ...\n",
              "694            694  ...  [year, prison, toni, stéphanoi, jean, servai, ...\n",
              "12163        12163  ...  [extrem, delight, bias, suppos, happen, ador, ...\n",
              "3506          3506  ...  [year, old, releas, year, later, qualm, hire, ...\n",
              "6488          6488  ...  [turn, better, expect, part, pretti, funni, ni...\n",
              "2088          2088  ...  [lot, dialogu, flat, goofi, add, machin, daili...\n",
              "10109        10109  ...  [great, new, avail, dvd, http, treasureflix, c...\n",
              "1113          1113  ...  [battleship, potemkin, said, favourit, charli,...\n",
              "2326          2326  ...  [despit, titl, unlik, stori, love, war, isn, s...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-doPxCEkPbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "90dd236c-6627-44d4-8cb4-d8715881e132"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(model, document_terms, dictionary)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1231407110429191846966539470\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1231407110429191846966539470_data = {\"mdsDat\": {\"x\": [-0.2879057314479191, -0.2598126764505448, -0.23651767248675487, -0.19809194679755152, -0.17662759281082074, -0.13562606768941535, 0.06633607612842955, 0.0751466439354839, 0.044114912921320616, 0.1398437362475478, 0.1786281264973778, 0.1878190380213718, 0.19920321967734586, 0.19391960320498025, 0.2095703310491476], \"y\": [0.008558419500870468, -0.017220438452116876, 0.028063720412006957, 0.06053048961334013, 0.06855646836686731, -0.10151077123244062, -0.09175425149981255, 0.131353763668719, -0.127252649970523, -0.15721122340429536, 0.00335663725362777, 0.2269764222176642, -0.07522583239834144, -0.09993187371678222, 0.14271111964121627], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [21.18174934387207, 17.099565505981445, 14.942209243774414, 13.44411563873291, 8.870416641235352, 8.538269996643066, 2.613550901412964, 2.5528929233551025, 2.2762601375579834, 1.680173397064209, 1.4415481090545654, 1.4088529348373413, 1.3797656297683716, 1.2893418073654175, 1.281285285949707]}, \"tinfo\": {\"Term\": [\"music\", \"bad\", \"plai\", \"love\", \"war\", \"stori\", \"good\", \"horror\", \"game\", \"charact\", \"song\", \"star\", \"kill\", \"action\", \"role\", \"great\", \"american\", \"life\", \"perform\", \"fight\", \"act\", \"actor\", \"funni\", \"comedi\", \"man\", \"episod\", \"plot\", \"girl\", \"think\", \"peopl\", \"crappi\", \"seagal\", \"kinda\", \"wanna\", \"barnei\", \"ghouli\", \"whine\", \"shelf\", \"lowest\", \"killjoi\", \"zoei\", \"anywai\", \"travolta\", \"immatur\", \"turd\", \"cheerlead\", \"vinni\", \"dumbest\", \"stupidest\", \"stoner\", \"chore\", \"dae\", \"klein\", \"rhy\", \"hartnett\", \"kutcher\", \"shriek\", \"haircut\", \"pleasanc\", \"likeabl\", \"worst\", \"garbag\", \"stupid\", \"crap\", \"min\", \"wast\", \"horribl\", \"rent\", \"laugh\", \"suck\", \"yeah\", \"sorri\", \"bad\", \"aw\", \"terribl\", \"funni\", \"wors\", \"joke\", \"pathet\", \"mayb\", \"wow\", \"think\", \"couldn\", \"monei\", \"got\", \"wasn\", \"dumb\", \"bore\", \"annoi\", \"gui\", \"kid\", \"know\", \"peopl\", \"thing\", \"seen\", \"act\", \"good\", \"want\", \"time\", \"better\", \"look\", \"thought\", \"actual\", \"minut\", \"go\", \"charact\", \"end\", \"wai\", \"actor\", \"plot\", \"make\", \"mstk\", \"oldboi\", \"cobb\", \"talentless\", \"firth\", \"portman\", \"zeta\", \"styliz\", \"chappel\", \"jodi\", \"campfir\", \"softcor\", \"overshadow\", \"midget\", \"cheaper\", \"remad\", \"arni\", \"inuyasha\", \"surrealist\", \"crichton\", \"forman\", \"anatomi\", \"romania\", \"hamper\", \"blurb\", \"slower\", \"druid\", \"soultak\", \"newton\", \"awkwardli\", \"altman\", \"grudg\", \"book\", \"adapt\", \"excel\", \"version\", \"stori\", \"cinematographi\", \"origin\", \"pace\", \"novel\", \"photographi\", \"charact\", \"great\", \"depth\", \"disappoint\", \"conrad\", \"perform\", \"product\", \"direct\", \"actor\", \"visual\", \"cast\", \"lack\", \"sceneri\", \"edit\", \"action\", \"element\", \"director\", \"best\", \"interest\", \"work\", \"good\", \"plot\", \"act\", \"script\", \"fan\", \"better\", \"time\", \"set\", \"seri\", \"screen\", \"feel\", \"role\", \"end\", \"seen\", \"wai\", \"look\", \"plai\", \"love\", \"make\", \"littl\", \"religion\", \"nero\", \"caligula\", \"cathol\", \"notion\", \"spiritu\", \"aesthet\", \"behaviour\", \"beethoven\", \"portrait\", \"herzog\", \"gulliv\", \"guilt\", \"distort\", \"disabl\", \"factual\", \"constitut\", \"dant\", \"fujimori\", \"darwin\", \"debbi\", \"goya\", \"cope\", \"jefferson\", \"drake\", \"cosmo\", \"viewpoint\", \"perceiv\", \"muslim\", \"lampoon\", \"racism\", \"philosophi\", \"societi\", \"religi\", \"social\", \"christian\", \"abus\", \"intellectu\", \"messag\", \"documentari\", \"cultur\", \"condit\", \"subject\", \"issu\", \"moral\", \"behavior\", \"life\", \"depict\", \"symbol\", \"sexual\", \"self\", \"human\", \"consequ\", \"suicid\", \"world\", \"individu\", \"discuss\", \"live\", \"experi\", \"emot\", \"realiti\", \"portrai\", \"present\", \"truth\", \"relationship\", \"power\", \"viewer\", \"imag\", \"person\", \"man\", \"peopl\", \"natur\", \"point\", \"audienc\", \"feel\", \"charact\", \"view\", \"famili\", \"stori\", \"wai\", \"real\", \"young\", \"woman\", \"director\", \"make\", \"love\", \"work\", \"come\", \"time\", \"end\", \"fact\", \"year\", \"know\", \"want\", \"gore\", \"zombi\", \"slasher\", \"predat\", \"gori\", \"halloween\", \"scarecrow\", \"blair\", \"corps\", \"cannib\", \"critter\", \"biker\", \"gruesom\", \"knife\", \"viru\", \"chupacabra\", \"splatter\", \"voodoo\", \"exorcist\", \"fulci\", \"paranorm\", \"argento\", \"hostag\", \"killer\", \"psychic\", \"psychopath\", \"trashi\", \"infect\", \"robocop\", \"resurrect\", \"horror\", \"witch\", \"blood\", \"demon\", \"massacr\", \"fbi\", \"puppet\", \"kill\", \"ghost\", \"bloodi\", \"satan\", \"murder\", \"creepi\", \"alien\", \"creatur\", \"cop\", \"dead\", \"evil\", \"monster\", \"bodi\", \"victim\", \"snake\", \"polic\", \"scare\", \"death\", \"hous\", \"violenc\", \"flick\", \"effect\", \"scari\", \"look\", \"run\", \"man\", \"get\", \"budget\", \"plot\", \"end\", \"head\", \"pretti\", \"gui\", \"turn\", \"bad\", \"start\", \"thing\", \"girl\", \"come\", \"set\", \"nuclear\", \"bush\", \"conspiraci\", \"lifeless\", \"kurtz\", \"bean\", \"ski\", \"apocalyps\", \"tarzan\", \"hacknei\", \"futurist\", \"carli\", \"rocket\", \"mumbl\", \"rhyme\", \"bearabl\", \"puke\", \"excruci\", \"decapit\", \"dien\", \"disconnect\", \"slot\", \"satellit\", \"marathon\", \"hmmm\", \"can\", \"bunni\", \"coppola\", \"bug\", \"subwai\", \"jungl\", \"episod\", \"space\", \"broadcast\", \"ship\", \"cartoon\", \"terrorist\", \"season\", \"duck\", \"engin\", \"programm\", \"helicopt\", \"scienc\", \"sheen\", \"fonda\", \"planet\", \"flight\", \"air\", \"plane\", \"network\", \"program\", \"crew\", \"race\", \"anim\", \"seri\", \"footag\", \"station\", \"earth\", \"televis\", \"new\", \"unfunni\", \"gag\", \"travel\", \"produc\", \"car\", \"world\", \"time\", \"show\", \"run\", \"dai\", \"year\", \"set\", \"shot\", \"short\", \"us\", \"hour\", \"american\", \"minut\", \"later\", \"work\", \"take\", \"come\", \"billi\", \"shirlei\", \"hitch\", \"bollywood\", \"susan\", \"reynold\", \"sara\", \"quaid\", \"gere\", \"boll\", \"snowbal\", \"lorenzo\", \"ator\", \"liar\", \"crystal\", \"hindi\", \"meg\", \"ellen\", \"segal\", \"govinda\", \"warden\", \"salman\", \"sandler\", \"affleck\", \"carel\", \"dori\", \"juan\", \"nikki\", \"beverli\", \"sarandon\", \"patricia\", \"amateurish\", \"martha\", \"owen\", \"karen\", \"brook\", \"marri\", \"husband\", \"bruno\", \"father\", \"wife\", \"son\", \"mother\", \"hitchcock\", \"daughter\", \"dean\", \"walker\", \"love\", \"lane\", \"romant\", \"famili\", \"christma\", \"parent\", \"plai\", \"girl\", \"comedi\", \"role\", \"young\", \"meet\", \"sister\", \"actress\", \"uncl\", \"friend\", \"boi\", \"woman\", \"home\", \"year\", \"perform\", \"man\", \"great\", \"best\", \"old\", \"cast\", \"get\", \"good\", \"life\", \"new\", \"come\", \"time\", \"stori\", \"ford\", \"rourk\", \"scarlett\", \"conneri\", \"rhett\", \"noah\", \"wagon\", \"stanwyck\", \"gabl\", \"hamilton\", \"mormon\", \"harrison\", \"bishop\", \"carei\", \"garfield\", \"timothi\", \"garbo\", \"ponyo\", \"columbo\", \"tart\", \"pepe\", \"bloat\", \"unexcit\", \"erica\", \"kidnapp\", \"missionari\", \"lumber\", \"teddi\", \"phoeb\", \"foxx\", \"wayn\", \"marion\", \"bond\", \"rai\", \"cowboi\", \"charl\", \"franci\", \"hors\", \"western\", \"evan\", \"taylor\", \"johnson\", \"anna\", \"lloyd\", \"hay\", \"sean\", \"john\", \"moor\", \"jame\", \"cooper\", \"joe\", \"role\", \"plai\", \"west\", \"star\", \"earli\", \"harri\", \"roger\", \"appear\", \"cast\", \"wind\", \"pictur\", \"big\", \"young\", \"lead\", \"soldier\", \"german\", \"russian\", \"bronson\", \"hitler\", \"germani\", \"wwii\", \"soviet\", \"bergman\", \"corn\", \"almighti\", \"pacino\", \"demi\", \"harvest\", \"eater\", \"bori\", \"wallac\", \"dam\", \"vera\", \"doo\", \"it\\u00b4\", \"traitor\", \"shylock\", \"bloke\", \"raptor\", \"rommel\", \"sander\", \"karloff\", \"lizzi\", \"liz\", \"russia\", \"war\", \"nazi\", \"chaplin\", \"patriot\", \"australian\", \"communist\", \"french\", \"armi\", \"hudson\", \"propaganda\", \"american\", \"militari\", \"battl\", \"civil\", \"japanes\", \"english\", \"anti\", \"countri\", \"british\", \"franc\", \"accent\", \"enemi\", \"histor\", \"histori\", \"charli\", \"fight\", \"speak\", \"men\", \"world\", \"anderson\", \"stan\", \"laurel\", \"lyric\", \"baldwin\", \"ernest\", \"rome\", \"braff\", \"hamlet\", \"concert\", \"album\", \"blatantli\", \"venu\", \"traci\", \"juri\", \"pornographi\", \"marx\", \"leland\", \"weed\", \"caller\", \"romanian\", \"armageddon\", \"knowl\", \"punchlin\", \"hayworth\", \"jacobi\", \"duh\", \"claudiu\", \"dunno\", \"pola\", \"sing\", \"band\", \"hardi\", \"song\", \"singer\", \"rita\", \"danc\", \"broadwai\", \"music\", \"guitar\", \"dancer\", \"rock\", \"radio\", \"number\", \"stone\", \"record\", \"soundtrack\", \"voic\", \"sound\", \"lynch\", \"stage\", \"video\", \"listen\", \"perform\", \"hear\", \"plai\", \"year\", \"version\", \"star\", \"dvd\", \"releas\", \"blah\", \"austen\", \"catherin\", \"murphi\", \"erika\", \"mencia\", \"damm\", \"stoog\", \"vinc\", \"redford\", \"marlow\", \"vampir\", \"colin\", \"hepburn\", \"aaron\", \"kai\", \"madsen\", \"niro\", \"lonesom\", \"wwe\", \"sant\", \"dove\", \"wrestler\", \"underdevelop\", \"miranda\", \"sissi\", \"fanni\", \"bennett\", \"pub\", \"darci\", \"werewolf\", \"wrestl\", \"gu\", \"chan\", \"van\", \"jane\", \"jonathan\", \"juli\", \"match\", \"ann\", \"julia\", \"wilson\", \"michael\", \"robert\", \"voic\", \"andrew\", \"cat\", \"jackson\", \"plai\", \"jean\", \"novel\", \"version\", \"lee\", \"tom\", \"mari\", \"park\", \"love\", \"coach\", \"mason\", \"myer\", \"cobra\", \"bikini\", \"turkish\", \"wynorski\", \"flynn\", \"ibm\", \"hogan\", \"belushi\", \"perri\", \"fort\", \"carson\", \"nbc\", \"hockei\", \"custer\", \"skateboard\", \"spade\", \"afghanistan\", \"marti\", \"dung\", \"roach\", \"soccer\", \"payton\", \"bradlei\", \"amir\", \"lamest\", \"sheep\", \"straw\", \"missil\", \"tommi\", \"team\", \"dan\", \"kennedi\", \"vega\", \"footbal\", \"jason\", \"david\", \"match\", \"sport\", \"bobbi\", \"turkei\", \"pilot\", \"win\", \"airport\", \"georg\", \"randi\", \"fly\", \"plai\", \"tom\", \"michael\", \"game\", \"robot\", \"cave\", \"ninja\", \"dracula\", \"dinosaur\", \"frankenstein\", \"glen\", \"lugosi\", \"skeleton\", \"muddl\", \"conan\", \"gorilla\", \"muppet\", \"costello\", \"ark\", \"gargoyl\", \"bela\", \"komodo\", \"sinatra\", \"carrot\", \"stuf\", \"volcano\", \"manti\", \"busei\", \"chanei\", \"kermit\", \"abbott\", \"carnosaur\", \"aeon\", \"wolf\", \"holli\", \"monkei\", \"giant\", \"pirat\", \"monster\", \"aztec\", \"island\", \"plai\", \"player\", \"scientist\", \"fight\", \"man\", \"frank\", \"star\", \"mummi\", \"heist\", \"eastwood\", \"concord\", \"bin\", \"clint\", \"incomprehens\", \"swayz\", \"boom\", \"patterson\", \"dillon\", \"dylan\", \"senseless\", \"dismal\", \"grier\", \"isra\", \"edison\", \"pam\", \"fuller\", \"leon\", \"jacquelin\", \"chipmunk\", \"veronica\", \"malkovich\", \"stripper\", \"potter\", \"schaech\", \"architect\", \"melvil\", \"kahn\", \"ranger\", \"spaghetti\", \"bandit\", \"carlo\", \"pimp\", \"mexican\", \"gold\", \"howard\", \"basebal\", \"ic\", \"gai\", \"lone\", \"cain\", \"western\", \"georg\", \"plai\", \"babi\", \"agent\", \"robin\", \"gein\", \"troma\", \"mose\", \"lestat\", \"glenda\", \"montgomeri\", \"pitt\", \"bam\", \"dunn\", \"conroi\", \"egyptian\", \"reba\", \"spacei\", \"jackass\", \"mash\", \"shearer\", \"madonna\", \"troll\", \"sherlock\", \"cheapest\", \"trivialbor\", \"ineptitud\", \"nielsen\", \"juliet\", \"wayan\", \"levi\", \"eastend\", \"leguizamo\", \"egypt\", \"gibson\", \"holm\", \"carmen\", \"topless\", \"olivi\", \"norma\", \"lewi\", \"hood\", \"jerri\", \"mel\", \"hospit\", \"queen\", \"scott\", \"king\", \"patient\", \"plai\", \"comedi\", \"ryan\", \"robert\", \"william\", \"comic\", \"willi\", \"sandra\", \"frost\", \"bullock\", \"kung\", \"batman\", \"chess\", \"snipe\", \"octopu\", \"kasparov\", \"ricci\", \"kirk\", \"robbin\", \"manson\", \"penguin\", \"spock\", \"weslei\", \"superhero\", \"tan\", \"orthodox\", \"witless\", \"lil\", \"goon\", \"akshai\", \"jackal\", \"schneider\", \"saudi\", \"crummi\", \"mclaren\", \"numbingli\", \"campbel\", \"bruce\", \"martial\", \"christina\", \"trek\", \"shatner\", \"pete\", \"murrai\", \"snowman\", \"jacki\", \"wine\", \"jack\", \"fight\", \"tim\", \"burton\", \"max\", \"sword\", \"star\", \"disnei\", \"action\", \"villain\", \"art\", \"return\", \"blade\", \"comic\", \"cartoon\", \"hero\"], \"Freq\": [3895.0, 10253.0, 8340.0, 7775.0, 2239.0, 12224.0, 13867.0, 3440.0, 1558.0, 14735.0, 1746.0, 4046.0, 3865.0, 3475.0, 4034.0, 7164.0, 2634.0, 5808.0, 4920.0, 1829.0, 8998.0, 7050.0, 3805.0, 3360.0, 5773.0, 1953.0, 7254.0, 3794.0, 7793.0, 8301.0, 351.0914001464844, 333.93389892578125, 192.3984375, 147.7987823486328, 137.31533813476562, 121.67062377929688, 115.6533432006836, 108.64588928222656, 102.1820297241211, 99.2181167602539, 92.67801666259766, 92.16307067871094, 83.97164916992188, 81.04389953613281, 77.40298461914062, 72.44867706298828, 65.9851303100586, 61.64517593383789, 59.855064392089844, 58.951045989990234, 52.723758697509766, 51.309696197509766, 50.688106536865234, 47.6082649230957, 44.08179473876953, 42.666873931884766, 41.20682907104492, 39.74774169921875, 39.387420654296875, 39.067039489746094, 2962.658203125, 576.146484375, 2124.371337890625, 1159.8668212890625, 191.27957153320312, 2420.43017578125, 1642.789794921875, 1225.866943359375, 2538.63916015625, 879.1578369140625, 520.9238891601562, 833.3628540039062, 8570.1240234375, 1912.7857666015625, 1946.94677734375, 3046.1708984375, 1421.0277099609375, 1402.924072265625, 564.9124755859375, 1822.2269287109375, 344.8592529296875, 5418.24951171875, 1276.58203125, 1727.9642333984375, 2276.628662109375, 1611.9345703125, 615.3253784179688, 2124.6201171875, 989.001708984375, 3084.06298828125, 1925.8038330078125, 4089.4091796875, 4671.77587890625, 4534.455078125, 3538.0869140625, 4868.80517578125, 6818.32861328125, 3494.3291015625, 6154.95947265625, 3151.35205078125, 4200.94287109375, 2224.879150390625, 2657.550048828125, 2270.707275390625, 2215.027587890625, 4172.009765625, 3293.44287109375, 3045.619384765625, 2809.464111328125, 2773.125732421875, 2318.728759765625, 259.1412658691406, 100.42874145507812, 124.11617279052734, 85.08338928222656, 80.67790985107422, 76.03903198242188, 75.77909088134766, 75.35918426513672, 72.33099365234375, 61.1589241027832, 60.53155517578125, 59.385108947753906, 57.42925262451172, 54.743919372558594, 54.37902069091797, 54.26079559326172, 53.82046890258789, 52.888763427734375, 50.14592361450195, 49.564640045166016, 49.521766662597656, 48.858741760253906, 48.82447052001953, 48.40408706665039, 48.35470962524414, 43.75763702392578, 43.692779541015625, 43.56119155883789, 43.284889221191406, 42.63481521606445, 112.9405746459961, 172.63145446777344, 2814.740478515625, 707.8218383789062, 1123.94970703125, 1647.75439453125, 7101.80126953125, 708.5191650390625, 2394.902099609375, 811.8251342773438, 792.0228881835938, 340.96051025390625, 7251.1435546875, 3851.309326171875, 474.3820495605469, 1352.791748046875, 127.9340591430664, 2640.98828125, 1517.0172119140625, 2162.190673828125, 3528.987060546875, 612.7508544921875, 2299.494873046875, 1291.8707275390625, 353.0296936035156, 822.2196655273438, 1736.8623046875, 655.7780151367188, 2452.83984375, 2334.597412109375, 1899.1600341796875, 2794.550048828125, 4741.8564453125, 2831.2265625, 3088.8642578125, 1622.933837890625, 1432.308349609375, 2202.938232421875, 4082.0634765625, 1613.966064453125, 1310.062255859375, 1352.1563720703125, 1721.1904296875, 1572.40576171875, 2216.007080078125, 1819.7681884765625, 1892.5802001953125, 1912.3851318359375, 1778.8883056640625, 1723.2283935546875, 1650.1588134765625, 1631.5667724609375, 223.56161499023438, 202.7929229736328, 147.16453552246094, 143.04884338378906, 134.4422607421875, 133.03587341308594, 120.83354949951172, 119.81116485595703, 116.35411071777344, 114.96342468261719, 107.94181060791016, 106.65242004394531, 106.39519500732422, 100.89295959472656, 99.29339599609375, 98.45336151123047, 97.54283142089844, 94.09614562988281, 93.888427734375, 93.6089096069336, 91.63444519042969, 91.53068542480469, 91.43755340576172, 90.96954345703125, 90.0118179321289, 88.13452911376953, 80.63786315917969, 80.62640380859375, 79.3034896850586, 78.0953369140625, 238.0494384765625, 132.3727569580078, 620.5140380859375, 362.6576232910156, 462.6632995605469, 498.4068908691406, 368.75213623046875, 269.03741455078125, 727.6863403320312, 816.7597045898438, 616.4379272460938, 246.53604125976562, 839.5040893554688, 615.3591918945312, 483.7517395019531, 264.23480224609375, 3353.618896484375, 516.7227172851562, 311.7892150878906, 705.6287841796875, 788.1182250976562, 1255.2318115234375, 211.11863708496094, 361.3835144042969, 1749.8421630859375, 283.1841125488281, 296.3441162109375, 1899.193359375, 875.8511352539062, 847.2097778320312, 604.2803344726562, 737.9110717773438, 793.4976196289062, 484.4868469238281, 744.3556518554688, 841.2888793945312, 965.4884643554688, 529.5106201171875, 1247.0235595703125, 1855.5556640625, 2330.099365234375, 670.8549194335938, 1361.619873046875, 1051.3990478515625, 1403.1407470703125, 2346.2822265625, 887.787353515625, 1019.4131469726562, 2072.74853515625, 1671.22607421875, 1260.216796875, 1068.1600341796875, 998.6290893554688, 1217.9248046875, 1294.912109375, 1318.978515625, 1185.8853759765625, 1159.4322509765625, 1379.52783203125, 1231.489501953125, 983.3842163085938, 974.7007446289062, 951.6817016601562, 882.913330078125, 1019.8218994140625, 968.2992553710938, 494.509033203125, 343.6226806640625, 245.58078002929688, 233.8848876953125, 230.09877014160156, 191.82591247558594, 186.1546173095703, 184.6798095703125, 182.5373992919922, 164.083251953125, 160.0498504638672, 154.72727966308594, 140.6735076904297, 137.804443359375, 129.53857421875, 128.0945281982422, 122.75599670410156, 122.57998657226562, 121.95378875732422, 113.85576629638672, 111.78094482421875, 1376.05908203125, 110.14070129394531, 107.38375854492188, 106.79151916503906, 102.28776550292969, 98.26860809326172, 95.60011291503906, 3394.002197265625, 319.1153564453125, 1005.7056884765625, 447.38531494140625, 251.60342407226562, 168.3928680419922, 293.1677551269531, 3201.1142578125, 470.9320373535156, 280.1838073730469, 219.22622680664062, 1408.591064453125, 417.4832458496094, 861.16064453125, 554.3400268554688, 790.9074096679688, 1266.7999267578125, 931.087646484375, 955.8475341796875, 899.6975708007812, 614.5428466796875, 441.50445556640625, 694.3248291015625, 460.945556640625, 1024.4298095703125, 961.0265502929688, 613.7694702148438, 824.75, 1384.674072265625, 548.1103515625, 2264.094482421875, 992.685546875, 1453.9112548828125, 1277.814697265625, 886.6819458007812, 1510.370849609375, 1565.277099609375, 822.7225952148438, 1012.5859985351562, 1126.6365966796875, 977.2808227539062, 1362.2322998046875, 1000.5319213867188, 1155.9549560546875, 938.4685668945312, 1007.9642944335938, 881.4613647460938, 191.36029052734375, 171.53482055664062, 141.62344360351562, 113.25455474853516, 112.87516784667969, 108.37166595458984, 100.30615997314453, 98.9075698852539, 97.53142547607422, 94.72319793701172, 94.39894104003906, 93.77191162109375, 91.91748046875, 74.14317321777344, 70.44959259033203, 70.31904602050781, 69.85263061523438, 68.56904602050781, 68.32015991210938, 67.71036529541016, 66.31663513183594, 65.96634674072266, 65.79438018798828, 64.61480712890625, 63.397056579589844, 62.13838577270508, 61.02594757080078, 59.81659698486328, 215.78224182128906, 58.64041519165039, 306.13189697265625, 1748.8375244140625, 873.041259765625, 124.22431945800781, 490.7479553222656, 561.2670288085938, 199.60845947265625, 494.9742736816406, 109.46966552734375, 170.17294311523438, 124.5228271484375, 128.6820526123047, 468.7445068359375, 114.41817474365234, 130.95779418945312, 304.0722351074219, 170.96170043945312, 593.4927978515625, 399.64208984375, 227.30393981933594, 273.2509765625, 498.8892517089844, 367.8521728515625, 842.0111083984375, 1202.356201171875, 456.340087890625, 277.7265319824219, 464.01702880859375, 433.20208740234375, 1246.69970703125, 263.9914245605469, 270.4142150878906, 336.85638427734375, 654.1390991210938, 500.3759460449219, 762.5809326171875, 1509.2568359375, 703.5076293945312, 622.0977172851562, 704.2547607421875, 820.0315551757812, 665.2313842773438, 587.0601196289062, 500.3699035644531, 515.9213256835938, 488.1163330078125, 489.5625, 528.5582275390625, 457.657470703125, 494.2926025390625, 462.3181457519531, 458.9264831542969, 394.4007873535156, 237.84642028808594, 224.54148864746094, 174.42039489746094, 158.07470703125, 155.0350799560547, 154.58447265625, 150.3357696533203, 146.72415161132812, 139.6090850830078, 121.44097900390625, 114.9041976928711, 112.97683715820312, 107.40652465820312, 105.18865966796875, 102.86193084716797, 98.57251739501953, 96.64228820800781, 94.85704040527344, 94.6875228881836, 94.3910140991211, 93.57354736328125, 90.96439361572266, 85.87986755371094, 83.07495880126953, 80.7817153930664, 76.34098815917969, 75.52484130859375, 73.55455017089844, 69.71733856201172, 87.90557098388672, 379.90618896484375, 143.53355407714844, 135.81332397460938, 197.54689025878906, 216.50535583496094, 640.6030883789062, 813.5808715820312, 129.42323303222656, 1257.8056640625, 1232.0697021484375, 927.5357055664062, 1032.4146728515625, 353.30133056640625, 799.1063232421875, 204.96311950683594, 180.7998504638672, 3044.638916015625, 213.53807067871094, 510.6640930175781, 1299.389892578125, 284.5071716308594, 561.0875244140625, 2678.8330078125, 1502.9609375, 1325.2154541015625, 1449.721435546875, 1184.5250244140625, 675.6456909179688, 517.9967651367188, 664.908935546875, 238.87564086914062, 1015.996826171875, 836.6019897460938, 915.9423217773438, 698.9403686523438, 1335.81591796875, 1160.9869384765625, 1252.21630859375, 1364.0692138671875, 1111.6214599609375, 972.46923828125, 989.3494262695312, 986.074951171875, 1361.68505859375, 937.41357421875, 841.42529296875, 925.9502563476562, 1032.4222412109375, 973.5205078125, 261.696533203125, 205.06011962890625, 180.66827392578125, 150.44622802734375, 135.11431884765625, 127.5580062866211, 120.55729675292969, 114.60611724853516, 107.4426498413086, 104.84197235107422, 100.35498809814453, 98.81014251708984, 86.8243179321289, 73.1889877319336, 72.10396575927734, 68.21895599365234, 68.15924072265625, 67.28527069091797, 65.55208587646484, 62.011207580566406, 60.85380172729492, 59.34627914428711, 58.670143127441406, 56.65821838378906, 56.51373291015625, 54.52260971069336, 54.43313980102539, 54.34169387817383, 54.23277282714844, 51.716087341308594, 326.5130615234375, 84.63549041748047, 400.14825439453125, 384.3324890136719, 195.26953125, 353.7472839355469, 83.16639709472656, 332.49774169921875, 535.6126708984375, 170.3515167236328, 168.9529571533203, 176.4481201171875, 168.81011962890625, 133.82083129882812, 90.49394226074219, 169.4832763671875, 591.5767211914062, 209.12669372558594, 333.2089538574219, 107.62731170654297, 190.10531616210938, 450.5169372558594, 579.9463500976562, 162.47262573242188, 348.8148193359375, 235.4215545654297, 169.5861358642578, 148.03993225097656, 208.7606964111328, 218.8098602294922, 155.3992156982422, 190.6182098388672, 197.883544921875, 188.25729370117188, 181.35682678222656, 812.3915405273438, 754.0501708984375, 505.8699035644531, 190.1126251220703, 185.68572998046875, 185.51211547851562, 170.88555908203125, 141.5904998779297, 129.32562255859375, 127.92990112304688, 119.00858306884766, 111.50941467285156, 105.96077728271484, 102.43805694580078, 93.98165893554688, 89.62350463867188, 86.41317749023438, 84.57545471191406, 78.2791748046875, 73.81346130371094, 67.90452575683594, 67.01876068115234, 65.76971435546875, 65.33149719238281, 61.98848342895508, 61.94289779663086, 60.117469787597656, 58.60319519042969, 56.86229705810547, 56.308109283447266, 155.79103088378906, 1823.966796875, 294.10540771484375, 179.86253356933594, 129.7521514892578, 195.73170471191406, 94.32530212402344, 409.14373779296875, 261.7164306640625, 134.4425506591797, 176.50143432617188, 788.5232543945312, 236.62539672851562, 291.915771484375, 181.46783447265625, 248.08389282226562, 326.5244140625, 232.24705505371094, 307.5986022949219, 272.84539794921875, 166.09124755859375, 244.38856506347656, 166.31288146972656, 200.84857177734375, 228.23214721679688, 161.06076049804688, 194.77926635742188, 175.2362823486328, 174.98731994628906, 173.69908142089844, 173.20957946777344, 170.79812622070312, 167.63783264160156, 157.92013549804688, 133.7176971435547, 125.86188507080078, 120.32642364501953, 105.94315338134766, 101.20368957519531, 158.93145751953125, 95.04730987548828, 94.29926300048828, 91.2956771850586, 90.7706298828125, 83.06107330322266, 81.76376342773438, 79.17227935791016, 67.32154083251953, 66.45730590820312, 66.40153503417969, 65.13813781738281, 64.58174896240234, 61.38136291503906, 60.60395812988281, 59.675132751464844, 58.194435119628906, 57.80678939819336, 56.37164306640625, 56.06498336791992, 55.422142028808594, 805.4509887695312, 536.5357666015625, 184.41021728515625, 1520.960693359375, 294.588623046875, 97.35630798339844, 919.2217407226562, 159.0734405517578, 2111.96337890625, 94.8257827758789, 184.85903930664062, 405.18377685546875, 208.27207946777344, 352.6396179199219, 177.51275634765625, 211.40235900878906, 238.32421875, 304.63616943359375, 355.8672180175781, 129.24954223632812, 213.73065185546875, 284.49169921875, 179.39645385742188, 301.40057373046875, 181.34103393554688, 294.8775329589844, 263.6516418457031, 202.9112548828125, 214.48825073242188, 185.44265747070312, 170.08277893066406, 218.34490966796875, 207.45425415039062, 191.1589813232422, 177.09341430664062, 156.80519104003906, 149.9593048095703, 141.97361755371094, 140.2788848876953, 108.91374206542969, 101.85247039794922, 99.79191589355469, 811.0069580078125, 91.05989074707031, 87.24144744873047, 84.57149505615234, 84.00282287597656, 83.53276824951172, 83.22801971435547, 77.40737915039062, 74.25723266601562, 73.20645141601562, 71.44661712646484, 70.31061553955078, 69.56044006347656, 69.4754638671875, 69.20709228515625, 67.87841796875, 64.05594635009766, 63.48491287231445, 62.92471694946289, 165.90492248535156, 161.2600860595703, 96.9566879272461, 192.6991424560547, 302.8051452636719, 200.1368408203125, 112.10735321044922, 155.78965759277344, 220.46006774902344, 194.61819458007812, 115.9266128540039, 118.32353973388672, 231.91053771972656, 221.5163116455078, 222.0889129638672, 116.48339080810547, 145.75477600097656, 124.11378479003906, 303.87823486328125, 123.81487274169922, 158.82342529296875, 181.7665252685547, 130.2632598876953, 132.05520629882812, 122.02828979492188, 120.4352798461914, 120.61056518554688, 219.57818603515625, 158.19163513183594, 134.06683349609375, 130.246826171875, 122.38653564453125, 116.00304412841797, 114.89888763427734, 110.24147033691406, 106.38977813720703, 116.19239807128906, 83.0281982421875, 82.40715789794922, 78.60611724853516, 77.66339874267578, 77.5624771118164, 75.43885803222656, 75.13137817382812, 74.85501861572266, 71.77266693115234, 71.55093383789062, 69.88256072998047, 69.24118041992188, 61.35847091674805, 60.740478515625, 60.647064208984375, 59.3856086730957, 58.44189453125, 55.890281677246094, 54.725669860839844, 54.432926177978516, 113.55813598632812, 160.99273681640625, 420.1043395996094, 137.46206665039062, 139.3910369873047, 125.06336975097656, 143.79498291015625, 151.150146484375, 253.58200073242188, 195.60101318359375, 133.44549560546875, 107.60433197021484, 129.82704162597656, 123.75992584228516, 134.60031127929688, 98.49736022949219, 125.9312744140625, 93.07891082763672, 111.02539825439453, 153.0261688232422, 110.44717407226562, 109.03486633300781, 1557.806884765625, 354.12335205078125, 280.5859375, 246.00730895996094, 242.28309631347656, 225.03219604492188, 173.11598205566406, 145.93592834472656, 136.80979919433594, 128.15591430664062, 127.17550659179688, 121.45227813720703, 116.67379760742188, 106.24485778808594, 105.63550567626953, 100.69410705566406, 99.16925048828125, 98.6451644897461, 97.03734588623047, 90.45198822021484, 82.31977844238281, 76.78160095214844, 76.46488952636719, 70.69696044921875, 70.43742370605469, 70.32892608642578, 69.76214599609375, 68.44610595703125, 67.36656188964844, 66.41175842285156, 179.94432067871094, 86.25187683105469, 150.86160278320312, 246.6127166748047, 105.29048919677734, 310.5445251464844, 76.58616638183594, 210.141845703125, 414.6315002441406, 136.35350036621094, 133.4727783203125, 178.83966064453125, 164.9202880859375, 104.96394348144531, 110.19300842285156, 224.35733032226562, 176.0490264892578, 170.81036376953125, 150.60000610351562, 143.8372344970703, 134.88790893554688, 130.61843872070312, 101.76427459716797, 101.29481506347656, 97.6078109741211, 96.91738891601562, 94.82530975341797, 89.96504974365234, 84.06387329101562, 81.18326568603516, 76.26701354980469, 73.51904296875, 70.11211395263672, 67.38333892822266, 65.2649917602539, 64.52680206298828, 64.10296630859375, 62.54520797729492, 60.94535827636719, 59.750755310058594, 59.571815490722656, 59.54706954956055, 58.826541900634766, 58.719207763671875, 57.981224060058594, 205.92140197753906, 101.12252807617188, 83.1289291381836, 116.04698944091797, 125.01640319824219, 175.0066375732422, 181.4327850341797, 139.67942810058594, 84.33824157714844, 145.39573669433594, 201.3279266357422, 124.98235321044922, 100.13850402832031, 140.93930053710938, 127.56641387939453, 112.29429626464844, 88.6776351928711, 84.21295928955078, 246.28463745117188, 191.6415557861328, 131.08396911621094, 119.74893951416016, 119.61551666259766, 112.95143127441406, 111.84516143798828, 102.70494079589844, 95.85124969482422, 94.99324798583984, 88.3742446899414, 82.23629760742188, 81.1209945678711, 80.28764343261719, 78.45266723632812, 75.36122131347656, 73.26055908203125, 95.07643127441406, 60.277645111083984, 58.00914001464844, 57.27622985839844, 57.12131881713867, 56.4704475402832, 55.91257858276367, 55.50673294067383, 55.40157699584961, 54.72890853881836, 53.428741455078125, 53.047569274902344, 52.864078521728516, 77.86190032958984, 208.7768096923828, 123.103515625, 103.50680541992188, 65.50959777832031, 75.03297424316406, 221.89418029785156, 109.02005767822266, 147.4390106201172, 95.69732666015625, 145.68666076660156, 137.10531616210938, 136.73069763183594, 146.33798217773438, 102.49419403076172, 216.6283721923828, 136.4757843017578, 97.1360855102539, 113.64484405517578, 105.5724868774414, 102.4207763671875, 329.5369873046875, 174.19895935058594, 172.73678588867188, 169.0918731689453, 146.883544921875, 144.34170532226562, 115.31158447265625, 113.75464630126953, 108.6854476928711, 92.63265991210938, 91.95207977294922, 84.92739868164062, 82.11943817138672, 81.20516204833984, 73.99969482421875, 73.25354766845703, 71.02618408203125, 68.32449340820312, 66.00759887695312, 62.116241455078125, 58.20807647705078, 57.92850875854492, 54.74250793457031, 51.81608963012695, 50.99711990356445, 49.85813522338867, 49.21192169189453, 47.58836364746094, 47.57212829589844, 46.530967712402344, 94.58840942382812, 339.2745666503906, 252.15548706054688, 76.86585235595703, 193.71768188476562, 90.3943099975586, 93.50251770019531, 106.3556900024414, 83.91300201416016, 145.34771728515625, 132.12384033203125, 360.1805725097656, 461.9637145996094, 155.6688995361328, 85.6748275756836, 150.71934509277344, 111.55178833007812, 315.62689208984375, 138.84149169921875, 228.06613159179688, 150.5093536376953, 175.55853271484375, 136.58541870117188, 100.1615982055664, 119.51628875732422, 114.32698822021484, 100.43318176269531], \"Total\": [3895.0, 10253.0, 8340.0, 7775.0, 2239.0, 12224.0, 13867.0, 3440.0, 1558.0, 14735.0, 1746.0, 4046.0, 3865.0, 3475.0, 4034.0, 7164.0, 2634.0, 5808.0, 4920.0, 1829.0, 8998.0, 7050.0, 3805.0, 3360.0, 5773.0, 1953.0, 7254.0, 3794.0, 7793.0, 8301.0, 352.07550048828125, 334.9179992675781, 193.38259887695312, 148.78294372558594, 138.29949951171875, 122.6547622680664, 116.63748168945312, 109.63003540039062, 103.16616821289062, 100.20225524902344, 93.66215515136719, 93.14725494384766, 84.9557876586914, 82.02803802490234, 78.38712310791016, 73.43281555175781, 66.96927642822266, 62.62932205200195, 60.839210510253906, 59.9351921081543, 53.70790481567383, 52.29385757446289, 51.67224884033203, 48.59241485595703, 45.06593704223633, 43.65101623535156, 42.190975189208984, 40.73188781738281, 40.3715705871582, 40.0521240234375, 3089.542724609375, 596.4140014648438, 2237.231689453125, 1214.854248046875, 196.811767578125, 2638.180908203125, 1780.462646484375, 1334.822265625, 2847.12109375, 954.47412109375, 559.8653564453125, 913.6787109375, 10253.306640625, 2203.875, 2303.859619140625, 3805.667236328125, 1716.57275390625, 1697.7479248046875, 653.6151733398438, 2341.239990234375, 385.9479064941406, 7793.88671875, 1621.922119140625, 2262.643310546875, 3072.19384765625, 2142.4267578125, 736.4193725585938, 2966.156005859375, 1262.4498291015625, 4686.99462890625, 2854.456787109375, 7058.96875, 8301.712890625, 8019.6826171875, 6066.30078125, 8998.8857421875, 13867.0556640625, 6148.72119140625, 14770.71484375, 5951.421875, 10015.5986328125, 3609.17724609375, 4855.27490234375, 4048.814697265625, 3882.176513671875, 14735.8271484375, 9176.3984375, 7948.5703125, 7050.4951171875, 7254.28857421875, 6563.7646484375, 260.0999450683594, 101.387451171875, 125.33159637451172, 86.0421142578125, 81.63742065429688, 76.99774169921875, 76.73780059814453, 76.3178939819336, 73.28971862792969, 62.11764144897461, 61.49027633666992, 60.34382629394531, 58.387969970703125, 55.7026481628418, 55.33774185180664, 55.21950912475586, 54.77919006347656, 53.84748077392578, 51.10464096069336, 50.523353576660156, 50.4804801940918, 49.81745910644531, 49.78318786621094, 49.3628044128418, 49.313438415527344, 44.71635437011719, 44.65150451660156, 44.51990509033203, 44.24361038208008, 43.59353256225586, 116.69135284423828, 181.2198944091797, 3435.404541015625, 823.6964721679688, 1495.677490234375, 2352.40576171875, 12224.38671875, 955.5653076171875, 3835.20751953125, 1164.7064208984375, 1132.888427734375, 448.20587158203125, 14735.8271484375, 7164.87890625, 653.7300415039062, 2203.35791015625, 147.65235900878906, 4920.20166015625, 2584.019775390625, 3914.286865234375, 7050.4951171875, 917.777099609375, 4410.78564453125, 2264.305908203125, 488.7617492675781, 1365.785400390625, 3475.37353515625, 1053.73779296875, 5444.4853515625, 5120.068359375, 4001.099609375, 6791.36328125, 13867.0556640625, 7254.28857421875, 8998.8857421875, 3715.134765625, 3130.9072265625, 5951.421875, 14770.71484375, 3901.964111328125, 2777.3671875, 2963.724365234375, 4748.759765625, 4034.76220703125, 9176.3984375, 6066.30078125, 7948.5703125, 10015.5986328125, 8340.3544921875, 7775.14111328125, 6563.7646484375, 5788.24365234375, 224.51983642578125, 203.7511444091797, 148.1227569580078, 144.00706481933594, 135.40048217773438, 133.9940948486328, 121.79197692871094, 120.76934814453125, 117.31229400634766, 115.9216079711914, 108.91023254394531, 107.61060333251953, 107.35525512695312, 101.85114288330078, 100.25157928466797, 99.41154479980469, 98.50102233886719, 95.05433654785156, 94.84661102294922, 94.56709289550781, 92.59263610839844, 92.4888687133789, 92.39573669433594, 91.92772674560547, 90.97001647949219, 89.09272003173828, 81.5960464477539, 81.58458709716797, 80.26167297363281, 79.05352783203125, 245.4691619873047, 135.2875213623047, 656.611572265625, 379.54827880859375, 494.10565185546875, 544.690185546875, 401.3322448730469, 293.1327209472656, 863.5623168945312, 1005.3088989257812, 753.2726440429688, 278.88916015625, 1105.3004150390625, 784.5261840820312, 613.8365478515625, 306.89813232421875, 5808.05712890625, 677.2951049804688, 375.9418640136719, 985.173828125, 1139.471435546875, 2006.8475341796875, 238.7704315185547, 458.4807434082031, 3270.68798828125, 345.8824462890625, 366.73138427734375, 3897.359375, 1473.6815185546875, 1441.7657470703125, 956.8814086914062, 1278.9288330078125, 1417.475341796875, 719.1064453125, 1324.823486328125, 1637.1077880859375, 2025.2169189453125, 828.4580078125, 3101.174072265625, 5773.06298828125, 8301.712890625, 1212.2156982421875, 4188.505859375, 2753.040283203125, 4748.759765625, 14735.8271484375, 2077.027587890625, 2771.84521484375, 12224.38671875, 7948.5703125, 4503.9404296875, 3206.402099609375, 2812.91015625, 5444.4853515625, 6563.7646484375, 7775.14111328125, 6791.36328125, 6356.08203125, 14770.71484375, 9176.3984375, 3687.77490234375, 5881.6259765625, 7058.96875, 6148.72119140625, 1020.8015747070312, 969.2789306640625, 495.4887390136719, 344.6023864746094, 246.560546875, 234.86465454101562, 231.0785369873047, 192.80567932128906, 187.13438415527344, 185.65957641601562, 183.5171661376953, 165.06301879882812, 161.0296173095703, 155.70704650878906, 141.6532745361328, 138.78421020507812, 130.51834106445312, 129.0742950439453, 123.73572540283203, 123.5597152709961, 122.93351745605469, 114.83549499511719, 112.76067352294922, 1388.1768798828125, 111.12042999267578, 108.36348724365234, 107.77124786376953, 103.26749420166016, 99.24833679199219, 96.57984161376953, 3440.983154296875, 325.74847412109375, 1067.9443359375, 476.0831298828125, 261.75384521484375, 172.7177276611328, 309.8885192871094, 3865.373291015625, 512.3330078125, 298.2000732421875, 231.5638427734375, 1755.8060302734375, 471.6289978027344, 1053.4486083984375, 665.0945434570312, 1008.3263549804688, 1746.7108154296875, 1228.7528076171875, 1267.310546875, 1221.578125, 798.5787963867188, 540.0051879882812, 991.9688110351562, 591.555419921875, 1980.259765625, 1925.8455810546875, 986.9764404296875, 1567.8175048828125, 3694.619384765625, 892.779541015625, 10015.5986328125, 2581.0234375, 5773.06298828125, 4612.04248046875, 2252.2744140625, 7254.28857421875, 9176.3984375, 2002.709228515625, 3379.570068359375, 4686.99462890625, 3581.34033203125, 10253.306640625, 3981.199462890625, 8019.6826171875, 3794.69287109375, 6356.08203125, 3901.964111328125, 192.3313751220703, 172.5059051513672, 142.5945281982422, 114.22561645507812, 113.84622955322266, 109.34272766113281, 101.2772216796875, 99.87863159179688, 98.50248718261719, 95.69425964355469, 95.37000274658203, 94.74297332763672, 92.88854217529297, 75.1142349243164, 71.420654296875, 71.29010772705078, 70.82369232177734, 69.54010772705078, 69.29122924804688, 68.68142700195312, 67.2876968383789, 66.93740844726562, 66.76544189453125, 65.58586883544922, 64.36811828613281, 63.10945129394531, 61.997013092041016, 60.787662506103516, 219.28880310058594, 59.611480712890625, 313.4765625, 1953.6378173828125, 1039.2718505859375, 131.18716430664062, 567.73583984375, 676.4995727539062, 225.418212890625, 619.8925170898438, 116.87224578857422, 191.76258850097656, 136.41192626953125, 142.86245727539062, 640.4999389648438, 126.1270523071289, 147.93896484375, 398.6059875488281, 202.83023071289062, 907.3382568359375, 572.4979858398438, 290.14886474609375, 367.335205078125, 810.0717163085938, 559.1141967773438, 1671.9359130859375, 2777.3671875, 780.42138671875, 404.1485900878906, 824.1981811523438, 819.3163452148438, 3981.823974609375, 419.0998229980469, 448.2855529785156, 645.3147583007812, 2009.9578857421875, 1425.8084716796875, 3270.68798828125, 14770.71484375, 3315.390625, 2581.0234375, 3666.1083984375, 5881.6259765625, 3901.964111328125, 3168.277587890625, 2043.3251953125, 2425.828369140625, 2276.2158203125, 2634.767333984375, 4048.814697265625, 1958.423583984375, 6791.36328125, 2817.336669921875, 6356.08203125, 395.6701965332031, 238.80035400390625, 225.49542236328125, 175.37432861328125, 159.0286407470703, 155.989013671875, 155.5384063720703, 151.28970336914062, 147.67808532714844, 140.56301879882812, 122.39488220214844, 115.85810852050781, 113.93074035644531, 108.36042785644531, 106.14256286621094, 103.81583404541016, 99.52810668945312, 97.59619140625, 95.81094360351562, 95.64142608642578, 95.34491729736328, 94.52745056152344, 91.91829681396484, 86.83377075195312, 84.02886962890625, 81.7356185913086, 77.29489135742188, 76.47874450683594, 74.50845336914062, 70.6712417602539, 89.50643920898438, 399.8089599609375, 153.01089477539062, 144.58717346191406, 221.8291015625, 245.99862670898438, 843.0267333984375, 1123.162841796875, 138.51634216308594, 2027.4415283203125, 2023.2568359375, 1490.177978515625, 1758.8773193359375, 480.18023681640625, 1348.25634765625, 246.2147216796875, 211.1394805908203, 7775.14111328125, 260.8988952636719, 806.4544067382812, 2771.84521484375, 384.0763854980469, 966.5777587890625, 8340.3544921875, 3794.69287109375, 3360.13720703125, 4034.76220703125, 3206.402099609375, 1462.1336669921875, 985.032958984375, 1500.6070556640625, 306.2304382324219, 3092.4345703125, 2319.7744140625, 2812.91015625, 1827.404541015625, 5881.6259765625, 4920.20166015625, 5773.06298828125, 7164.87890625, 5120.068359375, 4030.170654296875, 4410.78564453125, 4612.04248046875, 13867.0556640625, 5808.05712890625, 3981.823974609375, 6356.08203125, 14770.71484375, 12224.38671875, 262.6604919433594, 206.0240936279297, 181.6322479248047, 151.4102020263672, 136.0782928466797, 128.52197265625, 121.52124786376953, 115.570068359375, 108.40660095214844, 105.80592346191406, 101.31893920898438, 99.7869873046875, 87.78826904296875, 74.15293884277344, 73.06791687011719, 69.18291473388672, 69.1231918334961, 68.24922180175781, 66.51603698730469, 62.975162506103516, 61.81775665283203, 60.31023406982422, 59.634098052978516, 57.62217330932617, 57.47768783569336, 55.48656463623047, 55.397098541259766, 55.30567169189453, 55.19672775268555, 52.6800422668457, 344.3182373046875, 87.1651382446289, 434.4206848144531, 456.1217956542969, 222.47486877441406, 437.6163635253906, 89.13174438476562, 462.3014221191406, 846.5423583984375, 215.6856231689453, 214.76901245117188, 233.99169921875, 222.8765869140625, 178.2844696044922, 103.51091766357422, 269.93505859375, 1996.75634765625, 419.403076171875, 988.6165161132812, 139.90591430664062, 482.482177734375, 4034.76220703125, 8340.3544921875, 375.4830627441406, 4046.610595703125, 1494.9908447265625, 557.1666870117188, 327.47412109375, 2519.74658203125, 4410.78564453125, 452.14251708984375, 1840.4766845703125, 3293.562744140625, 3206.402099609375, 2756.156494140625, 813.3536987304688, 755.0123291015625, 506.83209228515625, 191.0748748779297, 186.64797973632812, 186.474365234375, 171.84780883789062, 142.55274963378906, 130.28787231445312, 128.89215087890625, 119.97080993652344, 112.47164154052734, 106.92300415039062, 103.40028381347656, 94.94388580322266, 90.58573150634766, 87.37540435791016, 85.53768157958984, 79.24140167236328, 74.77568817138672, 68.86675262451172, 67.98098754882812, 66.73194122314453, 66.2937240600586, 62.95071029663086, 62.90512466430664, 61.07969665527344, 59.56542205810547, 57.824527740478516, 57.27033615112305, 160.27059936523438, 2239.039794921875, 327.2772521972656, 210.2937469482422, 145.1924591064453, 258.87994384765625, 109.39302062988281, 849.0917358398438, 459.7138366699219, 180.40733337402344, 267.47930908203125, 2634.767333984375, 452.90185546875, 743.5508422851562, 330.2322082519531, 585.4951171875, 1035.3912353515625, 562.4452514648438, 1027.9573974609375, 821.5759887695312, 285.8822937011719, 869.7670288085938, 321.62786865234375, 711.6270751953125, 1230.5489501953125, 383.8841552734375, 1829.58349609375, 1190.424560546875, 1936.582275390625, 3270.68798828125, 174.17413330078125, 171.76268005371094, 168.60238647460938, 158.8846893310547, 134.6823272705078, 126.826416015625, 121.29095458984375, 106.90768432617188, 102.16822814941406, 160.53419494628906, 96.0118408203125, 95.26380157470703, 92.26020812988281, 91.73516082763672, 84.02560424804688, 82.7282943725586, 80.13681030273438, 68.28607177734375, 67.42183685302734, 67.3660659790039, 66.10267639160156, 65.54627990722656, 62.34589767456055, 61.5684928894043, 60.63966369628906, 59.15896987915039, 58.771324157714844, 57.336177825927734, 57.029518127441406, 56.38667297363281, 832.6156005859375, 567.2717895507812, 191.19699096679688, 1746.4202880859375, 330.30499267578125, 102.40684509277344, 1243.02197265625, 187.6099395751953, 3895.164306640625, 104.90385437011719, 239.7215576171875, 711.0435791015625, 368.8209228515625, 1297.978759765625, 366.7328186035156, 546.1593017578125, 799.2474975585938, 1436.1868896484375, 2510.6650390625, 216.74783325195312, 828.7929077148438, 1809.4803466796875, 550.0780639648438, 4920.20166015625, 941.0250244140625, 8340.3544921875, 5881.6259765625, 2352.40576171875, 4046.610595703125, 2148.6572265625, 1732.9271240234375, 219.31602478027344, 208.4253692626953, 192.13009643554688, 178.0645294189453, 157.77630615234375, 150.930419921875, 142.94473266601562, 141.25, 109.88484954833984, 102.82357788085938, 100.76302337646484, 819.615966796875, 92.03101348876953, 88.21255493164062, 85.5426025390625, 84.97393035888672, 84.50387573242188, 84.19912719726562, 78.37848663330078, 75.22834014892578, 74.17755889892578, 72.417724609375, 71.2830810546875, 70.53154754638672, 70.44657135009766, 70.1781997680664, 68.84952545166016, 65.02705383300781, 64.45601654052734, 63.89582061767578, 194.0604705810547, 204.436767578125, 109.6772689819336, 284.7044372558594, 598.8178100585938, 360.2243957519531, 163.4773406982422, 316.4762878417969, 642.2518920898438, 530.2951049804688, 195.24049377441406, 216.38046264648438, 1248.4918212890625, 1266.6201171875, 1436.1868896484375, 233.39047241210938, 491.42608642578125, 294.2962646484375, 8340.3544921875, 300.7481994628906, 1132.888427734375, 2352.40576171875, 560.5177612304688, 708.364501953125, 487.9493713378906, 529.1072387695312, 7775.14111328125, 220.54547119140625, 159.15879821777344, 135.03399658203125, 131.2139892578125, 123.35369110107422, 116.9701919555664, 115.8668212890625, 111.2086181640625, 107.35692596435547, 117.50851440429688, 83.99534606933594, 83.37430572509766, 79.57327270507812, 78.63054656982422, 78.52962493896484, 76.40601348876953, 76.09852600097656, 75.8221664428711, 72.73981475830078, 72.5180892944336, 70.8497085571289, 70.20833587646484, 62.32562255859375, 61.7076301574707, 61.61421585083008, 60.352760314941406, 59.4090461730957, 56.8574333190918, 55.69282150268555, 55.40007781982422, 123.85790252685547, 242.45162963867188, 989.4088745117188, 206.59779357910156, 219.9105987548828, 188.8583984375, 261.1634521484375, 314.82696533203125, 897.6544189453125, 642.2518920898438, 328.1769104003906, 207.47894287109375, 352.1049499511719, 362.40570068359375, 770.130615234375, 227.8738555908203, 765.1419677734375, 192.43531799316406, 537.4439086914062, 8340.3544921875, 708.364501953125, 1248.4918212890625, 1558.7828369140625, 355.0990295410156, 281.5616149902344, 246.98301696777344, 243.25880432128906, 226.00790405273438, 174.09169006347656, 146.91163635253906, 137.78550720214844, 129.13162231445312, 128.15121459960938, 122.4280014038086, 117.64949798583984, 107.2205581665039, 106.6112060546875, 101.66980743408203, 100.14495086669922, 99.62086486816406, 98.01304626464844, 91.42768859863281, 83.29547882080078, 77.7573013305664, 77.44058990478516, 71.67266082763672, 71.41312408447266, 71.30462646484375, 70.73784637451172, 69.42180633544922, 68.3422622680664, 67.38745880126953, 253.0366668701172, 99.96595764160156, 240.7026824951172, 548.7233276367188, 152.91310119628906, 1267.310546875, 84.98067474365234, 854.1687622070312, 8340.3544921875, 515.9249267578125, 512.5104370117188, 1829.58349609375, 5773.06298828125, 392.8479919433594, 4046.610595703125, 225.32644653320312, 177.0181427001953, 171.77947998046875, 151.56912231445312, 144.8063507080078, 135.85702514648438, 131.58755493164062, 102.7333755493164, 102.26392364501953, 98.57691192626953, 97.88660430908203, 95.79441833496094, 90.93415832519531, 85.03298950195312, 82.1523666381836, 77.23612213134766, 74.48815155029297, 71.08121490478516, 68.35244750976562, 66.23409271240234, 65.49591827392578, 65.07206726074219, 63.51431655883789, 61.914466857910156, 60.71986389160156, 60.54092788696289, 60.516178131103516, 59.795650482177734, 59.688846588134766, 58.95033264160156, 222.10520935058594, 112.80641174316406, 92.10748291015625, 140.25413513183594, 157.48187255859375, 244.39845275878906, 382.95703125, 275.7179260253906, 111.31550598144531, 341.8219299316406, 756.9668579101562, 329.8829650878906, 189.6024932861328, 846.5423583984375, 765.1419677734375, 8340.3544921875, 628.8047485351562, 484.01812744140625, 247.4613037109375, 192.60755920410156, 132.0499725341797, 120.71493530273438, 120.58151245117188, 113.91742706298828, 112.8111572265625, 103.67093658447266, 96.81724548339844, 95.95924377441406, 89.34024047851562, 83.2022933959961, 82.08699035644531, 81.25364685058594, 79.41866302490234, 76.32721710205078, 74.22655487060547, 96.474609375, 61.24364471435547, 58.975135803222656, 58.24222946166992, 58.08731460571289, 57.43644714355469, 56.87857437133789, 56.47272872924805, 56.36757278442383, 55.69490432739258, 54.39474105834961, 54.01356506347656, 53.830074310302734, 80.86167907714844, 230.97023010253906, 131.83030700683594, 111.80188751220703, 68.25305938720703, 83.62805938720703, 358.6209716796875, 168.9085235595703, 344.0788269042969, 162.17202758789062, 401.10638427734375, 408.78558349609375, 472.94476318359375, 710.3330688476562, 296.2561340332031, 8340.3544921875, 3360.13720703125, 369.4770202636719, 1266.6201171875, 799.8270874023438, 1036.601318359375, 330.50848388671875, 175.17047119140625, 173.7082977294922, 170.06338500976562, 147.85638427734375, 145.31321716308594, 116.28309631347656, 114.72615814208984, 109.6569595336914, 93.60417175292969, 92.92359161376953, 85.89891052246094, 83.09095001220703, 82.17667388916016, 74.97119903564453, 74.22505187988281, 71.99769592285156, 69.2961196899414, 66.97911071777344, 63.08774948120117, 59.17959213256836, 58.900020599365234, 55.714019775390625, 52.78759765625, 51.9686279296875, 50.82964324951172, 50.18342971801758, 48.55987548828125, 48.543636322021484, 47.502479553222656, 98.42166900634766, 374.46234130859375, 314.44122314453125, 83.01371002197266, 238.38214111328125, 100.80255126953125, 105.95384979248047, 124.56756591796875, 95.79785919189453, 208.86900329589844, 185.10952758789062, 908.1319580078125, 1829.58349609375, 300.88470458984375, 101.88032531738281, 348.9859619140625, 200.82217407226562, 4046.610595703125, 439.4117431640625, 3475.37353515625, 801.69775390625, 1520.086181640625, 1094.0030517578125, 193.69442749023438, 1036.601318359375, 676.4995727539062, 1337.4652099609375], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.260799884796143, -7.3109002113342285, -7.862299919128418, -8.12600040435791, -8.199600219726562, -8.320500373840332, -8.371299743652344, -8.433799743652344, -8.495100021362305, -8.524499893188477, -8.592700004577637, -8.598299980163574, -8.691399574279785, -8.726900100708008, -8.77280044555664, -8.83899974822998, -8.93239974975586, -9.000499725341797, -9.029899597167969, -9.04520034790039, -9.156800270080566, -9.184000015258789, -9.196200370788574, -9.258899688720703, -9.335800170898438, -9.368399620056152, -9.403300285339355, -9.439299583435059, -9.448399543762207, -9.456600189208984, -5.127999782562256, -6.765500068664551, -5.460599899291992, -6.065800189971924, -7.868100166320801, -5.3302001953125, -5.717700004577637, -6.010499954223633, -5.28249979019165, -6.342899799346924, -6.866300106048584, -6.396399974822998, -4.065800189971924, -5.565499782562256, -5.547800064086914, -5.100200176239014, -5.86269998550415, -5.875500202178955, -6.785200119018555, -5.613999843597412, -7.27869987487793, -4.5243000984191895, -5.969900131225586, -5.667200088500977, -5.39139986038208, -5.736700057983398, -6.699699878692627, -5.4604997634887695, -6.225200176239014, -5.087900161743164, -5.558800220489502, -4.805699825286865, -4.672599792480469, -4.702400207519531, -4.950500011444092, -4.63129997253418, -4.29449987411499, -4.9629998207092285, -4.3968000411987305, -5.066299915313721, -4.778800010681152, -5.414400100708008, -5.236700057983398, -5.394000053405762, -5.418799877166748, -4.785699844360352, -5.022200107574463, -5.100399971008301, -5.181099891662598, -5.1940999031066895, -5.3730998039245605, -7.350399971008301, -8.298299789428711, -8.086600303649902, -8.464099884033203, -8.51729965209961, -8.576499938964844, -8.579999923706055, -8.58549976348877, -8.626500129699707, -8.794300079345703, -8.80459976196289, -8.823699951171875, -8.857199668884277, -8.905099868774414, -8.911800384521484, -8.913999557495117, -8.922100067138672, -8.939599990844727, -8.992799758911133, -9.004500389099121, -9.005399703979492, -9.018799781799316, -9.019499778747559, -9.028200149536133, -9.029199600219727, -9.12909984588623, -9.130599975585938, -9.133600234985352, -9.140000343322754, -9.155099868774414, -8.180899620056152, -7.7565999031066895, -4.965199947357178, -6.345600128173828, -5.883200168609619, -5.5005998611450195, -4.039700031280518, -6.344600200653076, -5.126699924468994, -6.208499908447266, -6.2332000732421875, -7.076000213623047, -4.018899917602539, -4.651599884033203, -6.745800018310547, -5.69789981842041, -8.056300163269043, -5.028900146484375, -5.5833001136779785, -5.228899955749512, -4.738999843597412, -6.489799976348877, -5.167300224304199, -5.743899822235107, -7.041200160980225, -6.195799827575684, -5.44789981842041, -6.421999931335449, -5.102799892425537, -5.152200222015381, -5.35860013961792, -4.972300052642822, -4.443600177764893, -4.9593000411987305, -4.872200012207031, -5.5157999992370605, -5.640699863433838, -5.21019983291626, -4.593400001525879, -5.521299839019775, -5.729899883270264, -5.698299884796143, -5.456999778747559, -5.547399997711182, -5.2042999267578125, -5.401299953460693, -5.362100124359131, -5.3516998291015625, -5.423999786376953, -5.4558000564575195, -5.499100208282471, -5.510499954223633, -7.3632001876831055, -7.460700035095215, -7.781400203704834, -7.809700012207031, -7.871799945831299, -7.882299900054932, -7.978499889373779, -7.986999988555908, -8.016300201416016, -8.028300285339355, -8.091300010681152, -8.103300094604492, -8.105799674987793, -8.158900260925293, -8.174799919128418, -8.183300018310547, -8.19260025024414, -8.228599548339844, -8.230799674987793, -8.233799934387207, -8.25510025024414, -8.256199836730957, -8.25730037689209, -8.262399673461914, -8.27299976348877, -8.293999671936035, -8.38290023803711, -8.383099555969238, -8.3996000289917, -8.414999961853027, -7.3003997802734375, -7.88730001449585, -6.342400074005127, -6.879499912261963, -6.635900020599365, -6.561500072479248, -6.862800121307373, -7.178100109100342, -6.183000087738037, -6.067599773406982, -6.348999977111816, -7.265399932861328, -6.04010009765625, -6.3506999015808105, -6.591300010681152, -7.196100234985352, -4.655099868774414, -6.525400161743164, -7.030600070953369, -6.213799953460693, -6.103300094604492, -5.637800216674805, -7.420499801635742, -6.882999897003174, -5.305600166320801, -7.126800060272217, -7.081399917602539, -5.223700046539307, -5.997700214385986, -6.031000137329102, -6.368899822235107, -6.169099807739258, -6.096499919891357, -6.589799880981445, -6.160399913787842, -6.038000106811523, -5.900300025939941, -6.500999927520752, -5.644400119781494, -5.247000217437744, -5.019199848175049, -6.264400005340576, -5.55649995803833, -5.815000057220459, -5.526400089263916, -5.01230001449585, -5.9842000007629395, -5.845900058746338, -5.136300086975098, -5.351600170135498, -5.633900165557861, -5.799200057983398, -5.866499900817871, -5.668000221252441, -5.6066999435424805, -5.5883002281188965, -5.694699764251709, -5.717199802398682, -5.543399810791016, -5.656899929046631, -5.881899833679199, -5.8907999992370605, -5.914700031280518, -5.989699840545654, -5.7399001121521, -5.7916998863220215, -6.463699817657471, -6.827700138092041, -7.163599967956543, -7.212399959564209, -7.228799819946289, -7.410699844360352, -7.440700054168701, -7.448599815368652, -7.460299968719482, -7.56689977645874, -7.591800212860107, -7.6255998611450195, -7.720799922943115, -7.741399765014648, -7.803299903869629, -7.814499855041504, -7.857100009918213, -7.858500003814697, -7.86359977722168, -7.932300090789795, -7.950699806213379, -5.440299987792969, -7.9654998779296875, -7.990900039672852, -7.996399879455566, -8.03950023651123, -8.07960033416748, -8.107099533081055, -4.537499904632568, -6.901700019836426, -5.753799915313721, -6.563799858093262, -7.139400005340576, -7.540999889373779, -6.986499786376953, -4.5960001945495605, -6.512599945068359, -7.031799793243408, -7.277200222015381, -5.416900157928467, -6.632999897003174, -5.908999919891357, -6.3495001792907715, -5.994100093841553, -5.5229997634887695, -5.830900192260742, -5.804699897766113, -5.865200042724609, -6.246399879455566, -6.577099800109863, -6.124300003051758, -6.533999919891357, -5.735400199890137, -5.799300193786621, -6.247600078582764, -5.952199935913086, -5.434000015258789, -6.360799789428711, -4.942299842834473, -5.766900062561035, -5.385300159454346, -5.514400005340576, -5.879799842834473, -5.3471999168396, -5.311399936676025, -5.954599857330322, -5.747000217437744, -5.6402997970581055, -5.78249979019165, -5.450399875640869, -5.758999824523926, -5.61460018157959, -5.822999954223633, -5.7515997886657715, -5.885700225830078, -6.997300148010254, -7.1066999435424805, -7.298299789428711, -7.5218000411987305, -7.525199890136719, -7.565899848937988, -7.643199920654297, -7.657299995422363, -7.671299934387207, -7.700500011444092, -7.70389986038208, -7.710599899291992, -7.730599880218506, -7.945400238037109, -7.996500015258789, -7.9984002113342285, -8.00510025024414, -8.023599624633789, -8.027199745178223, -8.036199569702148, -8.057000160217285, -8.062299728393555, -8.064900398254395, -8.083000183105469, -8.10200023651123, -8.122099876403809, -8.14009952545166, -8.160200119018555, -6.877200126647949, -8.180000305175781, -6.527400016784668, -4.7846999168396, -5.479499816894531, -7.4293999671936035, -6.055500030517578, -5.921199798583984, -6.955100059509277, -6.046899795532227, -7.555799961090088, -7.11460018157959, -7.427000045776367, -7.394100189208984, -6.101399898529053, -7.511600017547607, -7.3765997886657715, -6.534200191497803, -7.110000133514404, -5.8653998374938965, -6.260900020599365, -6.825200080871582, -6.64109992980957, -6.039100170135498, -6.343800067901611, -5.515699863433838, -5.15939998626709, -6.128200054168701, -6.624800205230713, -6.111499786376953, -6.180200099945068, -5.123199939727783, -6.67549991607666, -6.651500225067139, -6.43179988861084, -5.768099784851074, -6.036099910736084, -5.614699840545654, -4.93209981918335, -5.695400238037109, -5.818299770355225, -5.694300174713135, -5.542099952697754, -5.751299858093262, -5.876299858093262, -6.036099910736084, -6.005499839782715, -6.0609002113342285, -6.0578999519348145, -5.981299877166748, -6.12529993057251, -6.048299789428711, -6.115200042724609, -6.122600078582764, -6.235899925231934, -6.741700172424316, -6.799200057983398, -7.051799774169922, -7.150199890136719, -7.169600009918213, -7.172500133514404, -7.200399875640869, -7.224699974060059, -7.274400234222412, -7.413899898529053, -7.469200134277344, -7.486100196838379, -7.5366997718811035, -7.557499885559082, -7.579899787902832, -7.622499942779541, -7.642300128936768, -7.660900115966797, -7.662700176239014, -7.665800094604492, -7.674499988555908, -7.7027997970581055, -7.760300159454346, -7.793499946594238, -7.821499824523926, -7.8780999183654785, -7.888800144195557, -7.915299892425537, -7.968800067901611, -7.736999988555908, -6.273399829864502, -7.246699810028076, -7.302000045776367, -6.927299976348877, -6.835700035095215, -5.750899791717529, -5.5117998123168945, -7.350200176239014, -5.076200008392334, -5.096799850463867, -5.38070011138916, -5.273600101470947, -6.3460001945495605, -5.529799938201904, -6.890500068664551, -7.015900135040283, -4.1921000480651855, -6.8495001792907715, -5.97760009765625, -5.043600082397461, -6.5625, -5.883399963378906, -4.320099830627441, -4.898099899291992, -5.02400016784668, -4.934199810028076, -5.136199951171875, -5.6975998878479, -5.9633002281188965, -5.713600158691406, -6.737299919128418, -5.289700031280518, -5.48390007019043, -5.3933000564575195, -5.663700103759766, -5.015999794006348, -5.156300067901611, -5.080599784851074, -4.995100021362305, -5.199699878692627, -5.333399772644043, -5.316199779510498, -5.319499969482422, -4.996799945831299, -5.370200157165527, -5.4781999588012695, -5.382500171661377, -5.273600101470947, -5.332399845123291, -5.462200164794922, -5.706099987030029, -5.832799911499023, -6.0157999992370605, -6.123300075531006, -6.1809000968933105, -6.237299919128418, -6.287899971008301, -6.352499961853027, -6.376999855041504, -6.4207000732421875, -6.436200141906738, -6.565499782562256, -6.736400127410889, -6.751299858093262, -6.806700229644775, -6.807600021362305, -6.820499897003174, -6.84660005569458, -6.902100086212158, -6.921000003814697, -6.946000099182129, -6.957499980926514, -6.992400169372559, -6.994900226593018, -7.030799865722656, -7.03249979019165, -7.03410005569458, -7.036099910736084, -7.083700180053711, -5.241000175476074, -6.591100215911865, -5.037600040435791, -5.077899932861328, -5.755099773406982, -5.160799980163574, -6.60860013961792, -5.222799777984619, -4.745999813079834, -5.891600131988525, -5.899799823760986, -5.856400012969971, -5.900700092315674, -6.132900238037109, -6.524099826812744, -5.896699905395508, -4.646599769592285, -5.686500072479248, -5.220699787139893, -6.350800037384033, -5.781899929046631, -4.919000148773193, -4.666500091552734, -5.938899993896484, -5.174900054931641, -5.5680999755859375, -5.896100044250488, -6.0320000648498535, -5.688199996948242, -5.641200065612793, -5.983399868011475, -5.779200077056885, -5.741799831390381, -5.791600227355957, -5.828999996185303, -4.306000232696533, -4.380499839782715, -4.779699802398682, -5.758299827575684, -5.781899929046631, -5.782800197601318, -5.864999771118164, -6.052999973297119, -6.143599987030029, -6.1545000076293945, -6.226799964904785, -6.291800022125244, -6.342899799346924, -6.376699924468994, -6.462800025939941, -6.510300159454346, -6.546800136566162, -6.568299770355225, -6.645699977874756, -6.704400062561035, -6.787799835205078, -6.801000118255615, -6.819799900054932, -6.826499938964844, -6.879000186920166, -6.879700183868408, -6.909599781036377, -6.935200214385986, -6.9653000831604, -6.975100040435791, -5.957399845123291, -3.4972000122070312, -5.322000026702881, -5.813799858093262, -6.1402997970581055, -5.7291998863220215, -6.459199905395508, -4.9918999671936035, -5.438700199127197, -6.104800224304199, -5.832600116729736, -4.3358001708984375, -5.5395002365112305, -5.329500198364258, -5.804900169372559, -5.492199897766113, -5.217400074005127, -5.55810022354126, -5.277200222015381, -5.396999835968018, -5.893400192260742, -5.507199764251709, -5.892099857330322, -5.703400135040283, -5.5756001472473145, -5.924200057983398, -5.734099864959717, -5.839799880981445, -5.84119987487793, -5.848599910736084, -5.736800193786621, -5.750800132751465, -5.769499778747559, -5.82919979095459, -5.995500087738037, -6.056099891662598, -6.10099983215332, -6.228400230407715, -6.274099826812744, -5.822800159454346, -6.336900234222412, -6.344799995422363, -6.377200126647949, -6.382900238037109, -6.471700191497803, -6.487400054931641, -6.519599914550781, -6.68179988861084, -6.694699764251709, -6.695499897003174, -6.714700222015381, -6.723299980163574, -6.774199962615967, -6.786900043487549, -6.802299976348877, -6.827499866485596, -6.834199905395508, -6.859300136566162, -6.864699840545654, -6.876299858093262, -4.199900150299072, -4.606100082397461, -5.674099922180176, -3.564199924468994, -5.205699920654297, -6.312900066375732, -4.067699909210205, -5.821899890899658, -3.2358999252319336, -6.339200019836426, -5.6717000007629395, -4.886899948120117, -5.5524001121521, -5.0258002281188965, -5.712200164794922, -5.537499904632568, -5.417600154876709, -5.172100067138672, -5.01669979095459, -6.0295000076293945, -5.526500225067139, -5.240600109100342, -5.701700210571289, -5.182799816131592, -5.690899848937988, -5.204699993133545, -5.3165998458862305, -5.578499794006348, -5.5229997634887695, -5.668499946594238, -5.755000114440918, -5.201499938964844, -5.252699851989746, -5.334499835968018, -5.410900115966797, -5.532599925994873, -5.577300071716309, -5.631999969482422, -5.644000053405762, -5.89709997177124, -5.964099884033203, -5.984499931335449, -3.8893001079559326, -6.076099872589111, -6.118899822235107, -6.150000095367432, -6.156799793243408, -6.162399768829346, -6.165999889373779, -6.238500118255615, -6.280099868774414, -6.294300079345703, -6.318699836730957, -6.334700107574463, -6.345399856567383, -6.34660005569458, -6.350500106811523, -6.369900226593018, -6.4278998374938965, -6.436800003051758, -6.445700168609619, -5.476200103759766, -5.5046000480651855, -6.013400077819824, -5.326499938964844, -4.874499797821045, -5.288599967956543, -5.868199825286865, -5.539100170135498, -5.19189977645874, -5.3165998458862305, -5.834700107574463, -5.814199924468994, -5.141300201416016, -5.187099933624268, -5.184500217437744, -5.829899787902832, -5.6057000160217285, -5.76639986038208, -4.870999813079834, -5.768799781799316, -5.519800186157227, -5.384900093078613, -5.718100070953369, -5.704400062561035, -5.783400058746338, -5.796500205993652, -5.795100212097168, -5.042699813842773, -5.37060022354126, -5.536099910736084, -5.565000057220459, -5.627299785614014, -5.680799961090088, -5.690400123596191, -5.731800079345703, -5.767300128936768, -5.679200172424316, -6.0152997970581055, -6.022799968719482, -6.070000171661377, -6.082099914550781, -6.083399772644043, -6.111100196838379, -6.115200042724609, -6.118899822235107, -6.160900115966797, -6.164000034332275, -6.187600135803223, -6.196800231933594, -6.317699909210205, -6.3277997970581055, -6.329400062561035, -6.350399971008301, -6.366399765014648, -6.410999774932861, -6.43209981918335, -6.4375, -5.702099800109863, -5.353099822998047, -4.393899917602539, -5.511099815368652, -5.497200012207031, -5.605599880218506, -5.466100215911865, -5.416200160980225, -4.898799896240234, -5.158400058746338, -5.5406999588012695, -5.75600004196167, -5.56820011138916, -5.616099834442139, -5.532100200653076, -5.844399929046631, -5.598700046539307, -5.901000022888184, -5.724699974060059, -5.403800010681152, -5.729899883270264, -5.742800235748291, -3.060499906539917, -4.541900157928467, -4.774600028991699, -4.906099796295166, -4.92140007019043, -4.995299816131592, -5.257500171661377, -5.428299903869629, -5.4928998947143555, -5.558300018310547, -5.565899848937988, -5.611999988555908, -5.652100086212158, -5.745800018310547, -5.751500129699707, -5.7993998527526855, -5.814700126647949, -5.820000171661377, -5.836400032043457, -5.906700134277344, -6.000899791717529, -6.070499897003174, -6.074699878692627, -6.15310001373291, -6.156799793243408, -6.158299922943115, -6.166399955749512, -6.185500144958496, -6.201300144195557, -6.21560001373291, -5.218900203704834, -5.95419979095459, -5.395100116729736, -4.90369987487793, -5.754799842834473, -4.6732001304626465, -6.0731000900268555, -5.063700199127197, -4.384099960327148, -5.496200084686279, -5.517600059509277, -5.224999904632568, -5.306000232696533, -5.757900238037109, -5.7093000411987305, -4.977399826049805, -5.219900131225586, -5.250100135803223, -5.375999927520752, -5.421999931335449, -5.486199855804443, -5.518400192260742, -5.76800012588501, -5.772600173950195, -5.809700012207031, -5.816800117492676, -5.838600158691406, -5.891200065612793, -5.959099769592285, -5.993899822235107, -6.056399822235107, -6.093100070953369, -6.140500068664551, -6.180200099945068, -6.212200164794922, -6.223599910736084, -6.230100154876709, -6.254700183868408, -6.280700206756592, -6.30049991607666, -6.303500175476074, -6.303899765014648, -6.315999984741211, -6.31790018081665, -6.33050012588501, -5.0630998611450195, -5.7743000984191895, -5.970200061798096, -5.636600017547607, -5.56220006942749, -5.225800037384033, -5.189799785614014, -5.451300144195557, -5.9558000564575195, -5.411200046539307, -5.085700035095215, -5.5625, -5.78410005569458, -5.442299842834473, -5.541999816894531, -5.66949987411499, -5.905600070953369, -5.957300186157227, -4.816400051116943, -5.067200183868408, -5.447000026702881, -5.537499904632568, -5.538599967956543, -5.595900058746338, -5.6057000160217285, -5.690999984741211, -5.7600998878479, -5.769000053405762, -5.841300010681152, -5.913300037384033, -5.9268999099731445, -5.93720006942749, -5.960400104522705, -6.0005998611450195, -6.028800010681152, -5.768199920654297, -6.223899841308594, -6.26230001449585, -6.275000095367432, -6.277699947357178, -6.289100170135498, -6.299099922180176, -6.306399822235107, -6.308199882507324, -6.320499897003174, -6.3445000648498535, -6.3516998291015625, -6.355100154876709, -5.967899799346924, -4.981599807739258, -5.509799957275391, -5.683199882507324, -6.140699863433838, -6.004899978637695, -4.9207000732421875, -5.63129997253418, -5.329400062561035, -5.76170015335083, -5.341400146484375, -5.402100086212158, -5.404799938201904, -5.336900234222412, -5.692999839782715, -4.944699764251709, -5.406700134277344, -5.746699810028076, -5.589799880981445, -5.66349983215332, -5.69379997253418, -4.518899917602539, -5.156400203704834, -5.16480016708374, -5.186100006103516, -5.326900005340576, -5.344399929046631, -5.568900108337402, -5.582499980926514, -5.6280999183654785, -5.787899971008301, -5.795300006866455, -5.874800205230713, -5.908400058746338, -5.919600009918213, -6.012499809265137, -6.02269983291626, -6.053500175476074, -6.092299938201904, -6.126800060272217, -6.187600135803223, -6.252600193023682, -6.257400035858154, -6.313899993896484, -6.368899822235107, -6.384799957275391, -6.407400131225586, -6.420499801635742, -6.453999996185303, -6.4542999267578125, -6.476500034332275, -5.767099857330322, -4.489799976348877, -4.786499977111816, -5.9745001792907715, -5.05019998550415, -5.812399864196777, -5.778600215911865, -5.649799823760986, -5.8867998123168945, -5.337500095367432, -5.432799816131592, -4.429999828338623, -4.181099891662598, -5.268899917602539, -5.866000175476074, -5.301199913024902, -5.602099895477295, -4.561999797821045, -5.383299827575684, -4.88700008392334, -5.302599906921387, -5.148600101470947, -5.399600028991699, -5.709799766540527, -5.533100128173828, -5.577499866485596, -5.707099914550781], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5492000579833984, 1.5491000413894653, 1.5469000339508057, 1.5454000234603882, 1.5448999404907227, 1.5440000295639038, 1.5435999631881714, 1.5429999828338623, 1.5424000024795532, 1.542199969291687, 1.5414999723434448, 1.5413999557495117, 1.5404000282287598, 1.5399999618530273, 1.5393999814987183, 1.5384999513626099, 1.5371999740600586, 1.5362000465393066, 1.5356999635696411, 1.5355000495910645, 1.5334999561309814, 1.5329999923706055, 1.5327999591827393, 1.531599998474121, 1.5299999713897705, 1.5291999578475952, 1.52839994430542, 1.5276000499725342, 1.527400016784668, 1.5270999670028687, 1.51010000705719, 1.5175000429153442, 1.5003000497817993, 1.5056999921798706, 1.5234999656677246, 1.46589994430542, 1.47160005569458, 1.4668999910354614, 1.4372999668121338, 1.4697999954223633, 1.4799000024795532, 1.4600000381469727, 1.3726999759674072, 1.4104000329971313, 1.3837000131607056, 1.3293999433517456, 1.3631000518798828, 1.361299991607666, 1.4062000513076782, 1.3013999462127686, 1.4394999742507935, 1.1885000467300415, 1.312600016593933, 1.2824000120162964, 1.2523000240325928, 1.2675000429153442, 1.3724000453948975, 1.218400001525879, 1.3078999519348145, 1.1334999799728394, 1.1584999561309814, 1.006100058555603, 0.9771000146865845, 0.9818000197410583, 1.0128999948501587, 0.9377999901771545, 0.8421000242233276, 0.9868999719619751, 0.6765999794006348, 0.9161999821662903, 0.6832000017166138, 1.0683000087738037, 0.949400007724762, 0.9736999869346619, 0.9908999800682068, 0.29010000824928284, 0.5273000001907349, 0.5927000045776367, 0.6319000124931335, 0.590399980545044, 0.5115000009536743, 1.7624000310897827, 1.756600022315979, 1.7563999891281128, 1.7548999786376953, 1.7542999982833862, 1.753600001335144, 1.753499984741211, 1.753499984741211, 1.7529000043869019, 1.750599980354309, 1.7503999471664429, 1.750100016593933, 1.7496000528335571, 1.7488000392913818, 1.7486000061035156, 1.7486000061035156, 1.7484999895095825, 1.7482000589370728, 1.7472000122070312, 1.746999979019165, 1.746899962425232, 1.7467000484466553, 1.7467000484466553, 1.746500015258789, 1.746500015258789, 1.7444000244140625, 1.7444000244140625, 1.7443000078201294, 1.7441999912261963, 1.743899941444397, 1.7333999872207642, 1.7175999879837036, 1.5669000148773193, 1.6145000457763672, 1.4803999662399292, 1.410099983215332, 1.2230000495910645, 1.4670000076293945, 1.295199990272522, 1.4052000045776367, 1.4082000255584717, 1.4925999641418457, 1.0570000410079956, 1.145300030708313, 1.4453999996185303, 1.2783000469207764, 1.6227999925613403, 1.1439000368118286, 1.2335000038146973, 1.1726000308990479, 1.0740000009536743, 1.3621000051498413, 1.114799976348877, 1.2049000263214111, 1.4407999515533447, 1.2585999965667725, 1.0724999904632568, 1.2918000221252441, 0.9688000082969666, 0.9807999730110168, 1.0210000276565552, 0.8780999779701233, 0.6930000185966492, 0.8252000212669373, 0.6967999935150146, 0.9379000067710876, 0.9840999841690063, 0.7723000049591064, 0.48010000586509705, 0.8833000063896179, 1.0147000551223755, 0.9814000129699707, 0.7512000203132629, 0.8238000273704529, 0.3452000021934509, 0.5620999932289124, 0.3310999870300293, 0.11029999703168869, 0.22100000083446503, 0.25940001010894775, 0.3853999972343445, 0.4997999966144562, 1.8967000246047974, 1.896299958229065, 1.8945000171661377, 1.8942999839782715, 1.8939000368118286, 1.8938000202178955, 1.8931000232696533, 1.8930000066757202, 1.892799973487854, 1.892699956893921, 1.8919999599456787, 1.8919999599456787, 1.8919999599456787, 1.8914999961853027, 1.8913999795913696, 1.8912999629974365, 1.8911999464035034, 1.8907999992370605, 1.8907999992370605, 1.8907999992370605, 1.8905999660491943, 1.8905999660491943, 1.8905999660491943, 1.8904999494552612, 1.8904000520706177, 1.8902000188827515, 1.88919997215271, 1.88919997215271, 1.8890000581741333, 1.888800024986267, 1.870300054550171, 1.8791999816894531, 1.8444000482559204, 1.8554999828338623, 1.8351999521255493, 1.8121999502182007, 1.8163000345230103, 1.8151999711990356, 1.7297999858856201, 1.6933000087738037, 1.7005000114440918, 1.7776999473571777, 1.6259000301361084, 1.6581000089645386, 1.6627999544143677, 1.7512999773025513, 1.3517999649047852, 1.6303999423980713, 1.7138999700546265, 1.5672999620437622, 1.5322999954223633, 1.4316999912261963, 1.777899980545044, 1.6629999876022339, 1.2755000591278076, 1.7009999752044678, 1.6878999471664429, 1.1821000576019287, 1.3806999921798706, 1.3693000078201294, 1.4413000345230103, 1.3509999513626099, 1.3207999467849731, 1.506100058555603, 1.3244999647140503, 1.235200047492981, 1.1601999998092651, 1.4534000158309937, 0.9900000095367432, 0.765999972820282, 0.6304000020027161, 1.3092999458312988, 0.7773000001907349, 0.9383999705314636, 0.6818000078201294, 0.06350000202655792, 1.0509999990463257, 0.9006999731063843, 0.12639999389648438, 0.34150001406669617, 0.6273000240325928, 0.801800012588501, 0.8654000163078308, 0.4034999907016754, 0.27790001034736633, 0.12690000236034393, 0.155799999833107, 0.19949999451637268, -0.4699000120162964, -0.10740000009536743, 0.579200029373169, 0.10350000113248825, -0.10279999673366547, -0.039799999445676804, 2.00570011138916, 2.0055999755859375, 2.0046000480651855, 2.0037999153137207, 2.0025999546051025, 2.0023999214172363, 2.0023999214172363, 2.001499891281128, 2.0013999938964844, 2.001300096511841, 2.001300096511841, 2.000699996948242, 2.000499963760376, 2.0002999305725098, 1.9996999502182007, 1.999500036239624, 1.9990999698638916, 1.9989999532699585, 1.9987000226974487, 1.9987000226974487, 1.9986000061035156, 1.9981000423431396, 1.9979000091552734, 1.9979000091552734, 1.9977999925613403, 1.997499942779541, 1.997499942779541, 1.9970999956130981, 1.9967000484466553, 1.996399998664856, 1.992900013923645, 1.9860999584197998, 1.9465999603271484, 1.9444999694824219, 1.9671000242233276, 1.9812999963760376, 1.951200008392334, 1.8180999755859375, 1.9223999977111816, 1.9443000555038452, 1.9519000053405762, 1.7862999439239502, 1.8846999406814575, 1.8050999641418457, 1.8244999647140503, 1.763800024986267, 1.6854000091552734, 1.729200005531311, 1.7245999574661255, 1.7007999420166016, 1.7446999549865723, 1.8051999807357788, 1.649899959564209, 1.757200002670288, 1.347499966621399, 1.3114999532699585, 1.531599998474121, 1.364300012588501, 1.0252000093460083, 1.5188000202178955, 0.5196999907493591, 1.0511000156402588, 0.6276999711990356, 0.7231000065803528, 1.0743999481201172, 0.4374000132083893, 0.23810000717639923, 1.1169999837875366, 0.8014000058174133, 0.5810999870300293, 0.7078999876976013, -0.011800000444054604, 0.6255999803543091, 0.06970000267028809, 0.609499990940094, 0.16509999334812164, 0.5189999938011169, 2.4173998832702637, 2.416800022125244, 2.415600061416626, 2.4138998985290527, 2.4138998985290527, 2.4135000705718994, 2.4128000736236572, 2.4126999378204346, 2.4124999046325684, 2.4121999740600586, 2.4121999740600586, 2.412100076675415, 2.411900043487549, 2.40939998626709, 2.408799886703491, 2.4086999893188477, 2.408600091934204, 2.408400058746338, 2.4082999229431152, 2.4082000255584717, 2.407900094985962, 2.4077999591827393, 2.4077999591827393, 2.4075000286102295, 2.4072000980377197, 2.406899929046631, 2.4066998958587646, 2.4063000679016113, 2.4063000679016113, 2.4059998989105225, 2.398699998855591, 2.3117001056671143, 2.248199939727783, 2.3678998947143555, 2.276700019836426, 2.2356998920440674, 2.300800085067749, 2.1974000930786133, 2.3570001125335693, 2.302999973297119, 2.3313000202178955, 2.3178999423980713, 2.110300064086914, 2.325000047683716, 2.30049991607666, 2.151700019836426, 2.251499891281128, 1.9980000257492065, 2.062999963760376, 2.178299903869629, 2.1266000270843506, 1.9377000331878662, 2.0037999153137207, 1.7365000247955322, 1.5851999521255493, 1.8859000205993652, 2.047300100326538, 1.8480000495910645, 1.7851999998092651, 1.261199951171875, 1.9602999687194824, 1.9170000553131104, 1.7724000215530396, 1.2999000549316406, 1.3753000497817993, 0.9664000272750854, 0.14139999449253082, 0.8722000122070312, 0.9995999932289124, 0.7727000117301941, 0.4521999955177307, 0.6532999873161316, 0.7365999817848206, 1.0154999494552612, 0.8744999766349792, 0.8827000260353088, 0.7394000291824341, 0.3864000141620636, 0.9686999917030334, -0.19779999554157257, 0.6151999831199646, -0.20579999685287476, 2.45740008354187, 2.4565999507904053, 2.456399917602539, 2.455199956893921, 2.4546000957489014, 2.4544999599456787, 2.4544999599456787, 2.4542999267578125, 2.4540998935699463, 2.4537999629974365, 2.4528000354766846, 2.4523000717163086, 2.452199935913086, 2.4518001079559326, 2.4516000747680664, 2.4514000415802, 2.4509999752044678, 2.4507999420166016, 2.4505999088287354, 2.4505999088287354, 2.4505999088287354, 2.450500011444092, 2.450200080871582, 2.4495999813079834, 2.449199914932251, 2.448899984359741, 2.448199987411499, 2.4481000900268555, 2.447700023651123, 2.447000026702881, 2.4426000118255615, 2.4094998836517334, 2.396699905395508, 2.3980000019073486, 2.3447000980377197, 2.332900047302246, 2.186000108718872, 2.138200044631958, 2.392699956893921, 1.983199954032898, 1.9645999670028687, 1.9865000247955322, 1.9278000593185425, 2.1538000106811523, 1.9375, 2.2771999835968018, 2.305500030517578, 1.5231000185012817, 2.2602999210357666, 2.003700017929077, 1.7029999494552612, 2.1605000495910645, 1.916700005531311, 1.3249000310897827, 1.5343999862670898, 1.5302000045776367, 1.437000036239624, 1.4648000001907349, 1.688599944114685, 1.8178999423980713, 1.6466000080108643, 2.2121999263763428, 1.347499966621399, 1.4407000541687012, 1.3386000394821167, 1.499500036239624, 0.9782999753952026, 1.0164999961853027, 0.9322999715805054, 0.8019000291824341, 0.9333000183105469, 1.0389000177383423, 0.9659000039100647, 0.917900025844574, 0.13979999721050262, 0.6366999745368958, 0.9061999917030334, 0.5343000292778015, -0.20010000467300415, -0.06970000267028809, 3.6407999992370605, 3.6398000717163086, 3.6391000747680664, 3.6380999088287354, 3.637399911880493, 3.636899948120117, 3.6364998817443848, 3.6361000537872314, 3.635499954223633, 3.6352999210357666, 3.6349000930786133, 3.6345999240875244, 3.6333999633789062, 3.6314001083374023, 3.631200075149536, 3.6303999423980713, 3.6303999423980713, 3.630199909210205, 3.6298999786376953, 3.628999948501587, 3.628700017929077, 3.6282999515533447, 3.628200054168701, 3.6275999546051025, 3.627500057220459, 3.6268999576568604, 3.6268999576568604, 3.6268999576568604, 3.626800060272217, 3.625999927520752, 3.591399908065796, 3.615000009536743, 3.562299966812134, 3.4732000827789307, 3.5139999389648438, 3.4316999912261963, 3.575200080871582, 3.3148999214172363, 3.1867001056671143, 3.4084999561309814, 3.4045000076293945, 3.3622000217437744, 3.3666000366210938, 3.357599973678589, 3.5100998878479004, 3.178999900817871, 2.427999973297119, 2.9486000537872314, 2.5569000244140625, 3.382200002670288, 2.713099956512451, 1.4522000551223755, 0.9785000085830688, 2.80679988861084, 1.1934000253677368, 1.7960000038146973, 2.4549999237060547, 2.8505001068115234, 1.1536999940872192, 0.6409000158309937, 2.5764999389648438, 1.3769999742507935, 0.8324000239372253, 0.8094000220298767, 0.92330002784729, 3.666800022125244, 3.6666998863220215, 3.6659998893737793, 3.662899971008301, 3.6628000736236572, 3.6628000736236572, 3.6623001098632812, 3.6612000465393066, 3.6605000495910645, 3.660399913787842, 3.659899950027466, 3.65939998626709, 3.658900022506714, 3.658600091934204, 3.6577999591827393, 3.6572999954223633, 3.656899929046631, 3.656599998474121, 3.6556999683380127, 3.6549999713897705, 3.653899908065796, 3.653700113296509, 3.65339994430542, 3.6533000469207764, 3.6524999141693115, 3.6524999141693115, 3.652100086212158, 3.651700019836426, 3.65120005607605, 3.6510000228881836, 3.6396000385284424, 3.462899923324585, 3.5611000061035156, 3.5116000175476074, 3.555500030517578, 3.3882999420166016, 3.519700050354004, 2.9377999305725098, 3.104599952697754, 3.3738999366760254, 3.25219988822937, 2.4616000652313232, 3.018699884414673, 2.7330000400543213, 3.069200038909912, 2.809299945831299, 2.5139000415802, 2.7834999561309814, 2.461400032043457, 2.5655999183654785, 3.1249001026153564, 2.3984999656677246, 3.0083999633789062, 2.402899980545044, 1.9831000566482544, 2.7994000911712646, 1.4279999732971191, 1.7519999742507935, 1.2640000581741333, 0.7325000166893005, 3.777100086212158, 3.7769999504089355, 3.776900053024292, 3.7764999866485596, 3.775399923324585, 3.7750000953674316, 3.7746999263763428, 3.7736001014709473, 3.773200035095215, 3.772599935531616, 3.7725000381469727, 3.7725000381469727, 3.7720999717712402, 3.7720999717712402, 3.7711000442504883, 3.770900011062622, 3.7704999446868896, 3.768399953842163, 3.768199920654297, 3.768199920654297, 3.767899990081787, 3.7678000926971436, 3.7669999599456787, 3.7667999267578125, 3.7665998935699463, 3.766200065612793, 3.7660999298095703, 3.765700101852417, 3.7655999660491943, 3.765399932861328, 3.749500036239624, 3.726900100708008, 3.746500015258789, 3.644399881362915, 3.6682000160217285, 3.732100009918213, 3.4809000492095947, 3.6175999641418457, 3.1705000400543213, 3.6816000938415527, 3.5227999687194824, 3.2202000617980957, 3.211199998855591, 2.4795000553131104, 3.056999921798706, 2.8334999084472656, 2.5725998878479004, 2.2320001125335693, 1.8288999795913696, 3.2655999660491943, 2.4274001121520996, 1.9325000047683716, 2.6621999740600586, 0.9900000095367432, 2.135999917984009, 0.44029998779296875, 0.6776999831199646, 1.332200050354004, 0.845300018787384, 1.332800030708313, 1.461400032043457, 4.0817999839782715, 4.081600189208984, 4.081200122833252, 4.0808000564575195, 4.080100059509277, 4.079800128936768, 4.079500198364258, 4.079400062561035, 4.077400207519531, 4.0767998695373535, 4.076600074768066, 4.075699806213379, 4.075699806213379, 4.075200080871582, 4.074900150299072, 4.07480001449585, 4.074699878692627, 4.074699878692627, 4.073800086975098, 4.073299884796143, 4.0731000900268555, 4.072800159454346, 4.072500228881836, 4.072400093078613, 4.072400093078613, 4.072299957275391, 4.0721001625061035, 4.071199893951416, 4.071100234985352, 4.071000099182129, 3.929500102996826, 3.8489999771118164, 3.9630000591278076, 3.696000099182129, 3.404400110244751, 3.498500108718872, 3.7091000080108643, 3.377500057220459, 3.0169999599456787, 3.083899974822998, 3.565000057220459, 3.4827001094818115, 2.402899980545044, 2.3427000045776367, 2.219599962234497, 3.3912999629974365, 2.8708999156951904, 3.222899913787842, 0.7739999890327454, 3.1988000869750977, 2.121500015258789, 1.5257999897003174, 2.627000093460083, 2.4065001010894775, 2.7002999782562256, 2.6061999797821045, -0.07980000227689743, 4.235099792480469, 4.233399868011475, 4.2322998046875, 4.232100009918213, 4.231599807739258, 4.231100082397461, 4.231100082397461, 4.2307000160217285, 4.230400085449219, 4.2281999588012695, 4.22790002822876, 4.227799892425537, 4.227200031280518, 4.227099895477295, 4.227099895477295, 4.2266998291015625, 4.2266998291015625, 4.226600170135498, 4.226099967956543, 4.22599983215332, 4.2256999015808105, 4.225599765777588, 4.223800182342529, 4.223700046539307, 4.223599910736084, 4.223299980163574, 4.2230000495910645, 4.222300052642822, 4.22189998626709, 4.221799850463867, 4.152599811553955, 3.8299999237060547, 3.3828001022338867, 3.8320000171661377, 3.7834999561309814, 3.8273000717163086, 3.642699956893921, 3.50570011138916, 2.975399971008301, 3.05049991607666, 3.339600086212158, 3.582900047302246, 3.2416999340057373, 3.1649999618530273, 2.4951999187469482, 3.400700092315674, 2.4351000785827637, 3.5130999088287354, 2.662400007247925, 0.24120000004768372, 2.38100004196167, 1.8013999462127686, 4.2617998123168945, 4.2596001625061035, 4.258900165557861, 4.258399963378906, 4.258399963378906, 4.2581000328063965, 4.256800174713135, 4.25570011138916, 4.255300045013428, 4.254799842834473, 4.254799842834473, 4.25439977645874, 4.2540998458862305, 4.253300189971924, 4.253200054168701, 4.252799987792969, 4.252600193023682, 4.252600193023682, 4.252399921417236, 4.251699924468994, 4.2505998611450195, 4.249800205230713, 4.24970006942749, 4.248700141906738, 4.248600006103516, 4.248600006103516, 4.248499870300293, 4.248199939727783, 4.248000144958496, 4.247799873352051, 3.9214999675750732, 4.114799976348877, 3.7952001094818115, 3.462599992752075, 3.88919997215271, 2.856100082397461, 4.158400058746338, 2.859999895095825, 1.2609000205993652, 2.9316999912261963, 2.9170000553131104, 1.937000036239624, 0.7069000005722046, 2.9426000118255615, 0.6589999794960022, 4.278900146484375, 4.2778000831604, 4.277599811553955, 4.276800155639648, 4.276500225067139, 4.276100158691406, 4.275899887084961, 4.273799896240234, 4.27370023727417, 4.273399829864502, 4.2733001708984375, 4.273099899291992, 4.272500038146973, 4.2718000411987305, 4.271399974822998, 4.270599842071533, 4.270199775695801, 4.269499778747559, 4.269000053405762, 4.268499851226807, 4.2683000564575195, 4.2683000564575195, 4.267899990081787, 4.267499923706055, 4.267199993133545, 4.267099857330322, 4.267099857330322, 4.266900062561035, 4.266900062561035, 4.26669979095459, 4.207600116729736, 4.173900127410889, 4.180699825286865, 4.093800067901611, 4.0524001121521, 3.9493000507354736, 3.5362000465393066, 3.6031999588012695, 4.00570011138916, 3.4284000396728516, 2.958899974822998, 3.312700033187866, 3.64490008354187, 2.4904000759124756, 2.49180006980896, -0.02449999935925007, 2.324399948120117, 2.5344998836517334, 4.34630012512207, 4.3460001945495605, 4.343699932098389, 4.3429999351501465, 4.3429999351501465, 4.34250020980835, 4.342400074005127, 4.341700077056885, 4.341000080108643, 4.34089994430542, 4.340199947357178, 4.339399814605713, 4.339200019836426, 4.339099884033203, 4.338799953460693, 4.3383002281188965, 4.337900161743164, 4.336400032043457, 4.335100173950195, 4.334499835968018, 4.3343000411987305, 4.3343000411987305, 4.334099769592285, 4.333899974822998, 4.333799839019775, 4.333799839019775, 4.333499908447266, 4.333099842071533, 4.333000183105469, 4.332900047302246, 4.313199996948242, 4.25, 4.28249979019165, 4.273900032043457, 4.309999942779541, 4.242599964141846, 3.871000051498413, 3.9131999015808105, 3.5035998821258545, 3.8236000537872314, 3.3382999897003174, 3.2585999965667725, 3.110100030899048, 2.771199941635132, 3.289599895477295, 0.7003999948501587, 1.1474000215530396, 3.0151000022888184, 1.940000057220459, 2.3259999752044678, 2.036400079727173, 4.354400157928467, 4.3516998291015625, 4.3516998291015625, 4.351600170135498, 4.3506999015808105, 4.350599765777588, 4.348899841308594, 4.348800182342529, 4.348400115966797, 4.34689998626709, 4.346799850463867, 4.345900058746338, 4.3454999923706055, 4.345399856567383, 4.344299793243408, 4.344099998474121, 4.343699932098389, 4.343200206756592, 4.342700004577637, 4.341800212860107, 4.340799808502197, 4.340700149536133, 4.339700222015381, 4.338699817657471, 4.338399887084961, 4.3379998207092285, 4.337800025939941, 4.337100028991699, 4.337100028991699, 4.336599826812744, 4.317599773406982, 4.258600234985352, 4.136600017547607, 4.280399799346924, 4.149799823760986, 4.248300075531006, 4.2322998046875, 4.19920015335083, 4.224800109863281, 3.9946999549865723, 4.020100116729736, 3.432499885559082, 2.9809000492095947, 3.6982998847961426, 4.184100151062012, 3.517699956893921, 3.769399881362915, 1.8062000274658203, 3.205199956893921, 1.6334999799728394, 2.6846001148223877, 2.1988000869750977, 2.276700019836426, 3.6977999210357666, 2.1970999240875244, 2.579400062561035, 1.7683000564575195]}, \"token.table\": {\"Topic\": [10, 12, 3, 4, 6, 1, 2, 4, 7, 8, 14, 1, 2, 3, 4, 6, 1, 2, 4, 5, 7, 8, 10, 12, 13, 15, 1, 2, 3, 4, 6, 7, 8, 10, 14, 1, 2, 4, 6, 8, 10, 14, 1, 2, 3, 4, 5, 8, 9, 2, 8, 10, 14, 12, 3, 6, 11, 4, 5, 6, 7, 11, 13, 14, 15, 1, 2, 5, 6, 8, 11, 5, 11, 13, 15, 9, 3, 4, 5, 8, 1, 2, 6, 14, 1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 11, 2, 9, 2, 8, 10, 11, 15, 1, 2, 4, 5, 7, 10, 12, 15, 6, 7, 10, 13, 2, 7, 9, 1, 2, 4, 5, 3, 4, 8, 15, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 13, 4, 12, 9, 5, 8, 11, 12, 15, 2, 1, 2, 3, 4, 9, 10, 12, 15, 6, 1, 2, 3, 4, 5, 6, 9, 10, 2, 8, 1, 2, 4, 5, 10, 2, 4, 12, 1, 3, 4, 6, 7, 13, 15, 1, 2, 4, 9, 14, 9, 12, 6, 13, 1, 1, 13, 15, 2, 3, 4, 5, 7, 8, 11, 12, 15, 5, 5, 3, 1, 3, 6, 3, 12, 11, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 1, 2, 3, 4, 5, 6, 7, 10, 12, 6, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 4, 11, 6, 13, 7, 2, 4, 5, 10, 15, 10, 4, 9, 7, 8, 2, 3, 4, 4, 8, 2, 6, 11, 1, 3, 4, 5, 6, 14, 1, 3, 4, 5, 6, 7, 11, 6, 6, 3, 7, 1, 2, 3, 6, 10, 14, 13, 1, 2, 4, 8, 11, 9, 1, 2, 3, 5, 7, 8, 11, 13, 5, 9, 7, 9, 8, 6, 14, 14, 15, 6, 8, 1, 2, 4, 5, 7, 15, 5, 8, 15, 12, 5, 1, 4, 8, 13, 3, 9, 4, 15, 2, 5, 4, 1, 4, 5, 6, 7, 6, 5, 7, 13, 9, 14, 12, 12, 11, 5, 15, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 1, 4, 5, 7, 10, 13, 15, 10, 3, 12, 10, 15, 12, 8, 9, 2, 1, 2, 3, 4, 5, 6, 7, 10, 4, 7, 11, 12, 15, 4, 5, 8, 9, 10, 2, 14, 1, 15, 13, 1, 1, 3, 4, 15, 1, 3, 5, 6, 9, 15, 4, 1, 2, 3, 4, 3, 5, 7, 8, 9, 13, 11, 2, 11, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 1, 2, 5, 6, 8, 9, 10, 14, 1, 2, 4, 5, 6, 7, 9, 14, 15, 8, 13, 12, 9, 10, 13, 3, 4, 5, 8, 7, 2, 4, 5, 14, 2, 3, 4, 5, 3, 7, 8, 1, 4, 5, 6, 10, 3, 5, 8, 4, 3, 12, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 13, 5, 6, 7, 1, 4, 1, 2, 4, 5, 12, 1, 2, 4, 6, 1, 2, 4, 5, 14, 2, 4, 15, 6, 1, 2, 3, 5, 11, 1, 1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 8, 10, 1, 4, 9, 11, 6, 9, 13, 14, 6, 9, 3, 10, 3, 3, 4, 6, 7, 2, 3, 4, 6, 7, 9, 11, 1, 2, 3, 4, 5, 6, 8, 15, 1, 6, 7, 13, 1, 3, 4, 5, 6, 8, 10, 11, 15, 3, 5, 8, 3, 4, 9, 2, 3, 5, 8, 1, 2, 3, 5, 5, 13, 12, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 3, 1, 2, 3, 4, 5, 1, 3, 5, 13, 1, 7, 10, 15, 3, 3, 5, 9, 11, 8, 6, 10, 12, 3, 2, 5, 7, 9, 1, 4, 5, 1, 11, 14, 9, 1, 2, 4, 5, 6, 9, 13, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 15, 1, 2, 3, 4, 5, 14, 13, 8, 13, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 14, 14, 2, 3, 4, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 2, 4, 5, 8, 12, 15, 5, 6, 7, 12, 1, 2, 3, 5, 6, 8, 11, 14, 1, 2, 5, 7, 10, 9, 6, 7, 1, 3, 4, 5, 6, 7, 8, 15, 2, 3, 6, 7, 9, 10, 12, 5, 4, 1, 2, 3, 4, 5, 9, 12, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 3, 4, 6, 7, 1, 2, 4, 6, 9, 10, 10, 3, 4, 6, 7, 11, 13, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 15, 2, 1, 2, 4, 6, 2, 5, 11, 1, 3, 4, 5, 8, 11, 12, 11, 5, 7, 3, 4, 5, 9, 11, 12, 1, 4, 11, 12, 7, 2, 11, 7, 2, 3, 7, 8, 10, 13, 5, 7, 2, 3, 6, 7, 9, 11, 12, 13, 14, 12, 1, 2, 3, 5, 8, 10, 13, 14, 1, 3, 4, 5, 6, 15, 3, 4, 13, 1, 5, 6, 8, 10, 14, 15, 5, 7, 1, 5, 6, 14, 1, 3, 6, 10, 13, 14, 12, 1, 5, 7, 7, 12, 14, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 6, 8, 8, 1, 2, 3, 4, 5, 6, 7, 9, 10, 2, 4, 1, 4, 5, 8, 11, 12, 1, 14, 1, 3, 4, 6, 7, 9, 10, 12, 14, 1, 2, 3, 4, 5, 6, 8, 4, 9, 11, 13, 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 15, 4, 4, 12, 1, 2, 4, 5, 6, 11, 6, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 13, 2, 5, 4, 10, 12, 1, 4, 5, 6, 7, 3, 9, 12, 3, 5, 1, 4, 7, 9, 2, 9, 11, 6, 7, 9, 10, 13, 7, 1, 8, 7, 9, 9, 1, 2, 3, 4, 5, 6, 7, 9, 11, 1, 2, 3, 4, 5, 6, 9, 13, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 3, 6, 2, 3, 8, 11, 1, 2, 3, 5, 8, 9, 11, 6, 2, 6, 8, 5, 11, 11, 10, 12, 11, 14, 1, 3, 4, 5, 6, 8, 4, 5, 14, 1, 4, 2, 4, 5, 7, 8, 11, 4, 5, 6, 8, 14, 4, 1, 2, 4, 5, 1, 3, 4, 5, 6, 12, 6, 7, 9, 10, 11, 13, 3, 5, 8, 1, 2, 3, 4, 5, 3, 4, 6, 7, 11, 2, 4, 5, 13, 15, 1, 2, 3, 4, 5, 9, 1, 13, 1, 2, 3, 5, 14, 4, 1, 3, 1, 2, 3, 4, 5, 6, 8, 2, 3, 4, 5, 6, 8, 12, 14, 13, 1, 2, 3, 5, 8, 4, 5, 6, 7, 9, 12, 15, 15, 14, 10, 11, 15, 1, 2, 8, 10, 14, 15, 9, 13, 2, 5, 6, 7, 11, 12, 14, 15, 5, 6, 7, 10, 2, 5, 8, 12, 13, 1, 4, 6, 10, 11, 3, 10, 11, 12, 13, 14, 15, 3, 4, 5, 6, 13, 14, 2, 1, 4, 5, 6, 7, 10, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 4, 6, 7, 12, 1, 5, 6, 8, 10, 6, 4, 6, 8, 10, 3, 6, 10, 14, 5, 10, 9, 13, 10, 4, 6, 8, 15, 1, 4, 7, 11, 13, 12, 1, 4, 6, 7, 15, 7, 1, 3, 4, 6, 8, 4, 15, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 15, 1, 4, 1, 2, 3, 4, 5, 6, 9, 9, 12, 15, 5, 1, 1, 2, 3, 4, 5, 11, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 14, 9, 13, 14, 14, 4, 6, 7, 14, 6, 1, 2, 3, 4, 5, 6, 9, 5, 1, 15, 1, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 8, 8, 7, 14, 3, 5, 6, 7, 13, 15, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 6, 1, 2, 3, 6, 8, 10, 14, 1, 12, 7, 2, 4, 9, 9, 14, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 15, 13, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 12, 5, 6, 7, 10, 14, 6, 7, 10, 3, 6, 7, 10, 14, 6, 7, 11, 10, 12, 15, 9, 14, 11, 4, 7, 8, 2, 3, 4, 6, 10, 11, 13, 1, 2, 7, 11, 12, 15, 1, 2, 3, 4, 5, 15, 1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 6, 6, 12, 14, 13, 1, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 10, 1, 3, 5, 8, 4, 12, 13, 1, 2, 4, 5, 6, 10, 11, 14, 15, 2, 4, 5, 8, 11, 12, 1, 13, 1, 2, 4, 5, 9, 10, 7, 11, 7, 1, 2, 4, 5, 6, 7, 8, 11, 13, 5, 12, 4, 12, 14, 1, 6, 7, 8, 9, 13, 1, 2, 3, 5, 6, 8, 10, 7, 14, 1, 3, 4, 6, 7, 2, 12, 5, 13, 12, 3, 4, 6, 7, 8, 14, 10, 5, 15, 1, 2, 3, 4, 7, 9, 10, 15, 3, 11, 1, 2, 3, 4, 5, 6, 7, 8, 8, 14, 11, 3, 1, 5, 6, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 2, 14, 6, 12, 10, 7, 7, 14, 3, 2, 3, 8, 10, 14, 5, 1, 2, 3, 4, 5, 6, 7, 9, 10, 14, 15, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 2, 14, 15, 1, 2, 4, 5, 6, 7, 9, 10, 15, 15, 2, 6, 11, 2, 3, 4, 5, 6, 10, 8, 13, 4, 1, 3, 6, 1, 3, 4, 5, 6, 8, 10, 12, 1, 3, 4, 5, 2, 3, 4, 14, 6, 8, 1, 8, 13, 11, 15, 1, 2, 3, 4, 5, 8, 7, 3, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 11, 1, 2, 3, 4, 5, 6, 9, 15, 2, 3, 7, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 5, 8, 11, 6, 13, 2, 8, 12, 13, 15, 14, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, 5, 8, 11, 12, 14, 15, 2, 4, 5, 12, 1, 2, 3, 5, 6, 7, 9, 11, 12, 1, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 8, 11, 9, 3, 4, 5, 6, 8, 14, 7, 9, 2, 1, 2, 3, 5, 6, 7, 8, 11, 3, 13, 1, 2, 3, 4, 5, 6, 7, 8, 15, 4, 1, 2, 3, 4, 5, 8, 9, 1, 2, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 3, 5, 2, 5, 3, 8, 4, 4, 10, 5, 9, 4, 12, 6, 1, 2, 4, 5, 6, 10, 11, 13, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 1, 3, 5, 9, 11, 4, 7, 10, 13, 15, 6, 10, 11, 4, 7, 13, 8, 1, 2, 3, 4, 5, 6, 7, 11, 12, 1, 2, 3, 5, 14, 1, 2, 3, 4, 5, 6, 8, 9, 11, 10, 2, 3, 6, 1, 2, 4, 5, 6, 8, 9, 1, 3, 4, 3, 2, 1, 2, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 15, 6, 7, 1, 5, 15, 8, 9, 11, 15, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 14, 4, 12, 1, 2, 4, 6, 9, 15, 5, 4, 6, 7, 12, 15, 1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 2, 9, 2, 3, 6, 8, 10, 9, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 7, 8, 8, 2, 4, 6, 8, 9, 14, 6, 8, 6, 15, 10, 6, 6, 3, 4, 5, 15, 1, 4, 4, 1, 2, 4, 7, 1, 2, 6, 7, 8, 10, 13, 15, 2, 4, 5, 12, 4, 5, 8, 12, 14, 4, 6, 7, 10, 11, 14, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 4, 5, 6, 7, 14, 1, 1, 6, 7, 15, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 8, 9, 6, 1, 2, 3, 4, 5, 9, 14, 13, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 14, 1, 3, 4, 6, 10, 15, 14, 5, 13, 11, 1, 14, 4, 5, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 8, 9, 11, 1, 8, 12, 1, 7, 9, 10, 6, 9, 15, 10, 1, 3, 4, 6, 11, 12, 5, 4, 5, 2, 4, 15, 15, 6, 7, 15, 11, 3, 6, 8, 1, 3, 4, 2, 8, 1, 3, 4, 6, 7, 13, 6, 7, 9, 10, 1, 2, 5, 2, 1, 2, 3, 4, 5, 7, 9, 1, 2, 4, 6, 9, 13, 8, 3, 4, 5, 14, 11, 4, 13, 1, 2, 3, 4, 5, 8, 9, 3, 4, 15, 1, 4, 7, 11, 12, 13, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 9, 7, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 8, 9, 11, 4, 5, 9, 10, 11, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 12, 1, 4, 1, 2, 1, 2, 3, 5, 5, 1, 4, 1, 3, 4, 8, 15, 2, 6, 13, 2, 4, 15, 2, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 15, 7, 5, 4, 7, 8, 1, 2, 4, 5, 6, 7, 10, 11, 12, 7, 1, 2, 5, 6, 9, 11, 1, 2, 4, 8, 4, 5, 14, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 6, 9, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 7, 1, 4, 5, 6, 7, 9, 10, 11, 13, 6, 10, 11, 11, 14, 9, 8, 4, 3, 4, 5, 6, 7, 8, 1, 2, 4, 15, 14, 14, 14, 1, 2, 3, 5, 6, 9, 11, 1, 4, 5, 8, 11, 12, 13, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 4, 6, 7, 10, 10, 7, 5, 6, 1, 2, 3, 4, 5, 7, 12, 4, 10, 4, 5, 10, 11, 12, 6, 11, 9, 8, 13, 1, 2, 4, 5, 7, 9, 10, 12, 14, 3, 4, 1, 2, 4, 5, 9, 12, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 3, 2, 4, 6, 7, 8, 10, 13, 15, 10, 1, 1, 2, 3, 4, 4, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 14, 15, 12, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 4, 6, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 3, 5, 8, 6, 1, 2, 4, 5, 6, 11, 1, 2, 4, 5, 14, 7, 15, 9, 4, 10, 12, 15, 5, 6, 7, 8, 11, 13, 2, 3, 5, 7, 8, 11, 13, 1, 1, 3, 4, 6, 7, 8, 14, 15, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 6, 8, 10, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 14, 1, 2, 3, 4, 5, 7, 13, 5, 11, 15, 3, 4, 15, 4, 5, 8, 12, 1, 3, 4, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 1, 2, 3, 4, 5, 8, 1, 2, 4, 5, 1, 2, 10, 11, 10, 10, 8, 11, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 2, 3, 4, 6, 7, 8, 10, 11, 2, 1, 4], \"Freq\": [0.9936569333076477, 0.9795193076133728, 0.9194377064704895, 0.06229252740740776, 0.01744190789759159, 0.27593594789505005, 0.34147074818611145, 0.02414439618587494, 0.033342260867357254, 0.28053489327430725, 0.04368986189365387, 0.5410670042037964, 0.34326472878456116, 0.026892218738794327, 0.06778617203235626, 0.021002599969506264, 0.15854410827159882, 0.4998023808002472, 0.2065964937210083, 0.04488725960254669, 0.0020141720306128263, 0.005467038135975599, 0.00028773886151611805, 0.014962420798838139, 0.0023019108921289444, 0.06560445576906204, 0.39841175079345703, 0.5005322098731995, 0.0055315266363322735, 0.0046805222518742085, 0.05460609495639801, 0.018863923847675323, 0.004396854434162378, 0.005957028362900019, 0.006949866656213999, 0.1606016755104065, 0.28188592195510864, 0.021324703469872475, 0.443153977394104, 0.0006663969834335148, 0.07463645935058594, 0.016659924760460854, 0.5474458336830139, 0.16167981922626495, 0.05766923725605011, 0.1552950143814087, 0.07497000694274902, 0.0022655772045254707, 0.0004119231307413429, 0.8595399260520935, 0.060701970010995865, 0.05705985426902771, 0.021852709352970123, 0.979410707950592, 0.9934973120689392, 0.990398108959198, 0.9928557276725769, 0.33883029222488403, 0.2458585649728775, 0.0743773803114891, 0.10330191254615784, 0.02892453595995903, 0.17354722321033478, 0.012396230362355709, 0.022726422175765038, 0.08045510947704315, 0.058412615209817886, 0.6535599827766418, 0.09478273242712021, 0.029757369309663773, 0.08265936374664307, 0.2281964272260666, 0.43006250262260437, 0.33790624141693115, 0.9850798845291138, 0.9894613027572632, 0.002847789553925395, 0.8173156380653381, 0.1784614771604538, 0.9919079542160034, 0.025708846747875214, 0.9683665037155151, 0.9504539370536804, 0.04752269759774208, 0.09374641627073288, 0.10399400442838669, 0.2273445576429367, 0.02163378894329071, 0.18597467243671417, 0.03567677363753319, 0.2994571924209595, 0.004934022203087807, 0.004174941685050726, 0.023531489074230194, 0.9762822985649109, 0.9835909008979797, 0.9932588338851929, 0.2570798993110657, 0.17138659954071045, 0.4970211386680603, 0.047131314873695374, 0.025707989931106567, 0.13397642970085144, 0.21711358428001404, 0.00119621807243675, 0.5036078095436096, 0.054427921772003174, 0.014354617334902287, 0.03588654473423958, 0.03887708857655525, 0.47709283232688904, 0.10183009505271912, 0.36771976947784424, 0.05280078947544098, 0.11216969788074493, 0.7582671642303467, 0.12563006579875946, 0.7833974957466125, 0.08554795384407043, 0.12673771381378174, 0.003168442752212286, 0.32536500692367554, 0.21157614886760712, 0.4124845862388611, 0.04978262260556221, 0.9876834154129028, 0.9912030100822449, 0.10715363174676895, 0.2444690316915512, 0.10278811305761337, 0.17343014478683472, 0.16271477937698364, 0.07580127567052841, 0.0829448476433754, 0.0007937306072562933, 0.010715363547205925, 0.0035717878490686417, 0.01349342055618763, 0.0035717878490686417, 0.018652670085430145, 0.9866938591003418, 0.9927244186401367, 0.9934119582176208, 0.9916657209396362, 0.20012450218200684, 0.569919764995575, 0.0630827248096466, 0.09136117994785309, 0.07613431662321091, 0.9857758283615112, 0.11907219886779785, 0.26972153782844543, 0.43287017941474915, 0.031577158719301224, 0.006578574422746897, 0.023025009781122208, 0.0013157149078324437, 0.11578290909528732, 0.9918306469917297, 0.15219537913799286, 0.3163774907588959, 0.38175976276397705, 0.0003632347797974944, 0.13948215544223785, 0.0029058782383799553, 0.006174991372972727, 0.9931612610816956, 0.2394932508468628, 0.757107675075531, 0.8680165410041809, 0.01814984902739525, 0.09347172826528549, 0.010889910161495209, 0.008621178567409515, 0.9863848686218262, 0.08237166702747345, 0.9060883522033691, 0.31329280138015747, 0.014312868937849998, 0.14789964258670807, 0.2528606951236725, 0.10496103763580322, 0.1415383666753769, 0.02226446382701397, 0.8358279466629028, 0.031209444627165794, 0.13283519446849823, 0.9949337840080261, 0.9915589094161987, 0.9466361999511719, 0.052884701639413834, 0.08685504645109177, 0.9011211395263672, 0.9906037449836731, 0.23357033729553223, 0.7546118497848511, 0.9909628629684448, 0.1116265282034874, 0.029587754979729652, 0.12642040848731995, 0.13448978960514069, 0.008069387637078762, 0.39271020889282227, 0.05245101824402809, 0.07934898138046265, 0.06724489480257034, 0.9877200126647949, 0.9819034337997437, 0.9888136982917786, 0.06190979480743408, 0.8602203130722046, 0.0749434307217598, 0.9936296343803406, 0.9937677383422852, 0.9881500005722046, 0.9842057228088379, 0.9901151657104492, 0.19042713940143585, 0.4560486078262329, 0.01835913024842739, 0.007226466201245785, 0.030077723786234856, 0.21718460321426392, 0.018554439768195152, 0.011523284018039703, 0.027929315343499184, 0.009179565124213696, 0.00410150783136487, 0.001757789053954184, 0.0027343383990228176, 0.0050780572928488255, 0.5294533371925354, 0.3701636493206024, 0.0013442166382446885, 0.051584310829639435, 0.01730678789317608, 0.024195898324251175, 0.004704758059233427, 0.0006721083191223443, 0.0005040811956860125, 0.9931759238243103, 0.3889405131340027, 0.1897641122341156, 0.07165493071079254, 0.12296714633703232, 0.11294759809970856, 0.060117270797491074, 0.01184128038585186, 0.00819780956953764, 0.024593427777290344, 0.008501431904733181, 0.9935598969459534, 0.9890259504318237, 0.9957787990570068, 0.9944314956665039, 0.9910207986831665, 0.16004590690135956, 0.18585975468158722, 0.12390650808811188, 0.010325542651116848, 0.5162771344184875, 0.9939994215965271, 0.9958212971687317, 0.9867336750030518, 0.9782751202583313, 0.9804849624633789, 0.022473081946372986, 0.03464600071310997, 0.9419966340065002, 0.9389669299125671, 0.05700870603322983, 0.9733654856681824, 0.4771568477153778, 0.5205347537994385, 0.0180094912648201, 0.1923741102218628, 0.736751914024353, 0.002455839654430747, 0.049116794019937515, 0.0008186132181435823, 0.3189965486526489, 0.1926911473274231, 0.06897222250699997, 0.006035069469362497, 0.36081093549728394, 0.011639062315225601, 0.040521182119846344, 0.9959945678710938, 0.9921634793281555, 0.07596323639154434, 0.9207664728164673, 0.05123123154044151, 0.8194085955619812, 0.053268834948539734, 0.048029277473688126, 0.019793884828686714, 0.00815042294561863, 0.9876405596733093, 0.7164154648780823, 0.19486500322818756, 0.08866694569587708, 0.9935339689254761, 0.9775857925415039, 0.9915096163749695, 0.052338432520627975, 0.3128134310245514, 0.008520210161805153, 0.20205070078372955, 0.04381822422146797, 0.3322882056236267, 0.04625256732106209, 0.0024343456607311964, 0.9452144503593445, 0.04573618248105049, 0.14924582839012146, 0.8475030660629272, 0.9943745732307434, 0.8821187615394592, 0.11788683384656906, 0.09079685062170029, 0.9052979946136475, 0.9312980771064758, 0.057754918932914734, 0.31923285126686096, 0.2863771915435791, 0.39382413029670715, 0.9850023984909058, 0.013680589385330677, 0.9937471151351929, 0.9839183688163757, 0.1472315639257431, 0.8441276550292969, 0.9802119731903076, 0.9970673322677612, 0.2584354281425476, 0.10548384487628937, 0.10020965337753296, 0.5274192094802856, 0.9924200773239136, 0.97972172498703, 0.030481092631816864, 0.9652345776557922, 0.9920267462730408, 0.9824202060699463, 0.9964473843574524, 0.11572381854057312, 0.3885514736175537, 0.3506782352924347, 0.14377807080745697, 0.9844518899917603, 0.9877557754516602, 0.9921579957008362, 0.16398803889751434, 0.8270701169967651, 0.060684073716402054, 0.9330176115036011, 0.9803597331047058, 0.984447181224823, 0.9919809103012085, 0.8292688131332397, 0.16851451992988586, 0.11562565714120865, 0.5212223529815674, 0.06506777554750443, 0.0031740376725792885, 0.2242230921983719, 0.049651019275188446, 0.008388528600335121, 0.0011335848830640316, 0.000680150929838419, 0.010655698366463184, 0.20348940789699554, 0.1811055690050125, 0.1444774717092514, 0.06511660665273666, 0.29709452390670776, 0.04680256173014641, 0.059011925011873245, 0.9941180944442749, 0.9930068254470825, 0.9980053305625916, 0.6778960227966309, 0.3196297287940979, 0.9817034602165222, 0.8559455871582031, 0.1426575928926468, 0.9824024438858032, 0.2831194996833801, 0.49206602573394775, 0.15920382738113403, 0.02137647196650505, 0.003189505310729146, 0.0380026176571846, 0.002239439869299531, 0.0006786181475035846, 0.1325361728668213, 0.8089277148246765, 0.020565958693623543, 0.020565958693623543, 0.015995746478438377, 0.15369220077991486, 0.29175469279289246, 0.41939735412597656, 0.01823466829955578, 0.11201296001672745, 0.975825846195221, 0.9786713123321533, 0.9804880619049072, 0.9889657497406006, 0.9835249185562134, 0.986819326877594, 0.08261577039957047, 0.9142811894416809, 0.06023101508617401, 0.927557647228241, 0.10154230147600174, 0.04946932569146156, 0.0937313511967659, 0.7420399188995361, 0.0026036486960947514, 0.010414594784379005, 0.9943494200706482, 0.008372007869184017, 0.7419691681861877, 0.16848665475845337, 0.08058056980371475, 0.32401442527770996, 0.1120423749089241, 0.012112689204514027, 0.548099160194397, 0.976695716381073, 0.9936917424201965, 0.9975267052650452, 0.9893754124641418, 0.9907480478286743, 0.988797128200531, 0.9922419190406799, 0.2907451391220093, 0.136247456073761, 0.18234503269195557, 0.1585882604122162, 0.07221429795026779, 0.14568723738193512, 0.007709151599556208, 0.004405229352414608, 0.0017306258669123054, 0.0001573296176502481, 0.3952219486236572, 0.08511557430028915, 0.04821231588721275, 0.39432913064956665, 0.01607077196240425, 0.0017856414197012782, 0.018749235197901726, 0.0404745377600193, 0.04823455214500427, 0.38008826971054077, 0.0009646910475566983, 0.16110339760780334, 0.12540984153747559, 0.05402269959449768, 0.015435056760907173, 0.09839848428964615, 0.11576292663812637, 0.8592870235443115, 0.12797892093658447, 0.9883359670639038, 0.9904431700706482, 0.006229202263057232, 0.9962451457977295, 0.8856565356254578, 0.04661349952220917, 0.003585653845220804, 0.060956116765737534, 0.9906862378120422, 0.866901159286499, 0.1151353120803833, 0.006772665306925774, 0.9849984645843506, 0.07119809836149216, 0.8836939930915833, 0.03769310936331749, 0.9958306550979614, 0.9949135184288025, 0.7719473242759705, 0.2215774804353714, 0.06644674390554428, 0.7844682335853577, 0.01190090924501419, 0.09818249940872192, 0.03867795318365097, 0.9848939180374146, 0.9870423674583435, 0.9930782914161682, 0.993938148021698, 0.9877350330352783, 0.9942669868469238, 0.7873374223709106, 0.14797258377075195, 0.05487316474318504, 0.009864838793873787, 0.03404810279607773, 0.023347271606326103, 0.36577391624450684, 0.006809620652347803, 0.21012544631958008, 0.027238482609391212, 0.02237446792423725, 0.2996233105659485, 0.0107008321210742, 0.08989779651165009, 0.026969337835907936, 0.8765034675598145, 0.9548470377922058, 0.04444977641105652, 0.9969452619552612, 0.042099278420209885, 0.832964301109314, 0.05262409895658493, 0.07066664844751358, 0.01484217494726181, 0.0784514918923378, 0.8841695785522461, 0.019082795828580856, 0.07283306121826172, 0.11480464786291122, 0.18393433094024658, 0.6159948706626892, 0.011110126972198486, 0.9896413683891296, 0.9971818923950195, 0.9884704351425171, 0.9892355799674988, 0.0371711365878582, 0.002655081218108535, 0.8177649974822998, 0.14071929454803467, 0.9855644106864929, 0.975257933139801, 0.2632218897342682, 0.09055924415588379, 0.15847867727279663, 0.06273682415485382, 0.19202923774719238, 0.21685120463371277, 0.009274139069020748, 0.00327322562225163, 0.003000456839799881, 0.0002727688115555793, 0.0005455376231111586, 0.9937140941619873, 0.9933909177780151, 0.09680645167827606, 0.05324355140328407, 0.1790919452905655, 0.6631242036819458, 0.19146886467933655, 0.7393272519111633, 0.04666047915816307, 0.021721256896853447, 0.22526134550571442, 0.7717286944389343, 0.988908052444458, 0.9859799742698669, 0.9940032958984375, 0.12163858860731125, 0.24476057291030884, 0.5926172733306885, 0.04005173221230507, 0.23839908838272095, 0.05013065040111542, 0.11362947523593903, 0.2807316482067108, 0.005570072215050459, 0.027850361540913582, 0.2829596698284149, 0.14312615990638733, 0.005725046154111624, 0.04465536028146744, 0.7253633737564087, 0.009160073474049568, 0.015457624569535255, 0.04637287184596062, 0.009732578881084919, 0.08935290575027466, 0.8326066136360168, 0.020307477563619614, 0.052799440920352936, 0.017169464379549026, 0.367123544216156, 0.5171038508415222, 0.003534889779984951, 0.05201337859034538, 0.028784101828932762, 0.001514952746219933, 0.002524921204894781, 0.010099684819579124, 0.993599534034729, 0.9813652038574219, 0.9913675785064697, 0.029406629502773285, 0.9389116764068604, 0.029406629502773285, 0.10778167098760605, 0.7633304595947266, 0.054629068821668625, 0.07382306456565857, 0.05812796950340271, 0.7250699400901794, 0.2095666229724884, 0.006118733435869217, 0.9900784492492676, 0.9909425377845764, 0.9955403804779053, 0.15609484910964966, 0.5523356199264526, 0.04905107989907265, 0.15251819789409637, 0.005109487567096949, 0.07408756762742996, 0.009708026424050331, 0.000510948768351227, 0.000510948768351227, 0.15006010234355927, 0.45054763555526733, 0.22371260821819305, 0.15134580433368683, 0.002755081281065941, 0.014142750762403011, 0.0007346883649006486, 0.006428522989153862, 0.000551016244571656, 0.9875156283378601, 0.3667130172252655, 0.6140627264976501, 0.004992379806935787, 0.013615582138299942, 0.9808627963066101, 0.12815919518470764, 0.8071302771568298, 0.06271620094776154, 0.9878519177436829, 0.3823293447494507, 0.0546184778213501, 0.24578315019607544, 0.31633201241493225, 0.9916432499885559, 0.8126855492591858, 0.12036101520061493, 0.05868842825293541, 0.007957752794027328, 0.9896264672279358, 0.9909999966621399, 0.9804229736328125, 0.9948252439498901, 0.9893369674682617, 0.985409140586853, 0.9326422810554504, 0.059894461184740067, 0.9868758320808411, 0.8351219892501831, 0.10048621892929077, 0.062464408576488495, 0.9899516105651855, 0.9827892780303955, 0.9900036454200745, 0.9819476008415222, 0.3309043347835541, 0.4291051924228668, 0.008377324789762497, 0.07586133480072021, 0.0693456381559372, 0.08610028773546219, 0.9917070269584656, 0.05217423290014267, 0.20602132380008698, 0.1056862622499466, 0.14582028985023499, 0.15250930190086365, 0.10635516792535782, 0.15719160437583923, 0.014046908356249332, 0.051505330950021744, 0.0013378008734434843, 0.006689004134386778, 0.11769013851881027, 0.07401132583618164, 0.0837177261710167, 0.1613689512014389, 0.5629714131355286, 0.9743589162826538, 0.9954622983932495, 0.9900584816932678, 0.9934465885162354, 0.19695627689361572, 0.6018515229225159, 0.026358461007475853, 0.09518332779407501, 0.07761102169752121, 0.0014643588801845908, 0.18323944509029388, 0.34266045689582825, 0.017593150958418846, 0.3748694658279419, 0.08146982640028, 0.9845797419548035, 0.9855497479438782, 0.6225457787513733, 0.1698714792728424, 0.20688258111476898, 0.9938912391662598, 0.06103626638650894, 0.333618700504303, 0.5874740481376648, 0.016646254807710648, 0.35885539650917053, 0.24148908257484436, 0.1341484934091568, 0.17054621875286102, 0.02255786955356598, 0.07214159518480301, 0.034201014786958694, 0.09949386864900589, 0.22075201570987701, 0.516124427318573, 0.055965300649404526, 0.07151121646165848, 0.8865128755569458, 0.026073908433318138, 0.057362597435712814, 0.026073908433318138, 0.0888553038239479, 0.38246411085128784, 0.1236247643828392, 0.0154530955478549, 0.011589821428060532, 0.31582266092300415, 0.009658184833824635, 0.05215419828891754, 0.04350857809185982, 0.060912005603313446, 0.8952529430389404, 0.9892025589942932, 0.9950796961784363, 0.9934839010238647, 0.20400062203407288, 0.7881842255592346, 0.0219735000282526, 0.0756864994764328, 0.7576788663864136, 0.056968335062265396, 0.004069166723638773, 0.012207499705255032, 0.04964383319020271, 0.021159667521715164, 0.7514988780021667, 0.05281887203454971, 0.18252597749233246, 0.006685933563858271, 0.0013371866662055254, 0.0006685933331027627, 0.0033429667819291353, 0.992233157157898, 0.9940540790557861, 0.07464299350976944, 0.22189326584339142, 0.5944296717643738, 0.0861787274479866, 0.021035753190517426, 0.0006785726873204112, 0.0006785726873204112, 0.3677014112472534, 0.20608633756637573, 0.26655641198158264, 0.061012402176856995, 0.0935523509979248, 0.0021693299058824778, 0.0010846649529412389, 0.0013558311620727181, 0.9858009815216064, 0.16054287552833557, 0.3676251471042633, 0.0007215410005301237, 0.46864089369773865, 0.002164623001590371, 0.33568546175956726, 0.4573754072189331, 0.1357434093952179, 0.02746807597577572, 0.021718943491578102, 0.02203834056854248, 0.9876611232757568, 0.3087635338306427, 0.04192475974559784, 0.6204864382743835, 0.01972929947078228, 0.0014796974137425423, 0.007398487068712711, 0.017369380220770836, 0.9726853370666504, 0.3143978714942932, 0.36241042613983154, 0.2954455614089966, 0.0031587195117026567, 0.02442743070423603, 0.24705076217651367, 0.02842176891863346, 0.01858346536755562, 0.20715096592903137, 0.009838304482400417, 0.00655886996537447, 0.10658163577318192, 0.017490319907665253, 0.004919152241200209, 0.09783647209405899, 0.0027328624855726957, 0.2525164783000946, 0.9921920299530029, 0.382059782743454, 0.08483130484819412, 0.5262091755867004, 0.006378293503075838, 0.0690232440829277, 0.8430696129798889, 0.08381393551826477, 0.07814768701791763, 0.06698373705148697, 0.014885274693369865, 0.483771413564682, 0.07628703117370605, 0.20653317868709564, 0.07442636787891388, 0.9891319870948792, 0.8855003118515015, 0.10815270990133286, 0.06919338554143906, 0.14094948768615723, 0.5842997431755066, 0.09610192477703094, 0.010250872001051903, 0.09610192477703094, 0.10721255093812943, 0.08040941506624222, 0.5513788461685181, 0.2603733241558075, 0.9974853992462158, 0.9904818534851074, 0.9927956461906433, 0.987091064453125, 0.08045268803834915, 0.18888892233371735, 0.034979432821273804, 0.5806585550308228, 0.06296297907829285, 0.04897120222449303, 0.05609673634171486, 0.9312058091163635, 0.12727569043636322, 0.007636541500687599, 0.19600456953048706, 0.16545839607715607, 0.06872887164354324, 0.007636541500687599, 0.2672789394855499, 0.09163849800825119, 0.06618335843086243, 0.9937292337417603, 0.022376852110028267, 0.14014975726604462, 0.1260170042514801, 0.065952830016613, 0.4816911816596985, 0.06241963803768158, 0.02002139389514923, 0.08126330375671387, 0.4675927460193634, 0.12482074648141861, 0.07857886701822281, 0.0003233698080293834, 0.3285437226295471, 0.9959225058555603, 0.9910739064216614, 0.9954701066017151, 0.9802136421203613, 0.8003852963447571, 0.01865638606250286, 0.15292981266975403, 0.00026276599965058267, 0.004992554429918528, 0.02207234501838684, 0.0005255319993011653, 0.9856348633766174, 0.9870247840881348, 0.21414922177791595, 0.6022946834564209, 0.0869981199502945, 0.09369028359651566, 0.32630226016044617, 0.36064988374710083, 0.005284246988594532, 0.0277422983199358, 0.2655334174633026, 0.011889556422829628, 0.9994977712631226, 0.9657720923423767, 0.03185706585645676, 0.9837508797645569, 0.9853845834732056, 0.988567054271698, 0.9968456029891968, 0.0013069469714537263, 0.0483570396900177, 0.1280808001756668, 0.06011956185102463, 0.12415996193885803, 0.10324881225824356, 0.030059780925512314, 0.005227787885814905, 0.16467532515525818, 0.06926818937063217, 0.16728921234607697, 0.09932797402143478, 0.9954083561897278, 0.9986591935157776, 0.9974561333656311, 0.31656256318092346, 0.07090134173631668, 0.01192530244588852, 0.27710065245628357, 0.09887159615755081, 0.21378813683986664, 0.0034691786859184504, 0.0010841183830052614, 0.006071062758564949, 0.07807421684265137, 0.9193239212036133, 0.9946617484092712, 0.2423807978630066, 0.266072154045105, 0.009112060070037842, 0.03280341625213623, 0.4501357674598694, 0.024733595550060272, 0.96461021900177, 0.3431107699871063, 0.006324622314423323, 0.24718733131885529, 0.39607948064804077, 0.0005270518595352769, 0.005797570571303368, 0.0005270518595352769, 0.9937946796417236, 0.9919465780258179, 0.5705562233924866, 0.12132369726896286, 0.03194084390997887, 0.16305285692214966, 0.05589647963643074, 0.0546085424721241, 0.002575874561443925, 0.3995226323604584, 0.07572650909423828, 0.04961392283439636, 0.4726378917694092, 0.4916689097881317, 0.3419615626335144, 0.0006490202504210174, 0.06014254316687584, 0.0013701538555324078, 0.0982183963060379, 0.002379740821197629, 0.003245101310312748, 7.211336196633056e-05, 0.00028845344786532223, 0.9871842265129089, 0.999214768409729, 0.997726559638977, 0.9944793581962585, 0.7411641478538513, 0.06444905698299408, 0.0537075474858284, 0.07584156841039658, 0.061519555747509, 0.003255002899095416, 0.9932934045791626, 0.9947143197059631, 0.19372273981571198, 0.5374829173088074, 0.020656315609812737, 0.00041870909626595676, 0.00041870909626595676, 0.19037307798862457, 0.005582788027822971, 0.022052012383937836, 0.01423610933125019, 0.009769879281520844, 0.005164078902453184, 0.9859728217124939, 0.9546413421630859, 0.044145263731479645, 0.9936060309410095, 0.8844130039215088, 0.10941191762685776, 0.6579909324645996, 0.2404525876045227, 0.012801379896700382, 0.0885428786277771, 0.0002133563393726945, 0.9873759746551514, 0.9055911302566528, 0.08579284697771072, 0.9943258166313171, 0.992745041847229, 0.9820315837860107, 0.996318519115448, 0.9923830032348633, 0.9885656237602234, 0.9723920822143555, 0.9623582363128662, 0.03138124570250511, 0.28716719150543213, 0.3051151633262634, 0.20101703703403473, 0.057433441281318665, 0.14896798133850098, 0.9921133518218994, 0.9763471484184265, 0.9864576458930969, 0.8694735169410706, 0.11592979729175568, 0.9894514083862305, 0.2406739741563797, 0.0014979707775637507, 0.08738163113594055, 0.41094332933425903, 0.12483090162277222, 0.04244250804185867, 0.02896076999604702, 0.060418155044317245, 0.001997294370085001, 0.45694851875305176, 0.08926436305046082, 0.11158045381307602, 0.06694827228784561, 0.0711989551782608, 0.010626710020005703, 0.19234344363212585, 0.9942483901977539, 0.09099661558866501, 0.9029663801193237, 0.9862541556358337, 0.07028219848871231, 0.005233780946582556, 0.14355513453483582, 0.33570966124534607, 0.1472935527563095, 0.051590126007795334, 0.04785171151161194, 0.08299281448125839, 0.03364573419094086, 0.006729146931320429, 0.0747682973742485, 0.9916423559188843, 0.9921415448188782, 0.3133663833141327, 0.3780069649219513, 0.2824513018131256, 0.026699377223849297, 0.09182893484830856, 0.18203258514404297, 0.3510628342628479, 0.12514740228652954, 0.18528315424919128, 0.0471334345638752, 0.01706555485725403, 0.9978029727935791, 0.2624014616012573, 0.7351406216621399, 0.9965283274650574, 0.9787454009056091, 0.9815981388092041, 0.9871625304222107, 0.13004426658153534, 0.8602928519248962, 0.09092080593109131, 0.9048784971237183, 0.1844145506620407, 0.19262291491031647, 0.12914490699768066, 0.10616149753332138, 0.382509708404541, 0.004377793520689011, 0.24273493885993958, 0.10656655579805374, 0.6453197002410889, 0.9227938652038574, 0.07694629579782486, 0.013368272222578526, 0.9863460063934326, 0.16655799746513367, 0.7181462049484253, 0.06705582141876221, 0.04542490839958191, 0.36897942423820496, 0.06232760474085808, 0.12465520948171616, 0.07728622853755951, 0.36399319767951965, 0.9932540655136108, 0.5214795470237732, 0.24075046181678772, 0.022844934836030006, 0.21439091861248016, 0.14123666286468506, 0.052444495260715485, 0.4990015923976898, 0.03634766861796379, 0.2705305218696594, 0.0005192524404264987, 0.1487026959657669, 0.07979169487953186, 0.15232959389686584, 0.07253789901733398, 0.03264205530285835, 0.5077652931213379, 0.16074734926223755, 0.0886881873011589, 0.7427635788917542, 0.01544711273163557, 0.016941994428634644, 0.6253589391708374, 0.1375291347503662, 0.20430052280426025, 0.25285735726356506, 0.013355142436921597, 0.7247390747070312, 0.008013085462152958, 0.9873605966567993, 0.043882496654987335, 0.12872199714183807, 0.3218049705028534, 0.4241974651813507, 0.07898849248886108, 0.004828247241675854, 0.1460544764995575, 0.6397427320480347, 0.05552484095096588, 0.047075409442186356, 0.10742849856615067, 0.9874672293663025, 0.9955348968505859, 0.02602040022611618, 0.0982992947101593, 0.8181970715522766, 0.05493195727467537, 0.9749906659126282, 0.987726092338562, 0.07846274971961975, 0.9176730513572693, 0.2231886386871338, 0.4746195375919342, 0.19194723665714264, 0.10147210210561752, 0.006498213857412338, 0.0007497938931919634, 0.000999725190922618, 0.9842614531517029, 0.0023414576426148415, 0.35473084449768066, 0.1510240137577057, 0.15570694208145142, 0.07375591993331909, 0.24585305154323578, 0.016390204429626465, 0.9839955568313599, 0.0675567016005516, 0.06118342652916908, 0.7839126586914062, 0.08667652308940887, 0.9874140620231628, 0.04845110699534416, 0.1497579663991928, 0.29401013255119324, 0.05946272239089012, 0.004404646344482899, 0.047349948436021805, 0.39641815423965454, 0.9813612699508667, 0.9821369051933289, 0.10054148733615875, 0.2010829746723175, 0.6942149996757507, 0.020387617871165276, 0.15970301628112793, 0.04077523574233055, 0.421344131231308, 0.03737730160355568, 0.31940603256225586, 0.9804092049598694, 0.9924282431602478, 0.14363506436347961, 0.01112665981054306, 0.45720458030700684, 0.3368343412876129, 0.005057572852820158, 0.0010115145705640316, 0.029333923012018204, 0.015172718092799187, 0.11104189604520798, 0.27482870221138, 0.05829699710011482, 0.5552094578742981, 0.3774583041667938, 0.07344211637973785, 0.4235731363296509, 0.08539780974388123, 0.03757503628730774, 0.034939829260110855, 0.22234435379505157, 0.21599166095256805, 0.044468872249126434, 0.4796285331249237, 0.09642618149518967, 0.4123050570487976, 0.02992536686360836, 0.01662520319223404, 0.16292698681354523, 0.19285236299037933, 0.08977609872817993, 0.9899080991744995, 0.020344175398349762, 0.2354111671447754, 0.2935373783111572, 0.01743786409497261, 0.4272276759147644, 0.9820076823234558, 0.16788184642791748, 0.11192123591899872, 0.2196972370147705, 0.05596061795949936, 0.3937969207763672, 0.0476701557636261, 0.052585285156965256, 0.17127777636051178, 0.11318356543779373, 0.24489718675613403, 0.29648083448410034, 0.004507310222834349, 0.009515432640910149, 0.016526803374290466, 0.03856253996491432, 0.028546297922730446, 0.024539798498153687, 0.11966236680746078, 0.055557526648044586, 0.7521634101867676, 0.0683784931898117, 0.8263888955116272, 0.16904747486114502, 0.0041231089271605015, 0.3058527708053589, 0.6851102113723755, 0.9832473993301392, 0.09479383379220963, 0.3159794509410858, 0.09479383379220963, 0.4929279386997223, 0.08707210421562195, 0.31243517994880676, 0.594139039516449, 0.9916290640830994, 0.9761495590209961, 0.01914018765091896, 0.9877941608428955, 0.9838790893554688, 0.9885385036468506, 0.10368341952562332, 0.8925790190696716, 0.9905075430870056, 0.9935454726219177, 0.04547302424907684, 0.04547302424907684, 0.05456762760877609, 0.6320750117301941, 0.21372321248054504, 0.9895693063735962, 0.674734354019165, 0.034332275390625, 0.2532881200313568, 0.010159551165997982, 0.027676019817590714, 0.991689145565033, 0.10839832574129105, 0.00413931580260396, 0.8281218409538269, 0.023801064118742943, 0.03518418222665787, 0.9912281632423401, 0.007924062199890614, 0.9880017042160034, 0.9928504228591919, 0.07742846757173538, 0.19005168974399567, 0.007038951385766268, 0.0351947583258152, 0.0802440494298935, 0.06757393479347229, 0.07742846757173538, 0.05068045109510422, 0.05208824202418327, 0.0577194020152092, 0.030971387401223183, 0.20553737878799438, 0.06757393479347229, 0.9895352721214294, 0.9869901537895203, 0.9954591393470764, 0.5792630910873413, 0.12112250924110413, 0.13486389815807343, 0.059923768043518066, 0.049723975360393524, 0.054682210087776184, 0.00028332750662229955, 0.978412389755249, 0.9896641969680786, 0.9942079782485962, 0.9925668835639954, 0.9850859045982361, 0.20845240354537964, 0.5705942511558533, 0.14044038951396942, 0.059620920568704605, 0.020756913349032402, 0.9849196076393127, 0.9866732358932495, 0.8202410936355591, 0.17631350457668304, 0.03727487847208977, 0.04595533013343811, 0.0852726623415947, 0.1945442259311676, 0.23386156558990479, 0.22518111765384674, 0.0827195942401886, 0.03727487847208977, 0.05055086314678192, 0.0005106147727929056, 0.007148606702685356, 0.8917779922485352, 0.03371826931834221, 0.0744611844420433, 0.9964271783828735, 0.11174982041120529, 0.3232762813568115, 0.14730659127235413, 0.19265960156917572, 0.010159075260162354, 0.12626278400421143, 0.0656711608171463, 0.012698843143880367, 0.005805185530334711, 0.003991065081208944, 0.11596421152353287, 0.001784064806997776, 0.03924942389130592, 0.25868940353393555, 0.03211316466331482, 0.23192842304706573, 0.03568129613995552, 0.030329100787639618, 0.11774827539920807, 0.03211316466331482, 0.09990762919187546, 0.9812349677085876, 0.981166422367096, 0.9813677072525024, 0.9951774477958679, 0.9875230193138123, 0.09480761736631393, 0.2621151804924011, 0.02509613335132599, 0.6190379858016968, 0.9874453544616699, 0.2024773508310318, 0.05268543213605881, 0.5774736404418945, 0.0022382698953151703, 0.002066095359623432, 0.16132761538028717, 0.001721746171824634, 0.9892702102661133, 0.9737311601638794, 0.9847195148468018, 0.439937561750412, 0.23087632656097412, 0.32540836930274963, 0.2783227562904358, 0.28195080161094666, 0.11350593715906143, 0.14754043519496918, 0.053902361541986465, 0.10815025120973587, 0.008465435355901718, 0.0039735715836286545, 0.0005182919558137655, 0.002073167823255062, 0.0013821118045598269, 0.12469981610774994, 0.02950715832412243, 0.48725298047065735, 0.06645525246858597, 0.08364637941122055, 0.18679314851760864, 0.0010263359872624278, 0.004361927974969149, 0.015651622787117958, 0.0005131679936312139, 0.9778186082839966, 0.9857408404350281, 0.7516078352928162, 0.2467965930700302, 0.1909768283367157, 0.08184720575809479, 0.18188267946243286, 0.15156890451908112, 0.3789222538471222, 0.015156890265643597, 0.9824124574661255, 0.4194457232952118, 0.1909022182226181, 0.043931473046541214, 0.22604739665985107, 0.04502975940704346, 0.04972244054079056, 0.005591278430074453, 0.004093614406883717, 0.006390032358467579, 0.006290188059210777, 0.0022964179515838623, 0.00019968851120211184, 0.9925934672355652, 0.20025360584259033, 0.22160369157791138, 0.16964322328567505, 0.3916327655315399, 0.0011575352400541306, 0.015562418848276138, 0.00012861502182204276, 0.9886962175369263, 0.994299054145813, 0.9747803211212158, 0.15225066244602203, 0.2445237785577774, 0.5951616764068604, 0.9944318532943726, 0.9847150444984436, 0.9940372705459595, 0.35330334305763245, 0.2513801157474518, 0.19729530811309814, 0.08988744020462036, 0.05301835387945175, 0.050885431468486786, 0.001980570610612631, 0.0007617579540237784, 0.00015235159662552178, 0.0009141095797531307, 0.00030470319325104356, 0.9852301478385925, 0.06097283214330673, 0.010393096134066582, 0.32149311900138855, 0.2518593668937683, 0.07188558578491211, 0.2168692797422409, 0.021132629364728928, 0.0036375836934894323, 0.0025982740335166454, 0.0003464365436229855, 0.00017321827181149274, 0.02858101576566696, 0.009700222872197628, 0.00017321827181149274, 0.9856811761856079, 0.9906148314476013, 0.9910671710968018, 0.5902251601219177, 0.09837086498737335, 0.2500259280204773, 0.05943239480257034, 0.02294495329260826, 0.9751604795455933, 0.9924275279045105, 0.19572332501411438, 0.7603554725646973, 0.018979232758283615, 0.009489616379141808, 0.015420625917613506, 0.9411094784736633, 0.05881934240460396, 0.9880068898200989, 0.13039003312587738, 0.06360489130020142, 0.8014216423034668, 0.9858141541481018, 0.9826114773750305, 0.9927192330360413, 0.9627365469932556, 0.015281532891094685, 0.019101915881037712, 0.1448030024766922, 0.06228085979819298, 0.07940809428691864, 0.05760979652404785, 0.3425447344779968, 0.3051761984825134, 0.006228086072951555, 0.06590522825717926, 0.27794814109802246, 0.05444345250725746, 0.12607957422733307, 0.04011622816324234, 0.4326821565628052, 0.7782201170921326, 0.14052382111549377, 0.062360115349292755, 0.009823854081332684, 0.008542481809854507, 0.9888010621070862, 0.07249679416418076, 0.12721134722232819, 0.1819259077310562, 0.0704449936747551, 0.46233803033828735, 0.03146087005734444, 0.0335126668214798, 0.0041035921312868595, 0.00889111589640379, 0.007523252163082361, 0.9946938753128052, 0.3268134593963623, 0.08016178756952286, 0.5919640064239502, 0.9884593486785889, 0.0201385710388422, 0.3439048230648041, 0.1988038420677185, 0.1182495579123497, 0.13528989255428314, 0.04440813139081001, 0.09036538004875183, 0.001549120876006782, 0.0020654944237321615, 0.018073076382279396, 0.01394208800047636, 0.013425714336335659, 0.99383544921875, 0.11927338689565659, 0.8430196642875671, 0.011579940095543861, 0.025475868955254555, 0.2700508236885071, 0.008183358237147331, 0.7160438299179077, 0.060072481632232666, 0.21626092493534088, 0.11934399604797363, 0.11694109439849854, 0.15058168768882751, 0.1858242005109787, 0.08730533719062805, 0.028033824637532234, 0.03524252027273178, 0.9873857498168945, 0.011039919219911098, 0.3069097697734833, 0.5232921838760376, 0.12585508823394775, 0.03311975672841072, 0.9704704284667969, 0.02540498413145542, 0.5609049201011658, 0.1338663399219513, 0.17091421782970428, 0.13065552711486816, 0.003457802115008235, 0.9794657230377197, 0.07266391068696976, 0.9204095602035522, 0.9912309646606445, 0.7637085318565369, 0.03403099253773689, 0.03756668046116829, 0.045963939279317856, 0.06717806309461594, 0.02209804765880108, 0.01016510184854269, 0.007955296896398067, 0.01104902382940054, 0.3697507679462433, 0.62732994556427, 0.754353404045105, 0.24540157616138458, 0.9928095936775208, 0.07868325710296631, 0.22412806749343872, 0.4983272850513458, 0.042918141931295395, 0.02861209399998188, 0.12637007236480713, 0.06842212378978729, 0.006516392808407545, 0.7884835004806519, 0.08797129988670349, 0.029323767870664597, 0.0032581964042037725, 0.016290981322526932, 0.9869822859764099, 0.9940775036811829, 0.013645067811012268, 0.3661426603794098, 0.031269945204257965, 0.5867379307746887, 0.0017056334763765335, 0.995771050453186, 0.9910167455673218, 0.9851661324501038, 0.9941132068634033, 0.988616406917572, 0.043854501098394394, 0.8024804592132568, 0.12358996272087097, 0.01879478618502617, 0.007404007017612457, 0.003986773081123829, 0.9940216541290283, 0.13647212088108063, 0.8509438037872314, 0.08343678712844849, 0.33631443977355957, 0.029780514538288116, 0.000513457169290632, 0.003594200126826763, 0.5422107577323914, 0.002053828677162528, 0.002053828677162528, 0.984280526638031, 0.9923427104949951, 0.023923134431242943, 0.18561053276062012, 0.55353182554245, 0.08744318038225174, 0.09404266625642776, 0.037947043776512146, 0.01567377895116806, 0.0016498713521286845, 0.8983209133148193, 0.09777642786502838, 0.9932557344436646, 0.9963133931159973, 0.02412554621696472, 0.7823570370674133, 0.18955786526203156, 0.1122601106762886, 0.1514381319284439, 0.12707744538784027, 0.07333322614431381, 0.3131730556488037, 0.2112097442150116, 0.0037671178579330444, 0.0012557059526443481, 0.00527396472170949, 0.0010045646922662854, 0.00025114117306657135, 0.9718917608261108, 0.9845535159111023, 0.9937401413917542, 0.9960198998451233, 0.9857584238052368, 0.9959386587142944, 0.09566166996955872, 0.8968281745910645, 0.9896567463874817, 0.6990979909896851, 0.08297374844551086, 0.06090626120567322, 0.14034920930862427, 0.016771290451288223, 0.9930776953697205, 0.13328415155410767, 0.20339316129684448, 0.00924514327198267, 0.06471600383520126, 0.18182115256786346, 0.09399229288101196, 0.006933857686817646, 0.2719613015651703, 0.01771985925734043, 0.016949430108070374, 0.9894220232963562, 0.9940089583396912, 0.3240557610988617, 0.016624605283141136, 0.07592730224132538, 0.17964500188827515, 0.08560431748628616, 0.24118085205554962, 0.03448985517024994, 0.008932624012231827, 0.018113376572728157, 0.007940110750496387, 0.00545882573351264, 0.0017368991393595934, 0.0004962569219060242, 0.9863153696060181, 0.9669896364212036, 0.02930271625518799, 0.19790324568748474, 0.6244772672653198, 0.09230269491672516, 0.06231735646724701, 0.007561520207673311, 0.004693357273936272, 0.0020859367214143276, 0.007561520207673311, 0.0010429683607071638, 0.9827581644058228, 0.9762284755706787, 0.9406090378761292, 0.05532994121313095, 0.6971713900566101, 0.05924239754676819, 0.20949485898017883, 0.0034343418665230274, 0.02318180724978447, 0.006868683733046055, 0.9958065748214722, 0.9847890138626099, 0.9924063086509705, 0.19553522765636444, 0.22243425250053406, 0.5803982019424438, 0.08882887661457062, 0.24002695083618164, 0.0623692087829113, 0.32129591703414917, 0.011339856311678886, 0.02078973688185215, 0.22679711878299713, 0.024569688364863396, 0.8644230365753174, 0.045898567885160446, 0.05354832857847214, 0.03518890216946602, 0.07426006346940994, 0.27003660798072815, 0.31054210662841797, 0.3442966639995575, 0.9831694960594177, 0.011172380298376083, 0.09642373770475388, 0.8953633308410645, 0.9941475987434387, 0.9900312423706055, 0.9870457053184509, 0.5627754330635071, 0.04998968169093132, 0.28066498041152954, 0.06287858635187149, 0.04300317168235779, 0.0006022853194735944, 0.9867714643478394, 0.9928345680236816, 0.005894067231565714, 0.5367665886878967, 0.10080887377262115, 0.01300759706646204, 0.23596593737602234, 0.02560870721936226, 0.0014227059436962008, 0.0611763559281826, 0.009349210187792778, 0.004877849016338587, 0.0006097311270423234, 0.0044713616371154785, 0.9835164546966553, 0.3301975131034851, 0.1402694582939148, 0.40210577845573425, 0.03385814279317856, 0.008706379681825638, 0.084161676466465, 0.11325685679912567, 0.8871787190437317, 0.014783329330384731, 0.9756997227668762, 0.9783188700675964, 0.7608110904693604, 0.06470240652561188, 0.11601811647415161, 0.05577794089913368, 0.11681756377220154, 0.2830788493156433, 0.11736089736223221, 0.09236737340688705, 0.09073736518621445, 0.08530398458242416, 0.1037774607539177, 0.039663638919591904, 0.06954719871282578, 0.001630012528039515, 0.5987764596939087, 0.057946108281612396, 0.3421579599380493, 0.20319798588752747, 0.7937421202659607, 0.006539661902934313, 0.09155526757240295, 0.6866645216941833, 0.1569518893957138, 0.05885695666074753, 0.9935281872749329, 0.1261337250471115, 0.21330028772354126, 0.03644929081201553, 0.030574239790439606, 0.3212093710899353, 0.06954140961170197, 0.016905756667256355, 0.035370200872421265, 0.03644929081201553, 0.018344543874263763, 0.049758076667785645, 0.013428686186671257, 0.02601807937026024, 0.006594443693757057, 0.08384308964014053, 0.6986924409866333, 0.015720579773187637, 0.14148521423339844, 0.0017467309953644872, 0.015720579773187637, 0.04366827756166458, 0.00752622913569212, 0.21324315667152405, 0.762657880783081, 0.012543715536594391, 0.172505721449852, 0.18025878071784973, 0.03682706505060196, 0.003876532893627882, 0.10854292660951614, 0.08916025608778, 0.04845666140317917, 0.0949750617146492, 0.2636042535305023, 0.9660263061523438, 0.3822566568851471, 0.39025190472602844, 0.20815274119377136, 0.017369035631418228, 0.0017920434474945068, 0.3101344704627991, 0.18980515003204346, 0.32517561316490173, 0.06995334476232529, 0.09955817461013794, 0.0007162458496168256, 0.0045362235978245735, 0.9754077792167664, 0.052421003580093384, 0.6996187567710876, 0.10282581299543381, 0.1189553514122963, 0.0020161925349384546, 0.02217811718583107, 0.9816961884498596, 0.9911965727806091, 0.9870419502258301, 0.05160568654537201, 0.2877407968044281, 0.5770453810691833, 0.0046914261765778065, 0.025802843272686005, 0.015638086944818497, 0.03596759960055351, 0.001563808647915721, 0.9920497536659241, 0.9910650849342346, 0.025654999539256096, 0.10384166240692139, 0.5137108564376831, 0.09590083360671997, 0.1704224944114685, 0.025654999539256096, 0.014659999869763851, 0.0012216666946187615, 0.047644998878240585, 0.9982519149780273, 0.012698633596301079, 0.2687877416610718, 0.5594453811645508, 0.02610274776816368, 0.0888904333114624, 0.0014109592884778976, 0.04232877865433693, 0.5068691968917847, 0.14587654173374176, 0.29974228143692017, 0.009172764606773853, 0.03491568565368652, 0.0014794780872762203, 0.0020712693221867085, 0.2542341947555542, 0.2741350829601288, 0.0318414643406868, 0.04875724017620087, 0.3253799378871918, 0.028856325894594193, 0.0004975228803232312, 0.03432907909154892, 0.0014925686409696937, 0.12654702365398407, 0.5870698094367981, 0.0232196357101202, 0.05611412227153778, 0.13157793879508972, 0.03250749036669731, 0.04218234121799469, 0.11161467432975769, 0.14156007766723633, 0.7431904077529907, 0.0806381106376648, 0.9163421392440796, 0.33647462725639343, 0.6617334485054016, 0.989916980266571, 0.987417459487915, 0.9774106740951538, 0.9883698225021362, 0.9907665252685547, 0.9455013275146484, 0.051631469279527664, 0.9914752840995789, 0.05626421421766281, 0.07094183564186096, 0.22261059284210205, 0.12720605731010437, 0.10029707849025726, 0.034247782081365585, 0.004892540629953146, 0.04647913575172424, 0.3351390063762665, 0.02682815119624138, 0.01967397704720497, 0.14844910800457, 0.032193779945373535, 0.6581839919090271, 0.01967397704720497, 0.06259901821613312, 0.01430834736675024, 0.01788543350994587, 0.9695718884468079, 0.028516819700598717, 0.11929909139871597, 0.005422685761004686, 0.2467322051525116, 0.5639593005180359, 0.06507223099470139, 0.03727074712514877, 0.8418803811073303, 0.03507835045456886, 0.048232730478048325, 0.03507835045456886, 0.43131375312805176, 0.08314482122659683, 0.4832792580127716, 0.045023705810308456, 0.022511852905154228, 0.927488386631012, 0.9848975539207458, 0.3046221435070038, 0.22402605414390564, 0.27975502610206604, 0.04973422735929489, 0.05484086647629738, 0.0810401514172554, 0.0037744727451354265, 0.001332166837528348, 0.0008881111862137914, 0.18706601858139038, 0.07837961614131927, 0.6312171816825867, 0.1024160385131836, 0.9867580533027649, 0.12084386497735977, 0.06408386677503586, 0.03661935403943062, 0.025633547455072403, 0.3002786934375763, 0.03112644888460636, 0.012816773727536201, 0.3863341808319092, 0.01830967701971531, 0.9919903874397278, 0.18417547643184662, 0.5615842342376709, 0.25361868739128113, 0.11368048936128616, 0.43567901849746704, 0.08598168939352036, 0.154074564576149, 0.1079099029302597, 0.004039408173412085, 0.09809990972280502, 0.0026347108650952578, 0.9564000964164734, 0.039520662277936935, 0.9976846575737, 0.9779152274131775, 0.9184743165969849, 0.07491634041070938, 0.00599330710247159, 0.993996262550354, 0.010968890972435474, 0.02285185642540455, 0.1617911458015442, 0.208408921957016, 0.1032903864979744, 0.2093230038881302, 0.004570371005684137, 0.09963408857584, 0.01736740954220295, 0.0319925993680954, 0.004570371005684137, 0.1252281665802002, 0.9936597347259521, 0.9920759201049805, 0.9878084659576416, 0.9801086187362671, 0.9900607466697693, 0.03905988857150078, 0.9472023248672485, 0.9787306785583496, 0.9868704080581665, 0.10500385612249374, 0.033948615193367004, 0.04184364154934883, 0.36632925271987915, 0.06316021829843521, 0.026053588837385178, 0.03236960992217064, 0.17526960372924805, 0.04184364154934883, 0.01342154573649168, 0.09000330418348312, 0.011053037829697132, 0.9940948486328125, 0.9874221086502075, 0.9969050288200378, 0.18564262986183167, 0.00562553433701396, 0.1757979393005371, 0.060474492609500885, 0.5695853233337402, 0.00140638358425349, 0.9904343485832214, 0.2687235176563263, 0.10993234813213348, 0.45194411277770996, 0.1190933808684349, 0.04580514505505562, 0.029245836660265923, 0.3896140456199646, 0.036681219935417175, 0.005948306061327457, 0.35937681794166565, 0.11177857965230942, 0.019084148108959198, 0.02081907168030739, 0.0007435382576659322, 0.0004956921329721808, 0.021562609821558, 0.004956921562552452, 0.9842680096626282, 0.9833187460899353, 0.22815920412540436, 0.08307971060276031, 0.6336377859115601, 0.0359598770737648, 0.01859993487596512, 0.989356517791748, 0.9856112599372864, 0.9950292706489563, 0.16853779554367065, 0.02092193253338337, 0.015497728250920773, 0.38473111391067505, 0.24098967015743256, 0.12746880948543549, 0.03951920568943024, 0.0011623295722529292, 0.0003874432004522532, 0.0003874432004522532, 0.024957790970802307, 0.9733538031578064, 0.9983582496643066, 0.11096765846014023, 0.0866089016199112, 0.42492493987083435, 0.07848931849002838, 0.03247833997011185, 0.2625332474708557, 0.9944201111793518, 0.982323169708252, 0.9900096654891968, 0.9933180809020996, 0.9841251373291016, 0.9965384602546692, 0.9905019402503967, 0.04750309884548187, 0.9457435011863708, 0.9885353446006775, 0.9764178991317749, 0.21975962817668915, 0.7793014645576477, 0.9953325986862183, 0.3729924261569977, 0.01232107076793909, 0.6138133406639099, 0.9965190887451172, 0.0859314352273941, 0.7222332954406738, 0.08797742426395416, 0.05728762596845627, 0.012275919318199158, 0.03478177264332771, 0.9914703965187073, 0.9836779832839966, 0.23887589573860168, 0.02185792475938797, 0.7322404980659485, 0.006245121825486422, 0.4799902141094208, 0.23023921251296997, 0.0019511798163875937, 0.2595069110393524, 0.02536533772945404, 0.03805941343307495, 0.28756001591682434, 0.1987547129392624, 0.09514853358268738, 0.09091971069574356, 0.28967443108558655, 0.16735699772834778, 0.4561827778816223, 0.05972215160727501, 0.03779028728604317, 0.1369898021221161, 0.08030436187982559, 0.03779028728604317, 0.02361893095076084, 0.00033741327933967113, 0.45678019523620605, 0.43686166405677795, 0.07832825183868408, 0.003230030881240964, 0.019649354740977287, 0.004575876984745264, 0.0002691692498046905, 0.9972590208053589, 0.011113784275949001, 0.3334135413169861, 0.6260765194892883, 0.022227568551898003, 0.0048395488411188126, 0.06775368005037308, 0.7985255122184753, 0.12744145095348358, 0.583221971988678, 0.3000181019306183, 0.03840890899300575, 0.04170581325888634, 0.017638426274061203, 0.015330594964325428, 0.0011539157712832093, 0.002472676569595933, 0.991536021232605, 0.20009277760982513, 0.05704399198293686, 0.6915487051010132, 0.010531198233366013, 0.012286398559808731, 0.005265599116683006, 0.021939996629953384, 0.9897270798683167, 0.0705704316496849, 0.4716697335243225, 0.01836271397769451, 0.43278396129608154, 0.006120904814451933, 0.025371838361024857, 0.41363784670829773, 0.10276875644922256, 0.22578372061252594, 0.17042699456214905, 0.01717083901166916, 0.007688435725867748, 0.02409043163061142, 0.005894467234611511, 0.001281405915506184, 0.005638186354190111, 0.1157156229019165, 0.7166247963905334, 0.11774571985006332, 0.049737416207790375, 0.09920383989810944, 0.8928345441818237, 0.9834755063056946, 0.9038504958152771, 0.08721364289522171, 0.987559974193573, 0.9942530989646912, 0.983465313911438, 0.1250581592321396, 0.8648388385772705, 0.008806913159787655, 0.9966484308242798, 0.1463301032781601, 0.4380115270614624, 0.02446991764008999, 0.003425788599997759, 0.24469918012619019, 0.008809170685708523, 0.0004893983714282513, 0.01174556091427803, 0.06655817478895187, 0.05530201643705368, 0.1432955265045166, 0.3288853168487549, 0.05113188177347183, 0.2733346223831177, 0.1852741688489914, 0.0025250313337892294, 0.015465816482901573, 0.26331737637519836, 0.15322478115558624, 0.21173974871635437, 0.015081179328262806, 0.2123430073261261, 0.12849164009094238, 0.008445460349321365, 0.0030162357725203037, 0.003921106457710266, 0.971771776676178, 0.9890316128730774, 0.9843844771385193, 0.0048041376285254955, 0.022819655016064644, 0.96683269739151, 0.0036031033378094435, 0.10293516516685486, 0.8931139707565308, 0.0030275050085037947, 0.98321133852005, 0.03959258273243904, 0.2710569202899933, 0.163446307182312, 0.5258707404136658, 0.9891566634178162, 0.991236686706543, 0.9873888492584229, 0.9990136027336121, 0.9859957695007324, 0.9839800596237183, 0.8185106515884399, 0.18147973716259003, 0.9936705231666565, 0.988603413105011, 0.11482511460781097, 0.8768463134765625, 0.988532543182373, 0.9370465278625488, 0.03238173946738243, 0.030357880517840385, 0.045689113438129425, 0.9457646012306213, 0.007614851929247379, 0.9777305126190186, 0.9983356595039368, 0.0281845536082983, 0.23218703269958496, 0.06777714192867279, 0.6227443814277649, 0.028855614364147186, 0.020131822675466537, 0.11394736915826797, 0.0022903995122760534, 0.8709243535995483, 0.012024597264826298, 0.9116990566253662, 0.06676307320594788, 0.019700579345226288, 0.9883219599723816, 0.3086831569671631, 0.24575161933898926, 0.007567715831100941, 0.1206851527094841, 0.1449815034866333, 0.029872562736272812, 0.1417950987815857, 0.1601506471633911, 0.44041427969932556, 0.010009415447711945, 0.08007532358169556, 0.2977800965309143, 0.010009415447711945, 0.9961224794387817, 0.013470970094203949, 0.14529404044151306, 0.8400111794471741, 0.9845712184906006, 0.9898293018341064, 0.09751218557357788, 0.8953391909599304, 0.24109046161174774, 0.14532630145549774, 0.21252921223640442, 0.10080437362194061, 0.0957641527056694, 0.14700637757778168, 0.056282442063093185, 0.9925810694694519, 0.9960286021232605, 0.9834954142570496, 0.24377095699310303, 0.07008414715528488, 0.09141410887241364, 0.40526920557022095, 0.18282821774482727, 0.0030471370555460453, 0.006032870151102543, 0.3547327518463135, 0.10376536846160889, 0.08446018397808075, 0.034990645945072174, 0.025338055565953255, 0.11100481450557709, 0.258206844329834, 0.013272314332425594, 0.006032870151102543, 0.0036197220906615257, 0.9955596923828125, 0.9950673580169678, 0.20634552836418152, 0.1584041714668274, 0.08451517671346664, 0.05659056827425957, 0.19720207154750824, 0.08624501526355743, 0.001976963132619858, 0.05288376286625862, 0.02668900229036808, 0.01803978905081749, 0.02718324400484562, 0.00222408352419734, 0.0029654446989297867, 0.07809004187583923, 0.4159550368785858, 0.12332966923713684, 0.04194715619087219, 0.25143176317214966, 0.10373757779598236, 0.06354868412017822, 0.027217712253332138, 0.13361422717571259, 0.6878657937049866, 0.11381952464580536, 0.012371687218546867, 0.02226903662085533, 0.004948675166815519, 0.22632279992103577, 0.2563174068927765, 0.48536697030067444, 0.027267808094620705, 0.005453561432659626, 0.9843966364860535, 0.991150438785553, 0.15330012142658234, 0.5809698700904846, 0.16957905888557434, 0.015379094518721104, 0.0009816443780437112, 0.0796767994761467, 8.180369331967086e-05, 8.180369331967086e-05, 0.9747278690338135, 0.9881445169448853, 0.9902607202529907, 0.9493876099586487, 0.050061870366334915, 0.9862061142921448, 0.9827315211296082, 0.08323528617620468, 0.09952045232057571, 0.7599743604660034, 0.056998077780008316, 0.9897422194480896, 0.9209259748458862, 0.07752960175275803, 0.161402627825737, 0.7873831391334534, 0.047984566539525986, 0.0021811167243868113, 0.9812959432601929, 0.9783847332000732, 0.9935317039489746, 0.9928613901138306, 0.1693040132522583, 0.2738741338253021, 0.5577073097229004, 0.09309950470924377, 0.8299155235290527, 0.07713958621025085, 0.1394934505224228, 0.12494069337844849, 0.19380004703998566, 0.21580664813518524, 0.16398465633392334, 0.13984839618206024, 0.004614287056028843, 0.009583518840372562, 0.0074538481421768665, 0.9878883361816406, 0.9853818416595459, 0.9845151305198669, 0.9948987364768982, 0.1443411260843277, 0.7868919372558594, 0.06518631428480148, 0.05053522437810898, 0.08085636049509048, 0.10511326789855957, 0.24459049105644226, 0.05356733873486519, 0.0030321134254336357, 0.015160567127168179, 0.4244958758354187, 0.021224794909358025, 0.9763917326927185, 0.10862714797258377, 0.23068012297153473, 0.5284894108772278, 0.08909867703914642, 0.018307946622371674, 0.021969536319375038, 0.8451035618782043, 0.04427352920174599, 0.10113463550806046, 0.00954919308423996, 0.07541538029909134, 0.8872397541999817, 0.03548958897590637, 0.5653590559959412, 0.13354642689228058, 0.10037803649902344, 0.14414535462856293, 0.038405511528253555, 0.017706437036395073, 0.0002493864158168435, 0.6951602101325989, 0.14549864828586578, 0.10598050057888031, 0.014370237477123737, 0.009751232340931892, 0.029253697022795677, 0.6164839863777161, 0.274300754070282, 0.08977115154266357, 0.002216571709141135, 0.012745287269353867, 0.00443314341828227, 0.15620601177215576, 0.2924708425998688, 0.033235322684049606, 0.5184710025787354, 0.41670292615890503, 0.27635765075683594, 0.0934281125664711, 0.03459548205137253, 0.10216160863637924, 0.06986797600984573, 0.0031142705120146275, 0.0008801199146546423, 0.0022341504227370024, 0.0006093137781135738, 0.9829016327857971, 0.02117553912103176, 0.07905534654855728, 0.07340853661298752, 0.3148096799850464, 0.012705323286354542, 0.06776172667741776, 0.18634474277496338, 0.15528728067874908, 0.08752556145191193, 0.11548694968223572, 0.2186003029346466, 0.6640499830245972, 0.06261075288057327, 0.9302168488502502, 0.9919860363006592, 0.9855696558952332, 0.9928436875343323, 0.24329212307929993, 0.11777198314666748, 0.5222257971763611, 0.09452751278877258, 0.006198525428771973, 0.015496313571929932, 0.9887495636940002, 0.16779780387878418, 0.016779780387878418, 0.8138193488121033, 0.9812813997268677, 0.9796934723854065, 0.9920486807823181, 0.09317118674516678, 0.10151487588882446, 0.673057496547699, 0.05006213113665581, 0.05423397198319435, 0.0027812293265014887, 0.02224983461201191, 0.9823042154312134, 0.2130046784877777, 0.16756367683410645, 0.10224224627017975, 0.36920809745788574, 0.10508230328559875, 0.045440997928380966, 0.9917056560516357, 0.26191312074661255, 0.1778663694858551, 0.08795589953660965, 0.2728028893470764, 0.0502605140209198, 0.11308614909648895, 0.01256512850522995, 0.011169002391397953, 0.0002792250597849488, 0.008097526617348194, 0.003071475774049759, 0.0005584501195698977, 0.052248235791921616, 0.7804580330848694, 0.15021367371082306, 0.016327572986483574, 0.9924637079238892, 0.9893668293952942, 0.629921555519104, 0.3674542307853699, 0.17808349430561066, 0.19374825060367584, 0.2584684193134308, 0.14015831053256989, 0.21271084249019623, 0.014015831053256989, 0.002885612193495035, 0.009760668501257896, 0.9894878268241882, 0.17868539690971375, 0.14695622026920319, 0.5059970021247864, 0.08850771933794022, 0.08015793561935425, 0.333583265542984, 0.6618715524673462, 0.9863407015800476, 0.9843339323997498, 0.9919023513793945, 0.016153676435351372, 0.7005594372749329, 0.058663349598646164, 0.035283029079437256, 0.004676064010709524, 0.08629463613033295, 0.07736760377883911, 0.0021254837047308683, 0.019129352644085884, 0.22915710508823395, 0.7701181173324585, 0.5001435875892639, 0.184583380818367, 0.12323980033397675, 0.0005526448367163539, 0.1569511443376541, 0.0342639796435833, 0.11506828665733337, 0.34039026498794556, 0.4275340437889099, 0.10255039483308792, 0.004333115182816982, 0.010110602714121342, 0.06715329736471176, 0.37033069133758545, 0.47649216651916504, 0.02370116487145424, 0.06172178313136101, 0.992695152759552, 0.165897935628891, 0.38667938113212585, 0.05737823247909546, 0.1596611738204956, 0.004989411681890488, 0.018710292875766754, 0.01995764672756195, 0.18835029006004333, 0.9919474720954895, 0.9855265617370605, 0.06484450399875641, 0.030395861715078354, 0.2816683351993561, 0.6221019625663757, 0.9953882098197937, 0.6679181456565857, 0.28111401200294495, 0.020702194422483444, 0.02832931838929653, 0.0010895892046391964, 0.18799781799316406, 0.18451637029647827, 0.02715524099767208, 0.0222812220454216, 0.12045785784721375, 0.04595502093434334, 0.003481440944597125, 0.21236790716648102, 0.15457598865032196, 0.0083554582670331, 0.018103493377566338, 0.015318340621888638, 0.9813975095748901, 0.991676926612854, 0.9957106709480286, 0.3832135796546936, 0.2381560355424881, 0.21022649109363556, 0.080643430352211, 0.03887491673231125, 0.042271751910448074, 0.0062904395163059235, 0.00012580878683365881, 0.1373499631881714, 0.8572531938552856, 0.9842586517333984, 0.9947376847267151, 0.5682482123374939, 0.10083397477865219, 0.14360709488391876, 0.060663022100925446, 0.011059210635721684, 0.1122184544801712, 0.00016263544966932386, 0.0019516253378242254, 0.00016263544966932386, 0.0008131772046908736, 0.00016263544966932386, 0.003572960151359439, 0.1813277304172516, 0.8146349191665649, 0.9858942031860352, 0.752417802810669, 0.19323880970478058, 0.02567182295024395, 0.0056011248379945755, 0.019137177616357803, 0.003267322899773717, 0.9172987341880798, 0.05344591662287712, 0.02653343416750431, 0.001895245281048119, 0.9757382869720459, 0.949702799320221, 0.04937293007969856, 0.9789113402366638, 0.036071229726076126, 0.855403482913971, 0.10306066274642944, 0.9861426949501038, 0.1358250379562378, 0.12783533334732056, 0.4314442276954651, 0.21838535368442535, 0.039948537945747375, 0.0452750101685524, 0.07442037761211395, 0.040163375437259674, 0.007087654899805784, 0.6331638097763062, 0.06851399689912796, 0.010631482116878033, 0.16655988991260529, 0.9945344924926758, 0.05090802162885666, 0.23081597685813904, 0.08501145243644714, 0.6089192032814026, 0.011862062849104404, 0.0024712630547583103, 0.010379305109381676, 0.9984614849090576, 0.03750810772180557, 0.05501189082860947, 0.018754053860902786, 0.04000864923000336, 0.428842693567276, 0.048760540783405304, 0.022504864260554314, 0.017503783106803894, 0.0500108078122139, 0.012502701953053474, 0.04125891625881195, 0.015003242529928684, 0.1325286477804184, 0.07876702398061752, 0.323504239320755, 0.12478021532297134, 0.5453357696533203, 0.18698127567768097, 0.03765594959259033, 0.10128152370452881, 0.04674531891942024, 0.2882627844810486, 0.027268102392554283, 0.054536204785108566, 0.05323772132396698, 0.1752949357032776, 0.010387848131358624, 0.018178734928369522, 0.14818336069583893, 0.10394952446222305, 0.05308060720562935, 0.26097965240478516, 0.05971568450331688, 0.34281226992607117, 0.028751997277140617, 0.21608828008174896, 0.06482648849487305, 0.7130913138389587, 0.018419118598103523, 0.9792831540107727, 0.9800676107406616, 0.11460789293050766, 0.11065589636564255, 0.059279944747686386, 0.7113593816757202, 0.008532089181244373, 0.35514819622039795, 0.2872470021247864, 0.325641393661499, 0.005688059609383345, 0.017419680953025818, 0.17478081583976746, 0.4115521311759949, 0.17463356256484985, 0.05168329179286957, 0.07273944467306137, 0.09806573390960693, 0.005153604317456484, 0.008834750391542912, 0.0023559334222227335, 0.10639963299036026, 0.043415941298007965, 0.5350556373596191, 0.0012229842832311988, 0.23328424990177155, 0.0006114921416155994, 0.05319981649518013, 0.02017924003303051, 0.001528730383142829, 0.005503429099917412, 0.8278122544288635, 0.019806908443570137, 0.0034953367430716753, 0.11010310798883438, 0.03145803138613701, 0.006990673486143351, 0.9590415954589844, 0.00873915757983923, 0.027512162923812866, 0.0045314147137105465, 0.8939030170440674, 0.10364092886447906, 0.7875295877456665, 0.20544250309467316, 0.9820002317428589, 0.9836718440055847, 0.9950665235519409, 0.9925188422203064, 0.9305809140205383, 0.06787346303462982, 0.2317386418581009, 0.12241512537002563, 0.1657704859972, 0.018362268805503845, 0.13941723108291626, 0.22714807093143463, 0.019892457872629166, 0.01785220578312874, 0.0448855459690094, 0.0013601680984720588, 0.010031240060925484, 0.0003400420246180147, 0.000850105076096952, 0.03648949787020683, 0.009044405072927475, 0.3330835998058319, 0.16622993350028992, 0.36957311630249023, 0.05863269791007042, 0.01559380255639553, 0.010603785514831543, 0.0006237520719878376, 0.9903854131698608, 0.9929304122924805, 0.9986805319786072], \"Term\": [\"aaron\", \"abbott\", \"abus\", \"abus\", \"abus\", \"accent\", \"accent\", \"accent\", \"accent\", \"accent\", \"accent\", \"act\", \"act\", \"act\", \"act\", \"act\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actress\", \"actress\", \"actress\", \"actress\", \"actress\", \"actress\", \"actress\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"aeon\", \"aesthet\", \"affleck\", \"afghanistan\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"airport\", \"airport\", \"airport\", \"akshai\", \"album\", \"alien\", \"alien\", \"alien\", \"almighti\", \"altman\", \"altman\", \"amateurish\", \"amateurish\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"amir\", \"anatomi\", \"anderson\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"anim\", \"anim\", \"anim\", \"anim\", \"anim\", \"anim\", \"anim\", \"anim\", \"ann\", \"ann\", \"ann\", \"ann\", \"anna\", \"anna\", \"anna\", \"annoi\", \"annoi\", \"annoi\", \"annoi\", \"anti\", \"anti\", \"anti\", \"anti\", \"anywai\", \"apocalyps\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"architect\", \"argento\", \"ark\", \"armageddon\", \"armi\", \"armi\", \"armi\", \"armi\", \"armi\", \"arni\", \"art\", \"art\", \"art\", \"art\", \"art\", \"art\", \"art\", \"art\", \"ator\", \"audienc\", \"audienc\", \"audienc\", \"audienc\", \"audienc\", \"audienc\", \"audienc\", \"austen\", \"australian\", \"australian\", \"aw\", \"aw\", \"aw\", \"aw\", \"aw\", \"awkwardli\", \"aztec\", \"aztec\", \"babi\", \"babi\", \"babi\", \"babi\", \"babi\", \"babi\", \"babi\", \"bad\", \"bad\", \"bad\", \"baldwin\", \"bam\", \"band\", \"band\", \"bandit\", \"bandit\", \"barnei\", \"basebal\", \"basebal\", \"batman\", \"battl\", \"battl\", \"battl\", \"battl\", \"battl\", \"battl\", \"battl\", \"battl\", \"battl\", \"bean\", \"bearabl\", \"beethoven\", \"behavior\", \"behavior\", \"behavior\", \"behaviour\", \"bela\", \"belushi\", \"bennett\", \"bergman\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"beverli\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"biker\", \"bikini\", \"billi\", \"bin\", \"bishop\", \"blade\", \"blade\", \"blade\", \"blade\", \"blade\", \"blah\", \"blair\", \"blatantli\", \"bloat\", \"bloke\", \"blood\", \"blood\", \"blood\", \"bloodi\", \"bloodi\", \"blurb\", \"bobbi\", \"bobbi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"boi\", \"boi\", \"boi\", \"boi\", \"boi\", \"boi\", \"boi\", \"boll\", \"bollywood\", \"bond\", \"bond\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"boom\", \"bore\", \"bore\", \"bore\", \"bori\", \"bradlei\", \"braff\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"broadcast\", \"broadcast\", \"broadwai\", \"broadwai\", \"bronson\", \"brook\", \"brook\", \"bruce\", \"bruce\", \"bruno\", \"bruno\", \"budget\", \"budget\", \"budget\", \"bug\", \"bug\", \"bullock\", \"bunni\", \"burton\", \"burton\", \"busei\", \"bush\", \"cain\", \"cain\", \"cain\", \"cain\", \"caligula\", \"caller\", \"campbel\", \"campbel\", \"campfir\", \"can\", \"cannib\", \"car\", \"car\", \"car\", \"car\", \"carei\", \"carel\", \"carli\", \"carlo\", \"carlo\", \"carmen\", \"carmen\", \"carnosaur\", \"carrot\", \"carson\", \"cartoon\", \"cartoon\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"catherin\", \"cathol\", \"cave\", \"chan\", \"chan\", \"chanei\", \"chaplin\", \"chaplin\", \"chappel\", \"charact\", \"charact\", \"charact\", \"charact\", \"charact\", \"charact\", \"charact\", \"charact\", \"charl\", \"charl\", \"charl\", \"charl\", \"charl\", \"charli\", \"charli\", \"charli\", \"charli\", \"charli\", \"cheaper\", \"cheapest\", \"cheerlead\", \"chess\", \"chipmunk\", \"chore\", \"christian\", \"christian\", \"christina\", \"christina\", \"christma\", \"christma\", \"christma\", \"christma\", \"christma\", \"christma\", \"chupacabra\", \"cinematographi\", \"cinematographi\", \"cinematographi\", \"cinematographi\", \"civil\", \"civil\", \"civil\", \"civil\", \"claudiu\", \"clint\", \"coach\", \"cobb\", \"cobra\", \"colin\", \"columbo\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comedi\", \"comedi\", \"comedi\", \"comedi\", \"comedi\", \"comedi\", \"comedi\", \"comedi\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"communist\", \"communist\", \"conan\", \"concert\", \"concert\", \"concord\", \"condit\", \"condit\", \"condit\", \"condit\", \"conneri\", \"conrad\", \"conrad\", \"conrad\", \"conroi\", \"consequ\", \"consequ\", \"consequ\", \"conspiraci\", \"constitut\", \"cooper\", \"cooper\", \"cop\", \"cop\", \"cop\", \"cop\", \"cop\", \"cope\", \"coppola\", \"corn\", \"corps\", \"cosmo\", \"costello\", \"couldn\", \"couldn\", \"couldn\", \"couldn\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"cowboi\", \"cowboi\", \"cowboi\", \"crap\", \"crap\", \"crappi\", \"creatur\", \"creatur\", \"creatur\", \"creatur\", \"creepi\", \"creepi\", \"creepi\", \"creepi\", \"crew\", \"crew\", \"crew\", \"crew\", \"crew\", \"crichton\", \"critter\", \"crummi\", \"crystal\", \"cultur\", \"cultur\", \"cultur\", \"cultur\", \"custer\", \"dae\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dai\", \"dam\", \"damm\", \"dan\", \"dan\", \"dan\", \"dan\", \"danc\", \"danc\", \"danc\", \"danc\", \"dancer\", \"dancer\", \"dant\", \"darci\", \"darwin\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dean\", \"dean\", \"dean\", \"dean\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"debbi\", \"decapit\", \"demi\", \"demon\", \"demon\", \"demon\", \"depict\", \"depict\", \"depict\", \"depict\", \"depth\", \"depth\", \"depth\", \"depth\", \"dien\", \"dillon\", \"dinosaur\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"director\", \"director\", \"director\", \"director\", \"director\", \"director\", \"director\", \"director\", \"director\", \"disabl\", \"disappoint\", \"disappoint\", \"disappoint\", \"disappoint\", \"disconnect\", \"discuss\", \"discuss\", \"discuss\", \"dismal\", \"disnei\", \"disnei\", \"disnei\", \"disnei\", \"distort\", \"documentari\", \"documentari\", \"documentari\", \"documentari\", \"doo\", \"dori\", \"dove\", \"dracula\", \"drake\", \"druid\", \"duck\", \"duck\", \"duh\", \"dumb\", \"dumb\", \"dumb\", \"dumbest\", \"dung\", \"dunn\", \"dunno\", \"dvd\", \"dvd\", \"dvd\", \"dvd\", \"dvd\", \"dvd\", \"dylan\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earli\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"eastend\", \"eastwood\", \"eater\", \"edison\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"egypt\", \"egyptian\", \"element\", \"element\", \"element\", \"ellen\", \"emot\", \"emot\", \"emot\", \"emot\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enemi\", \"enemi\", \"enemi\", \"enemi\", \"enemi\", \"enemi\", \"engin\", \"engin\", \"engin\", \"engin\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"episod\", \"episod\", \"episod\", \"erica\", \"erika\", \"ernest\", \"evan\", \"evan\", \"evil\", \"evil\", \"evil\", \"evil\", \"evil\", \"evil\", \"evil\", \"evil\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excruci\", \"exorcist\", \"experi\", \"experi\", \"experi\", \"experi\", \"experi\", \"experi\", \"experi\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"factual\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fanni\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"fbi\", \"fbi\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"firth\", \"flick\", \"flick\", \"flick\", \"flick\", \"flight\", \"flight\", \"flight\", \"fly\", \"fly\", \"fly\", \"fly\", \"fly\", \"fly\", \"fly\", \"flynn\", \"fonda\", \"fonda\", \"footag\", \"footag\", \"footag\", \"footag\", \"footag\", \"footag\", \"footbal\", \"footbal\", \"footbal\", \"footbal\", \"ford\", \"forman\", \"fort\", \"foxx\", \"franc\", \"franc\", \"franc\", \"franc\", \"franc\", \"franc\", \"franci\", \"franci\", \"frank\", \"frank\", \"frank\", \"frank\", \"frank\", \"frank\", \"frank\", \"frank\", \"frank\", \"frankenstein\", \"french\", \"french\", \"french\", \"french\", \"french\", \"french\", \"french\", \"french\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"frost\", \"fujimori\", \"fulci\", \"fuller\", \"funni\", \"funni\", \"funni\", \"funni\", \"funni\", \"funni\", \"funni\", \"futurist\", \"gabl\", \"gag\", \"gag\", \"gag\", \"gag\", \"gai\", \"gai\", \"gai\", \"gai\", \"gai\", \"gai\", \"game\", \"garbag\", \"garbag\", \"garbo\", \"garfield\", \"gargoyl\", \"gein\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"georg\", \"gere\", \"german\", \"germani\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"ghost\", \"ghost\", \"ghouli\", \"giant\", \"giant\", \"giant\", \"giant\", \"giant\", \"gibson\", \"gibson\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"glen\", \"glenda\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"gold\", \"gold\", \"gold\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"goon\", \"gore\", \"gori\", \"gorilla\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"govinda\", \"goya\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"grier\", \"grudg\", \"grudg\", \"gruesom\", \"gu\", \"gu\", \"gui\", \"gui\", \"gui\", \"gui\", \"gui\", \"guilt\", \"guitar\", \"guitar\", \"gulliv\", \"hacknei\", \"haircut\", \"halloween\", \"hamilton\", \"hamlet\", \"hamper\", \"hardi\", \"hardi\", \"harri\", \"harri\", \"harri\", \"harri\", \"harri\", \"harrison\", \"hartnett\", \"harvest\", \"hay\", \"hay\", \"hayworth\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"heist\", \"helicopt\", \"helicopt\", \"hepburn\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"herzog\", \"hindi\", \"histor\", \"histor\", \"histor\", \"histor\", \"histori\", \"histori\", \"histori\", \"histori\", \"histori\", \"histori\", \"histori\", \"hitch\", \"hitchcock\", \"hitchcock\", \"hitler\", \"hmmm\", \"hockei\", \"hogan\", \"holli\", \"holli\", \"holm\", \"holm\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hood\", \"hood\", \"hood\", \"horribl\", \"horribl\", \"horror\", \"horror\", \"hors\", \"hors\", \"hors\", \"hors\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hostag\", \"hour\", \"hour\", \"hour\", \"hour\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"hudson\", \"hudson\", \"hudson\", \"human\", \"human\", \"human\", \"human\", \"human\", \"husband\", \"husband\", \"husband\", \"husband\", \"ibm\", \"ic\", \"ic\", \"ic\", \"ic\", \"ic\", \"imag\", \"imag\", \"imag\", \"imag\", \"imag\", \"imag\", \"immatur\", \"incomprehens\", \"individu\", \"individu\", \"individu\", \"individu\", \"ineptitud\", \"infect\", \"intellectu\", \"intellectu\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"inuyasha\", \"island\", \"island\", \"island\", \"island\", \"island\", \"island\", \"island\", \"isra\", \"issu\", \"issu\", \"issu\", \"issu\", \"it\\u00b4\", \"jack\", \"jack\", \"jack\", \"jack\", \"jack\", \"jack\", \"jack\", \"jackal\", \"jackass\", \"jacki\", \"jacki\", \"jacki\", \"jackson\", \"jackson\", \"jackson\", \"jackson\", \"jackson\", \"jackson\", \"jacobi\", \"jacquelin\", \"jame\", \"jame\", \"jame\", \"jame\", \"jame\", \"jame\", \"jame\", \"jame\", \"jane\", \"jane\", \"jane\", \"jane\", \"japanes\", \"japanes\", \"japanes\", \"japanes\", \"japanes\", \"jason\", \"jason\", \"jason\", \"jason\", \"jason\", \"jean\", \"jean\", \"jean\", \"jean\", \"jean\", \"jean\", \"jean\", \"jefferson\", \"jerri\", \"jerri\", \"jerri\", \"jerri\", \"jerri\", \"jodi\", \"joe\", \"joe\", \"joe\", \"joe\", \"joe\", \"joe\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"johnson\", \"johnson\", \"johnson\", \"johnson\", \"joke\", \"joke\", \"joke\", \"jonathan\", \"jonathan\", \"juan\", \"juli\", \"juli\", \"juli\", \"juli\", \"julia\", \"julia\", \"julia\", \"juliet\", \"jungl\", \"jungl\", \"juri\", \"kahn\", \"kai\", \"karen\", \"karen\", \"karloff\", \"kasparov\", \"kennedi\", \"kennedi\", \"kennedi\", \"kennedi\", \"kennedi\", \"kermit\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kidnapp\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"killer\", \"killer\", \"killjoi\", \"kinda\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"king\", \"kirk\", \"klein\", \"knife\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"knowl\", \"komodo\", \"kung\", \"kurtz\", \"kutcher\", \"lack\", \"lack\", \"lack\", \"lack\", \"lack\", \"lamest\", \"lampoon\", \"lane\", \"lane\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"later\", \"laugh\", \"laugh\", \"laugh\", \"laurel\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"lee\", \"leguizamo\", \"leland\", \"leon\", \"lestat\", \"levi\", \"lewi\", \"lewi\", \"lewi\", \"lewi\", \"liar\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"lifeless\", \"likeabl\", \"lil\", \"listen\", \"listen\", \"listen\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"liz\", \"lizzi\", \"lloyd\", \"lloyd\", \"lone\", \"lone\", \"lone\", \"lone\", \"lone\", \"lone\", \"lonesom\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lorenzo\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lowest\", \"lugosi\", \"lumber\", \"lynch\", \"lynch\", \"lynch\", \"lyric\", \"madonna\", \"madsen\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"malkovich\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manson\", \"manti\", \"marathon\", \"mari\", \"mari\", \"mari\", \"mari\", \"marion\", \"marion\", \"marlow\", \"marri\", \"marri\", \"marri\", \"marri\", \"marri\", \"martha\", \"martha\", \"marti\", \"martial\", \"martial\", \"martial\", \"marx\", \"mash\", \"mason\", \"massacr\", \"massacr\", \"massacr\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"mayb\", \"mayb\", \"mayb\", \"mayb\", \"mayb\", \"mclaren\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meg\", \"mel\", \"mel\", \"mel\", \"melvil\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"mencia\", \"messag\", \"messag\", \"messag\", \"messag\", \"mexican\", \"mexican\", \"mexican\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"midget\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"min\", \"min\", \"minut\", \"minut\", \"minut\", \"minut\", \"minut\", \"miranda\", \"missil\", \"missil\", \"missionari\", \"monei\", \"monei\", \"monei\", \"monei\", \"monei\", \"monei\", \"monei\", \"monei\", \"monei\", \"monkei\", \"monkei\", \"monster\", \"monster\", \"montgomeri\", \"moor\", \"moor\", \"moor\", \"moor\", \"moor\", \"moor\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"mormon\", \"mose\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mstk\", \"muddl\", \"mumbl\", \"mummi\", \"muppet\", \"murder\", \"murder\", \"murder\", \"murder\", \"murder\", \"murder\", \"murphi\", \"murrai\", \"murrai\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"muslim\", \"myer\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"nazi\", \"nazi\", \"nbc\", \"nero\", \"network\", \"network\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"newton\", \"nielsen\", \"nikki\", \"ninja\", \"niro\", \"noah\", \"norma\", \"norma\", \"notion\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"nuclear\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"numbingli\", \"octopu\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"oldboi\", \"olivi\", \"olivi\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"orthodox\", \"overshadow\", \"owen\", \"owen\", \"pace\", \"pace\", \"pace\", \"pace\", \"pace\", \"pace\", \"pacino\", \"pam\", \"paranorm\", \"parent\", \"parent\", \"parent\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"pathet\", \"pathet\", \"pathet\", \"pathet\", \"patient\", \"patient\", \"patient\", \"patient\", \"patricia\", \"patricia\", \"patriot\", \"patriot\", \"patterson\", \"payton\", \"penguin\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"pepe\", \"perceiv\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perri\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"pete\", \"pete\", \"philosophi\", \"philosophi\", \"phoeb\", \"photographi\", \"photographi\", \"photographi\", \"photographi\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pilot\", \"pilot\", \"pilot\", \"pimp\", \"pimp\", \"pirat\", \"pirat\", \"pirat\", \"pirat\", \"pirat\", \"pitt\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plai\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"planet\", \"planet\", \"planet\", \"planet\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"pleasanc\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pola\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"ponyo\", \"pornographi\", \"portman\", \"portrai\", \"portrai\", \"portrai\", \"portrai\", \"portrai\", \"portrai\", \"portrai\", \"portrai\", \"portrait\", \"potter\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"predat\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"produc\", \"produc\", \"produc\", \"produc\", \"produc\", \"produc\", \"produc\", \"produc\", \"produc\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"program\", \"program\", \"program\", \"programm\", \"programm\", \"propaganda\", \"propaganda\", \"psychic\", \"psychopath\", \"pub\", \"puke\", \"punchlin\", \"puppet\", \"puppet\", \"quaid\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"race\", \"race\", \"race\", \"race\", \"race\", \"race\", \"race\", \"race\", \"race\", \"racism\", \"racism\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"rai\", \"rai\", \"rai\", \"rai\", \"rai\", \"randi\", \"randi\", \"randi\", \"ranger\", \"ranger\", \"ranger\", \"raptor\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"realiti\", \"realiti\", \"realiti\", \"realiti\", \"reba\", \"record\", \"record\", \"record\", \"record\", \"record\", \"record\", \"record\", \"record\", \"record\", \"redford\", \"relationship\", \"relationship\", \"relationship\", \"releas\", \"releas\", \"releas\", \"releas\", \"releas\", \"releas\", \"releas\", \"religi\", \"religi\", \"religi\", \"religion\", \"remad\", \"rent\", \"rent\", \"rent\", \"resurrect\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"reynold\", \"rhett\", \"rhy\", \"rhyme\", \"ricci\", \"rita\", \"rita\", \"roach\", \"robbin\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robin\", \"robocop\", \"robot\", \"rock\", \"rock\", \"rock\", \"rock\", \"rock\", \"rock\", \"rocket\", \"roger\", \"roger\", \"roger\", \"roger\", \"roger\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"romania\", \"romanian\", \"romant\", \"romant\", \"romant\", \"romant\", \"romant\", \"rome\", \"rommel\", \"rourk\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"russia\", \"russia\", \"russian\", \"ryan\", \"ryan\", \"ryan\", \"ryan\", \"ryan\", \"ryan\", \"salman\", \"sander\", \"sandler\", \"sandra\", \"sant\", \"sara\", \"sarandon\", \"satan\", \"satan\", \"satellit\", \"saudi\", \"scare\", \"scare\", \"scarecrow\", \"scari\", \"scari\", \"scari\", \"scarlett\", \"sceneri\", \"sceneri\", \"sceneri\", \"sceneri\", \"sceneri\", \"sceneri\", \"schaech\", \"schneider\", \"scienc\", \"scienc\", \"scienc\", \"scienc\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"script\", \"script\", \"script\", \"script\", \"script\", \"script\", \"script\", \"seagal\", \"sean\", \"sean\", \"sean\", \"sean\", \"season\", \"season\", \"season\", \"season\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"segal\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"senseless\", \"seri\", \"seri\", \"seri\", \"seri\", \"seri\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sexual\", \"sexual\", \"sexual\", \"sexual\", \"shatner\", \"shatner\", \"shearer\", \"sheen\", \"sheen\", \"sheep\", \"shelf\", \"sherlock\", \"ship\", \"ship\", \"ship\", \"shirlei\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shriek\", \"shylock\", \"sinatra\", \"sing\", \"sing\", \"sing\", \"sing\", \"singer\", \"singer\", \"singer\", \"sissi\", \"sister\", \"sister\", \"sister\", \"sister\", \"skateboard\", \"skeleton\", \"ski\", \"slasher\", \"slot\", \"slower\", \"snake\", \"snake\", \"snipe\", \"snowbal\", \"snowman\", \"snowman\", \"soccer\", \"social\", \"social\", \"social\", \"societi\", \"societi\", \"societi\", \"softcor\", \"soldier\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"song\", \"song\", \"song\", \"song\", \"sorri\", \"sorri\", \"sorri\", \"soultak\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"soundtrack\", \"soundtrack\", \"soundtrack\", \"soundtrack\", \"soundtrack\", \"soundtrack\", \"soviet\", \"space\", \"space\", \"space\", \"spacei\", \"spade\", \"spaghetti\", \"spaghetti\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"spiritu\", \"splatter\", \"spock\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stan\", \"stanwyck\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"station\", \"station\", \"station\", \"station\", \"station\", \"station\", \"station\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stoner\", \"stoog\", \"stori\", \"stori\", \"stori\", \"stori\", \"stori\", \"stori\", \"stori\", \"stori\", \"straw\", \"stripper\", \"stuf\", \"stupid\", \"stupid\", \"stupidest\", \"styliz\", \"subject\", \"subject\", \"subject\", \"subject\", \"subwai\", \"suck\", \"suck\", \"suicid\", \"suicid\", \"suicid\", \"suicid\", \"superhero\", \"surrealist\", \"susan\", \"swayz\", \"sword\", \"sword\", \"sword\", \"symbol\", \"symbol\", \"symbol\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talentless\", \"tan\", \"tart\", \"tarzan\", \"taylor\", \"taylor\", \"taylor\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"teddi\", \"televis\", \"televis\", \"televis\", \"televis\", \"televis\", \"televis\", \"terribl\", \"terribl\", \"terribl\", \"terribl\", \"terrorist\", \"terrorist\", \"terrorist\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"tim\", \"tim\", \"tim\", \"tim\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timothi\", \"tom\", \"tom\", \"tom\", \"tom\", \"tom\", \"tom\", \"tom\", \"tom\", \"tom\", \"tommi\", \"tommi\", \"tommi\", \"topless\", \"topless\", \"traci\", \"traitor\", \"trashi\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travolta\", \"trek\", \"trek\", \"trek\", \"trivialbor\", \"troll\", \"troma\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"turd\", \"turkei\", \"turkei\", \"turkei\", \"turkei\", \"turkei\", \"turkei\", \"turkish\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"uncl\", \"uncl\", \"uncl\", \"uncl\", \"underdevelop\", \"unexcit\", \"unfunni\", \"unfunni\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"vampir\", \"vampir\", \"van\", \"van\", \"van\", \"van\", \"van\", \"vega\", \"vega\", \"venu\", \"vera\", \"veronica\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"victim\", \"victim\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"viewer\", \"viewer\", \"viewer\", \"viewer\", \"viewer\", \"viewpoint\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"vinc\", \"vinni\", \"violenc\", \"violenc\", \"violenc\", \"violenc\", \"viru\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"voic\", \"volcano\", \"voodoo\", \"wagon\", \"wai\", \"wai\", \"wai\", \"wai\", \"wai\", \"wai\", \"wai\", \"wai\", \"walker\", \"walker\", \"wallac\", \"wanna\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"war\", \"war\", \"war\", \"warden\", \"wasn\", \"wasn\", \"wasn\", \"wasn\", \"wasn\", \"wasn\", \"wast\", \"wast\", \"wast\", \"wast\", \"wayan\", \"wayn\", \"wayn\", \"weed\", \"werewolf\", \"werewolf\", \"werewolf\", \"weslei\", \"west\", \"west\", \"west\", \"west\", \"west\", \"west\", \"western\", \"western\", \"western\", \"western\", \"western\", \"western\", \"western\", \"whine\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"willi\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"william\", \"wilson\", \"wilson\", \"wilson\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wine\", \"wine\", \"wine\", \"witch\", \"witch\", \"witless\", \"wolf\", \"wolf\", \"wolf\", \"wolf\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"wors\", \"wors\", \"wors\", \"wors\", \"wors\", \"wors\", \"worst\", \"worst\", \"worst\", \"worst\", \"wow\", \"wow\", \"wrestl\", \"wrestl\", \"wrestler\", \"wwe\", \"wwii\", \"wynorski\", \"yeah\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"young\", \"young\", \"young\", \"young\", \"young\", \"young\", \"young\", \"young\", \"young\", \"zeta\", \"zoei\", \"zombi\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 7, 9, 15, 1, 8, 10, 14, 4, 3, 13, 2, 12, 11, 6]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1231407110429191846966539470\", ldavis_el1231407110429191846966539470_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1231407110429191846966539470\", ldavis_el1231407110429191846966539470_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1231407110429191846966539470\", ldavis_el1231407110429191846966539470_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "4     -0.287906  0.008558       1        1  21.181749\n",
              "6     -0.259813 -0.017220       2        1  17.099566\n",
              "8     -0.236518  0.028064       3        1  14.942209\n",
              "14    -0.198092  0.060530       4        1  13.444116\n",
              "0     -0.176628  0.068556       5        1   8.870417\n",
              "7     -0.135626 -0.101511       6        1   8.538270\n",
              "9      0.066336 -0.091754       7        1   2.613551\n",
              "13     0.075147  0.131354       8        1   2.552893\n",
              "3      0.044115 -0.127253       9        1   2.276260\n",
              "2      0.139844 -0.157211      10        1   1.680173\n",
              "12     0.178628  0.003357      11        1   1.441548\n",
              "1      0.187819  0.226976      12        1   1.408853\n",
              "11     0.199203 -0.075226      13        1   1.379766\n",
              "10     0.193920 -0.099932      14        1   1.289342\n",
              "5      0.209570  0.142711      15        1   1.281285, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
              "189     music   3895.000000   3895.000000  Default  30.0000  30.0000\n",
              "87        bad  10253.000000  10253.000000  Default  29.0000  29.0000\n",
              "446      plai   8340.000000   8340.000000  Default  28.0000  28.0000\n",
              "422      love   7775.000000   7775.000000  Default  27.0000  27.0000\n",
              "1039      war   2239.000000   2239.000000  Default  26.0000  26.0000\n",
              "...       ...           ...           ...      ...      ...      ...\n",
              "766    return    136.585419   1094.003052  Topic15  -5.3996   2.2767\n",
              "2831    blade    100.161598    193.694427  Topic15  -5.7098   3.6978\n",
              "2462    comic    119.516289   1036.601318  Topic15  -5.5331   2.1971\n",
              "4011  cartoon    114.326988    676.499573  Topic15  -5.5775   2.5794\n",
              "411      hero    100.433182   1337.465210  Topic15  -5.7071   1.7683\n",
              "\n",
              "[1022 rows x 6 columns], token_table=       Topic      Freq    Term\n",
              "term                          \n",
              "8396      10  0.993657   aaron\n",
              "6119      12  0.979519  abbott\n",
              "2654       3  0.919438    abus\n",
              "2654       4  0.062293    abus\n",
              "2654       6  0.017442    abus\n",
              "...      ...       ...     ...\n",
              "1292      10  0.010604   young\n",
              "1292      11  0.000624   young\n",
              "12079      2  0.990385    zeta\n",
              "38038      1  0.992930    zoei\n",
              "2544       4  0.998681   zombi\n",
              "\n",
              "[2828 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 7, 9, 15, 1, 8, 10, 14, 4, 3, 13, 2, 12, 11, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sg1UzzQ98N5",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with BERT\n",
        "In the second part, we will use sentiment analysis with BERT on the reviews according to topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8_OZicX-eVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "e3eabb91-a65b-420b-e80f-2c57c4e8077a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=37f61cbe35aa8759cbc90a59c74d9b6382760e45903ebad6395b1cc6208649ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHnGvZR4-b2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "681af7c040a24a8388b1243e44d7503c",
            "8363e67accaa4c328f7a1c658bd81996",
            "e48e1146e0a7416a8cf63ce2dc2a500b",
            "f72f62c7a55c4a49ad790430995d741e",
            "97aa0ad91a734b49852f0e9bf2befd0a",
            "271c7621d3484d27a4a72cf0baed171a",
            "447b684f51b3416bbc7dc395119c3329",
            "274dc6e5a9544e46bba1f5887ab108ec"
          ]
        },
        "outputId": "6e9e5e89-284d-4c11-978f-f3dc4302e5ce"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681af7c040a24a8388b1243e44d7503c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XraXSDhojh-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Dominant_Topic']=df_dominant_topic['Dominant_Topic']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "908AJMvl8GyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=[]\n",
        "documents=[]\n",
        "\n",
        "groups=df.groupby(['Dominant_Topic'])\n",
        "for name, sentiment in groups['Sentiment']:\n",
        "  labels.append(sentiment.tolist())\n",
        "for name, review in groups['Review']:\n",
        "  documents.append(review.tolist())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt6JFR9Uj8sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "345a3062-bf7c-4555-a0cf-06847fda1091"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', data[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(data[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(data[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss. A holiday to Burma with her sister seemed like a good idea to get away from it all, but when her passport was stolen in Rangoon, she could not leave the country with her sister, and was forced to stay back until she could get I.D. papers from the American embassy. To fill in a day before she could fly out, she took a trip into the countryside with a tour guide. \"I tried finding something in those stone statues, but nothing stirred in me. I was stone myself.\" <br /><br />Suddenly all hell broke loose and she was caught in a political revolt. Just when it looked like she had escaped and safely boarded a train, she saw her tour guide get beaten and shot. In a split second she decided to jump from the moving train and try to rescue him, with no thought of herself. Continually her life was in danger. <br /><br />Here is a woman who demonstrated spontaneous, selfless charity, risking her life to save another. Patricia Arquette is beautiful, and not just to look at; she has a beautiful heart. This is an unforgettable story. <br /><br />\"We are taught that suffering is the one promise that life always keeps.\"\n",
            "Tokenized:  ['based', 'on', 'an', 'actual', 'story', ',', 'john', 'boo', '##rman', 'shows', 'the', 'struggle', 'of', 'an', 'american', 'doctor', ',', 'whose', 'husband', 'and', 'son', 'were', 'murdered', 'and', 'she', 'was', 'continually', 'plagued', 'with', 'her', 'loss', '.', 'a', 'holiday', 'to', 'burma', 'with', 'her', 'sister', 'seemed', 'like', 'a', 'good', 'idea', 'to', 'get', 'away', 'from', 'it', 'all', ',', 'but', 'when', 'her', 'passport', 'was', 'stolen', 'in', 'rang', '##oon', ',', 'she', 'could', 'not', 'leave', 'the', 'country', 'with', 'her', 'sister', ',', 'and', 'was', 'forced', 'to', 'stay', 'back', 'until', 'she', 'could', 'get', 'i', '.', 'd', '.', 'papers', 'from', 'the', 'american', 'embassy', '.', 'to', 'fill', 'in', 'a', 'day', 'before', 'she', 'could', 'fly', 'out', ',', 'she', 'took', 'a', 'trip', 'into', 'the', 'countryside', 'with', 'a', 'tour', 'guide', '.', '\"', 'i', 'tried', 'finding', 'something', 'in', 'those', 'stone', 'statues', ',', 'but', 'nothing', 'stirred', 'in', 'me', '.', 'i', 'was', 'stone', 'myself', '.', '\"', '<', 'br', '/', '>', '<', 'br', '/', '>', 'suddenly', 'all', 'hell', 'broke', 'loose', 'and', 'she', 'was', 'caught', 'in', 'a', 'political', 'revolt', '.', 'just', 'when', 'it', 'looked', 'like', 'she', 'had', 'escaped', 'and', 'safely', 'boarded', 'a', 'train', ',', 'she', 'saw', 'her', 'tour', 'guide', 'get', 'beaten', 'and', 'shot', '.', 'in', 'a', 'split', 'second', 'she', 'decided', 'to', 'jump', 'from', 'the', 'moving', 'train', 'and', 'try', 'to', 'rescue', 'him', ',', 'with', 'no', 'thought', 'of', 'herself', '.', 'continually', 'her', 'life', 'was', 'in', 'danger', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'here', 'is', 'a', 'woman', 'who', 'demonstrated', 'spontaneous', ',', 'self', '##less', 'charity', ',', 'risking', 'her', 'life', 'to', 'save', 'another', '.', 'patricia', 'ar', '##quette', 'is', 'beautiful', ',', 'and', 'not', 'just', 'to', 'look', 'at', ';', 'she', 'has', 'a', 'beautiful', 'heart', '.', 'this', 'is', 'an', 'un', '##for', '##get', '##table', 'story', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', '\"', 'we', 'are', 'taught', 'that', 'suffering', 'is', 'the', 'one', 'promise', 'that', 'life', 'always', 'keeps', '.', '\"']\n",
            "Token IDs:  [2241, 2006, 2019, 5025, 2466, 1010, 2198, 22017, 14515, 3065, 1996, 5998, 1997, 2019, 2137, 3460, 1010, 3005, 3129, 1998, 2365, 2020, 7129, 1998, 2016, 2001, 14678, 17808, 2007, 2014, 3279, 1012, 1037, 6209, 2000, 11050, 2007, 2014, 2905, 2790, 2066, 1037, 2204, 2801, 2000, 2131, 2185, 2013, 2009, 2035, 1010, 2021, 2043, 2014, 12293, 2001, 7376, 1999, 8369, 7828, 1010, 2016, 2071, 2025, 2681, 1996, 2406, 2007, 2014, 2905, 1010, 1998, 2001, 3140, 2000, 2994, 2067, 2127, 2016, 2071, 2131, 1045, 1012, 1040, 1012, 4981, 2013, 1996, 2137, 8408, 1012, 2000, 6039, 1999, 1037, 2154, 2077, 2016, 2071, 4875, 2041, 1010, 2016, 2165, 1037, 4440, 2046, 1996, 10833, 2007, 1037, 2778, 5009, 1012, 1000, 1045, 2699, 4531, 2242, 1999, 2216, 2962, 11342, 1010, 2021, 2498, 13551, 1999, 2033, 1012, 1045, 2001, 2962, 2870, 1012, 1000, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 3402, 2035, 3109, 3631, 6065, 1998, 2016, 2001, 3236, 1999, 1037, 2576, 10073, 1012, 2074, 2043, 2009, 2246, 2066, 2016, 2018, 6376, 1998, 9689, 17383, 1037, 3345, 1010, 2016, 2387, 2014, 2778, 5009, 2131, 7854, 1998, 2915, 1012, 1999, 1037, 3975, 2117, 2016, 2787, 2000, 5376, 2013, 1996, 3048, 3345, 1998, 3046, 2000, 5343, 2032, 1010, 2007, 2053, 2245, 1997, 2841, 1012, 14678, 2014, 2166, 2001, 1999, 5473, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2182, 2003, 1037, 2450, 2040, 7645, 17630, 1010, 2969, 3238, 5952, 1010, 26875, 2014, 2166, 2000, 3828, 2178, 1012, 10717, 12098, 29416, 2003, 3376, 1010, 1998, 2025, 2074, 2000, 2298, 2012, 1025, 2016, 2038, 1037, 3376, 2540, 1012, 2023, 2003, 2019, 4895, 29278, 18150, 10880, 2466, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1000, 2057, 2024, 4036, 2008, 6114, 2003, 1996, 2028, 4872, 2008, 2166, 2467, 7906, 1012, 1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvnQ5UHYD6eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-cEPt6H-ANA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bdefacb-bedf-4368-aa62-dfe470b77486"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for document in documents:\n",
        "  for sentence in document:\n",
        "\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
        "\n",
        "      # Update the maximum sentence length.\n",
        "      max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  3157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhALPs7-7YR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "d8d6d499-0629-4571-b2f2-851905b68680"
      },
      "source": [
        "# Tokenize all of the data and map the tokens to thier word IDs.\n",
        "input_ids = [[] for x in range(NUM_TOPICS)]\n",
        "attention_masks = [[] for x in range(NUM_TOPICS)]\n",
        "\n",
        "# For every group...\n",
        "topic_counter=0\n",
        "for document in documents:\n",
        "  # For every document...\n",
        "  for sentence in document:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 3200,           # Pad & truncate all data.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids[topic_counter].append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks[topic_counter].append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "  input_ids[topic_counter] = torch.cat(input_ids[topic_counter], dim=0)\n",
        "  attention_masks[topic_counter] = torch.cat(attention_masks[topic_counter], dim=0)\n",
        "  labels[topic_counter] = torch.tensor(labels[topic_counter])\n",
        "\n",
        "  # Print sentence 0, now as a list of IDs.\n",
        "  print('Original: ', documents[topic_counter][0])\n",
        "  print(topic_counter)\n",
        "  print('Token IDs:', input_ids[topic_counter][0])\n",
        "  topic_counter+=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I played Sam (the porter, Lou's sidekick) in the Film \"Dead Rail\" Which later aired as \"Alien Express.\" And, I have to say that for my part I thoroughly enjoyed watching this film. As a struggling actor this was a chance for me to work with fantastic people, it gave me great scenes to include on my reel, and it allowed me to work on a dream job for a month and a half (no waiting tables!) Turi(the director) And Steve and Scott (the producers) Were very kind by giving me this opportunity to participate in the production. I made many friends (Lou, Todd, Steven) and I consider myself very fortunate to have been able to work with these incredibly talented people. There was not a day that went by that I did not laugh my butt off. The real tragedy isn't so much the special effects, it's that every single person who watched this film didn't get to see what happened behind the scenes and all the talent that truly went into it. Craftsmen building the set, prop masters, gaffers,wardrobe, makeup artists, script supervisors, the cinematographer, production assistants, extras, craft services, producers, director, and actors. It's a given that Sci fi didn't spend a terrible amount of money on the film (2 million) But There was a lot of time, energy, and man power that was instilled into it. I look on the film now as a production that brought a lot of talented people together for a fun project that was shot without complications in less than two months. It was a magnificent cast and crew and I'm just so glad to be apart of it! On a further note to those of you who don't know Lou Diamond Phillips, Todd Bridges, and Steven Brand. They are fantastic people who are incredibly funny. Lou I still am working on my Deniro impression and can't thank you enough for introducing me to \"midnight Run.\" Todd, every time I hear an Elvis song I can't forget the story you told me about hanging out with him at his house for dinner. \"Can you please pass me the pa tators?\" (IM A HUGE ELVIS FAN!) Steven, \"Mr. Brand!\" You are a true gent and all the advice and encouragement I received from you will always be appreciated. I miss you guys and hope you are well. Thanks for the good memories, stories, jokes,and friendship. Oh and miss Utah says hello! wink wink.<br /><br />joe-\n",
            "0\n",
            "Token IDs: tensor([ 101, 1045, 2209,  ...,    0,    0,    0])\n",
            "Original:  This film marked the end of the \"serious\" Universal Monsters era (Abbott and Costello meet up with the monsters later in \"Abbott and Costello Meet Frankentstein\"). It was a somewhat desparate, yet fun attempt to revive the classic monsters of the Wolf Man, Frankenstein's monster, and Dracula one \"last\" time.<br /><br />I say desparate, because in the previous film, \"House of Frankenstein,\" both Dracula and the Wolf Man are killed according to how the vampire and werewolf legends say they should be (Dracula by the sunlight, and the wolf man by a silver bullet). Yet somehow they return in House of Dracula with no explanation. This movie could have played as a kind of prequel to House of Frankenstein if the Frankenstein monster plot wouldn't be continuing chronologically into House of Dracula from House of Frankenstein, and if the wolf man didn't get cured. Then there'd be no plot holes. But since this is not the case, the plots of Dracula and the Wolf Man make no sense.<br /><br />However, ignoring these plot holes, House of Dracula is a classic atmospheric horror film that's fun to watch. It has many high points. Especially seeing the wolf man get cured. I know I just said that this shouldn't have been included, but it was nice to actually see him get cured after all this time. And the scene with the lady playing \"Moonlight Senada,\" on the piano then all of a sudden playing a haunting melody when under Dracula's spell was very eerie. Dr. Edleman's transformation into the \"Dr. Jekyl/Mr. Hyde\" type character was also done very well.<br /><br />And it's great to see Dracula, Frankenstein, and the Wolf Man together, one \"last\" time.<br /><br />*** out of ****\n",
            "1\n",
            "Token IDs: tensor([ 101, 2023, 2143,  ...,    0,    0,    0])\n",
            "Original:  Sam Lion (Jean Paul Belmondo) discovers he needs to take some time off as everybody around him relies to much on him and stages his own death. When he discovers those he loved ans still loves are in need, he gets Albert Duvivier (Richard Anconina) to help them. In search of his own past, of his own desires, this fabulous film by Claude Lelouch is a man's quest for himself at a ripe age.<br /><br />Built like all Lelouch films, the film's beginning with constant flashbacks may be puzzling, especially scenes where Paul Belmondo (who looks a huge lot like his father) is playing a young Sam Lion while Sam Lion stands in the same room - a flashback sequence which takes a second to grasp.<br /><br />One of Lelouch's most elaborate works, L'itineraire d'un infant gate is a must-see tale of self fulfilment.\n",
            "2\n",
            "Token IDs: tensor([ 101, 3520, 7006,  ...,    0,    0,    0])\n",
            "Original:  I bought my first Zep album in 1974 (at 17) and have been hooked ever since. This DVD has now taken pride of place in my music collection. It is not often that a band can boast 4 virtuosos in their lineup but here we can. Each member made their own contribution to the band but on the stage together, the electricity they generated was bigger than the 4 individuals. This masterpiece covers the band's entire career from Led Zep 1 to Coda and this is captured magnificently on this DVD as each concert shows how the band became bigger and bigger over the years. Recently my copy disappeared, but I'm happy to say was found in my 17yo son's room as the new generation discover just how great these guys were. This is a must have for anyone who has an appreciation of rock music. Long live Led Zeppelin.\n",
            "3\n",
            "Token IDs: tensor([ 101, 1045, 4149,  ...,    0,    0,    0])\n",
            "Original:  I really like this show. It has drama, romance, and comedy all rolled into one. I am 28 and I am a married mother, so I can identify both with Lorelei's and Rory's experiences in the show. I have been watching mostly the repeats on the Family Channel lately, so I am not up-to-date on what is going on now. I think females would like this show more than males, but I know some men out there would enjoy it! I really like that is an hour long and not a half hour, as th hour seems to fly by when I am watching it! Give it a chance if you have never seen the show! I think Lorelei and Luke are my favorite characters on the show though, mainly because of the way they are with one another. How could you not see something was there (or take that long to see it I guess I should say)? <br /><br />Happy viewing!\n",
            "4\n",
            "Token IDs: tensor([ 101, 1045, 2428,  ...,    0,    0,    0])\n",
            "Original:  i originally seen the flash Gordon serial on PBS,and thought it was fun and awesome,i overlooked the special effects of the rocket ships with sparklers,and the big dragon monster with lobster claws,who cares this is 1936 and it was a serial,so each week they would show a new chapter, buster Crabbe played flash Gordon 3 times,in all 3 serials.then in 1939 he played buck rogers,in 1933 he played Tarzan the fearless.he was a very busy actor.beautiful jean rogers played sexy dale Arden.frank Shannon as professor zarkov,and Charles Middleton played the evil ming the merciless.he makes Darth Vader look like a boyscout.the serials were very close to the Alex Raymond comic strip.space travel was just a pipe dream at the time.not to mention ray guns and television.this one stands out as the best serial ever.the sequel flash Gordon's trip to mars is 2 chapters longer,the next flash Gordon conquers the universe is only 12 chapters.and then there's the natives of mongo..,hawk-men, lion-men,shark-men.the feature version leaves out the shark-men scenes. for the full effect you must see the complete serial.i heard George Lucas was inspired by flash Gordon when he did star wars.flash Gordon was from universal studios.and the music on the soundtrack is from many universal movies like bride of Frankenstein,werewolf of London,Dracula's daughter,etc;even today flash Gordon continues to delight people young and old.10 out of 10.\n",
            "5\n",
            "Token IDs: tensor([ 101, 1045, 2761,  ...,    0,    0,    0])\n",
            "Original:  This is a gem. As a Film Four production - the anticipated quality was indeed delivered. Shot with great style that reminded me some Errol Morris films, well arranged and simply gripping. It's long yet horrifying to the point it's excruciating. We know something bad happened (one can guess by the lack of participation of a person in the interviews) but we are compelled to see it, a bit like a car accident in slow motion. The story spans most conceivable aspects and unlike some documentaries did not try and refrain from showing the grimmer sides of the stories, as also dealing with the guilt of the people Don left behind him, wondering why they didn't stop him in time. It took me a few hours to get out of the melancholy that gripped me after seeing this very-well made documentary.\n",
            "6\n",
            "Token IDs: tensor([ 101, 2023, 2003,  ...,    0,    0,    0])\n",
            "Original:  Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss. A holiday to Burma with her sister seemed like a good idea to get away from it all, but when her passport was stolen in Rangoon, she could not leave the country with her sister, and was forced to stay back until she could get I.D. papers from the American embassy. To fill in a day before she could fly out, she took a trip into the countryside with a tour guide. \"I tried finding something in those stone statues, but nothing stirred in me. I was stone myself.\" <br /><br />Suddenly all hell broke loose and she was caught in a political revolt. Just when it looked like she had escaped and safely boarded a train, she saw her tour guide get beaten and shot. In a split second she decided to jump from the moving train and try to rescue him, with no thought of herself. Continually her life was in danger. <br /><br />Here is a woman who demonstrated spontaneous, selfless charity, risking her life to save another. Patricia Arquette is beautiful, and not just to look at; she has a beautiful heart. This is an unforgettable story. <br /><br />\"We are taught that suffering is the one promise that life always keeps.\"\n",
            "7\n",
            "Token IDs: tensor([ 101, 2241, 2006,  ...,    0,    0,    0])\n",
            "Original:  There is no need for me to repeat the synopsis rendered by Glenn. The black and white rendition is even more powerful in portraying the bleakness of country village life at that time. The deep measure of friendship shown by Babette toward the two elderly sisters touches the heart strings. The supporting cast is excellent and their performances superb, it would not be fair to single out any one character since the entire story depends on the cast as a whole. I cannot put my finger exactly on why I rate this movie so highly since I am not a professional critic; individual viewers may or may not agree with my rating since enjoyment of this type of movie is always in the eye of the beholder.\n",
            "8\n",
            "Token IDs: tensor([ 101, 2045, 2003,  ...,    0,    0,    0])\n",
            "Original:  In 1983 two Bond movies was made, one was the official Bond movie Octopussy starring Roger Moore who starred as James Bond for the first time in Live and Let Die and the other was the unofficial Bond movie Never Say Never Again starring Sean Connery who played the role as James Bond for the first time in Dr. No, that film was also the first 007 James Bond movie to be made. Never Say Never Again is called unofficial because the company that made the other James Bond movies didn't make this one. Never Say Never Again is also a remake of the 1965 007 movie Thunderball, there are several differences in Never Say Never Again that lets you know it wasn't made by EON. One thing is that the opening is different, there's no gun barrel sequence and no pre-credit sequence, another difference is the music score. Some things in this movie does feel like a James Bond movie like the gadgets and cars, plus James Bond always getting it on with the ladies and the film does have an opening credits song. Sean Connery still does a great job playing Bond, the acting from the other stars is also great. <br /><br />Never Say Never Again is a good film that's just has entertaining as the official James Bond films. Check this out. 10/10\n",
            "9\n",
            "Token IDs: tensor([ 101, 1999, 3172,  ...,    0,    0,    0])\n",
            "Original:  Once upon a time, Troma, the company that brought us cinema classics such as: The Toxic Avenger, Rabid Grannies, Poultrygeist, Redneck Zombies and Surf Nazis Must Die, decided long ago to adapt Shakespeare's famous play, 'Romeo and Juliet.' This adaptation decided to spice up the story by adding kinky sex, extreme violence, genital monsters, body piercing and incest and it succeeded in creating a bizarre yet hilarious film. Anyone going into a Troma production should know what to expect, and that is irreverent and perverse comedy with plenty of political incorrectness. Expect plenty of nods to other Troma films and plenty of re-used gags (flipping cars and head squashing). Many may think it sounds like utter crap that only morons would find funny...they may be right, but at the same time they may need to lighten up and enjoy the insanity and mind-numbingness that is Tromeo and Juliet.<br /><br />With a great cast, a funny script (by James Gunn and Lloyd Kaufman), a fitting soundtrack and plenty of great visual gags, Kaufman has yet again succeeded in turning what is right upside down and grossing the hell out of everyone. Get some popcorn, grab a beer, invite your friends over and enjoy Tromeo and Juliet for what it is, a Shakespeare adaptation with plenty of balls. The end.<br /><br />4/5\n",
            "10\n",
            "Token IDs: tensor([ 101, 2320, 2588,  ...,    0,    0,    0])\n",
            "Original:  Dolelemite (1975) is a cult classic. Starring Rudy Ray Moore as the pimp superhero out to wrong rights whilst challenging the MAN along the way. He has two enemies, that no good Willie Green and the sleazy mayor. Watch Dolemite kick, punch, slap and pimp his way across the screen. What's the man's name? DOLEMITE!<br /><br />Interesting film that paved the way for a generation of rappers and performers. To sell more of his party albums, Rudy Ray Moore made several on the cheap films during the seventies. Self produced and marketed he catered towards a specific audience. Some people call it blacksploitation others call it trash, I call it entertaining. Dolemite was followed by the semi-sequel The Human Tornado and a direct to video Return of Dolemite 25 years later.<br /><br />Highly recommended, a definite cult classic! <br /><br />Footnotes, if the film was properly matted on video you wouldn't see the boom mikes. Dolemite was cut to receive an R-rating.\n",
            "11\n",
            "Token IDs: tensor([ 101, 2079, 2571,  ...,    0,    0,    0])\n",
            "Original:  This is a luminously photographed and unusually well-written western by veteran creator of \"Rawhide\" Charles Marquis Warren. Direcxtor Gordon Douglas is its chief help in this regard. Its strong plot line can be told in a few sentences. A hard-nosed by-the- book, Cavalry officer, Captain Richard Lance, captures a leader of the Indian enemy after a massacre at a fort. He insists on bringing the man back for trial, to be sent toTucson; his commander sends another man to try to take the prisoner for trial and the patrol is wiped out. This means the leader has escaped, and Lance must now lead a second patrol--and he picks the men the fort can most spare, a company of problems-- to defend the advance fort that had been wiped out and save the command from another attack by stopping up the bottleneck pass in that sector. As Lance, young Gregory Peck is quite strong. Other in the large cast of this film which really shows life at a cavalry outpost looking like an army establishment of heterogeneous and quarreling types includes War Bond powerful as a hard-drinking sergeant, Neville Brand and Steve Brodie as troublemakers, Warner Anderson and Lon Chaney Jr. as psychological troublemakers and Gig Young, Art Baker, Herbert Heyes as fellow officers with Nana Bryant as the Colonel's wife. Even Barbara Payton as the love interest gets by in a difficult role; Michael Ansara is the captured war chief, and Jeff Corey plays the Fort's scout. There are really two great scenes in this very-well-made western--the long section at the fort before the last patrol is sent out, and that long patrol to the doomed Ft. Defiant itself. Once at that fort, Peck gets to deliver a grand speech in which at the demand of the men he has lined up for orders, he tells them each why he took them along. reading them their shortcomings one by one; they then tell them why they think he sent his best friend to die in his place take the Indian in instead of going himself-- and he proves them wrong for the remainder of the film by winning his lonely battle through intelligence and courage. The music by Franz Waxman is good, the production qualities admirable; the argument about what would happen if Lance takes the war chief in happens to be true; other than this unsolvable mistake by the central character, this is is great western. it has been a favorite of mine for fifty years.\n",
            "12\n",
            "Token IDs: tensor([ 101, 2023, 2003,  ...,    0,    0,    0])\n",
            "Original:  I grew up outside of Naila Germany(where they landed),every detail of the film was 100% authentic,the power lines that they flew over,the nosy neighbors,the grandmother telling the kids that they cant watch west German TV,etc..This movie brings back lots of good memories to those that are European,a great production from Disney...The same movie in German has Klaus Lowitsch and Gunter Meisner using their own voices for translating the English version into German...for the German version they also use Cookoo birds ,a bird that is native to Germany as background noise to let you know that you are in Germany..I showed this move to many of my German relative and they really liked this movie.(these people made made a prototype balloon which they had to give up because the materials that they used was too porous and the other 2 balloons that they used for the escape.The burner problem was solved when they turned the propane cylinders upside down.)\n",
            "13\n",
            "Token IDs: tensor([ 101, 1045, 3473,  ...,    0,    0,    0])\n",
            "Original:  In the future, a disparate group of people asleep aboard a commercial spaceship is forced to improvise their survival when the spaceship crash-lands on a remote, barren planet. They already have one problem in that one of the passengers is intense criminal Richard Riddick (Vin Diesel, in his first top-billed role); however, they are soon preyed upon by a strange species of predator that thrives in the darkness - and a rare solar eclipse is soon to take place.<br /><br />While the script for this movie is ultimately on the routine side, it is decently acted and it is especially well-made technically. Location work, photography, and design (production as well as creature design) are all very impressive. It is not the most original or stimulating science-fiction / horror picture ever made, far from it, but it still provides good entertainment. Diesel is particularly good at getting under the skin of his intimidating character. It is not ENTIRELY predictable, however, and gets some points for<br /><br />**SPOILER**<br /><br />having a more politically correct ending than most of its type.<br /><br />Filmed on location in the desolate Coober Pedy area of Queensland in Australia.<br /><br />A sequel of sorts is in the works.<br /><br />7/10\n",
            "14\n",
            "Token IDs: tensor([ 101, 1999, 1996,  ...,    0,    0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHgD8Co1_koc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d1e02d9e-a88e-43d7-947b-324560432b25"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset= [[] for x in range(NUM_TOPICS)]\n",
        "train_dataset= [[] for x in range(NUM_TOPICS)]\n",
        "val_dataset= [[] for x in range(NUM_TOPICS)]\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "for i in range(NUM_TOPICS):\n",
        "  dataset[i] = TensorDataset(input_ids[i], attention_masks[i], labels[i])\n",
        "  # Create a 90-10 train-validation split.\n",
        "\n",
        "  # Calculate the number of samples to include in each set.\n",
        "  train_size = int(0.9 * len(dataset[i]))\n",
        "  val_size = len(dataset[i]) - train_size\n",
        "\n",
        "  # Divide the dataset by randomly selecting samples.\n",
        "  train_dataset[i], val_dataset[i] = random_split(dataset[i], [train_size, val_size])\n",
        "\n",
        "  print('{:>5,} training samples'.format(train_size))\n",
        "  print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,134 training samples\n",
            "  126 validation samples\n",
            "   52 training samples\n",
            "    6 validation samples\n",
            "   68 training samples\n",
            "    8 validation samples\n",
            "  137 training samples\n",
            "   16 validation samples\n",
            "7,930 training samples\n",
            "  882 validation samples\n",
            "   49 training samples\n",
            "    6 validation samples\n",
            "5,313 training samples\n",
            "  591 validation samples\n",
            "1,611 training samples\n",
            "  180 validation samples\n",
            "3,063 training samples\n",
            "  341 validation samples\n",
            "  207 training samples\n",
            "   24 validation samples\n",
            "   47 training samples\n",
            "    6 validation samples\n",
            "   37 training samples\n",
            "    5 validation samples\n",
            "   77 training samples\n",
            "    9 validation samples\n",
            "  175 training samples\n",
            "   20 validation samples\n",
            "2,592 training samples\n",
            "  288 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTLaNmjnAxKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader= [[] for x in range(NUM_TOPICS)]\n",
        "validation_dataloader= [[] for x in range(NUM_TOPICS)]\n",
        "\n",
        "for i in range(NUM_TOPICS):\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "\n",
        "  train_dataloader[i] = DataLoader(\n",
        "              train_dataset[i],  # The training samples.\n",
        "              sampler = RandomSampler(train_dataset[i]), # Select batches randomly\n",
        "              batch_size = batch_size # Trains with this batch size.\n",
        "          )\n",
        "\n",
        "  # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "  validation_dataloader[i] = DataLoader(\n",
        "              val_dataset[i], # The validation samples.\n",
        "              sampler = SequentialSampler(val_dataset[i]), # Pull out batches sequentially.\n",
        "              batch_size = batch_size # Evaluate with this batch size.\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqtstYVsLZvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4f5f9ff-d13f-4603-c5a6-b9d3cac4482c"
      },
      "source": [
        "print(train_dataloader[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7ff9e87bdd30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1OewInJBGb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNW1wiQxH_h0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "66fe8af1-aba3-485a-a56b-a4fa85426d29"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWmFsGEYIFfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnAND7_yIOwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "total_steps= []\n",
        "scheduler= []\n",
        "\n",
        "for i in range(NUM_TOPICS):\n",
        "  # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "  # (Note that this is not the same as the number of training samples).\n",
        "  total_steps.append(len(train_dataloader[i]) * epochs)\n",
        "\n",
        "  # Create the learning rate scheduler.\n",
        "  scheduler.append(get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                              num_training_steps = total_steps[i]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPp7KnsuIaCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQgxduW3Ihvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrXRi2T5IkeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ccfe7232-c80f-45a0-df82-412d7052c7d4"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = [[] for x in range(NUM_TOPICS)]\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "for i in range(NUM_TOPICS):\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "      \n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      # Perform one full pass over the training set.\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      # Measure how long the training epoch takes.\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Reset the total loss for this epoch.\n",
        "      total_train_loss = 0\n",
        "\n",
        "      # Put the model into training mode. Don't be mislead--the call to \n",
        "      # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "      # `dropout` and `batchnorm` layers behave differently during training\n",
        "      # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(train_dataloader[i]):\n",
        "          # Progress update every 40 batches.\n",
        "          if step % 40 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader[i]), elapsed))\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          # Always clear any previously calculated gradients before performing a\n",
        "          # backward pass. PyTorch doesn't do this automatically because \n",
        "          # accumulating the gradients is \"convenient while training RNNs\". \n",
        "          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "          model.zero_grad()        \n",
        "\n",
        "          # Perform a forward pass (evaluate the model on this training batch).\n",
        "          # The documentation for this `model` function is here: \n",
        "          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "          # It returns different numbers of parameters depending on what arguments\n",
        "          # arge given and what flags are set. For our useage here, it returns\n",
        "          # the loss (because we provided labels) and the \"logits\"--the model\n",
        "          # outputs prior to activation.\n",
        "          loss, logits = model(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=b_input_mask, \n",
        "                              labels=b_labels)\n",
        "\n",
        "          # Accumulate the training loss over all of the batches so that we can\n",
        "          # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "          # single value; the `.item()` function just returns the Python value \n",
        "          # from the tensor.\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip the norm of the gradients to 1.0.\n",
        "          # This is to help prevent the \"exploding gradients\" problem.\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "          # Update parameters and take a step using the computed gradient.\n",
        "          # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "          # modified based on their gradients, the learning rate, etc.\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update the learning rate.\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader[i])            \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set.\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Put the model in evaluation mode--the dropout layers behave differently\n",
        "      # during evaluation.\n",
        "      model.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in validation_dataloader[i]:\n",
        "          \n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "          # the `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          \n",
        "          # Tell pytorch not to bother with constructing the compute graph during\n",
        "          # the forward pass, since this is only needed for backprop (training).\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              # Forward pass, calculate logit predictions.\n",
        "              # token_type_ids is the same as the \"segment ids\", which \n",
        "              # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "              # The documentation for this `model` function is here: \n",
        "              # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "              # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "              # values prior to applying an activation function like the softmax.\n",
        "              (loss, logits) = model(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels)\n",
        "              \n",
        "          # Accumulate the validation loss.\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "          # Calculate the accuracy for this batch of test sentences, and\n",
        "          # accumulate it over all batches.\n",
        "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "          \n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      avg_val_accuracy = total_eval_accuracy / len(validation_dataloader[i])\n",
        "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader[i])\n",
        "      \n",
        "      # Measure how long the validation run took.\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "      \n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats[i].append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Valid. Accur.': avg_val_accuracy,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-e44337c14868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0;31m#   [1]: attention masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0;31m#   [2]: labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           \u001b[0mb_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m           \u001b[0mb_input_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwpfhmY_JSPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}